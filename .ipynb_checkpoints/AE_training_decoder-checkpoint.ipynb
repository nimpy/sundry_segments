{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, UpSampling2D, Conv2D, Flatten, Dense, Reshape\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras import backend as K\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import listdir\n",
    "from os import system\n",
    "import os\n",
    "import random\n",
    "\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 16, 16\n",
    "\n",
    "nb_epoch = 50\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/niaki/Code/ImageNet/tiny-imagenet-200'\n",
    "\n",
    "train_data_dir      = base_dir + '/tiny_train16'\n",
    "validation_data_dir = base_dir + '/tiny_validation16'\n",
    "test_data_dir       = base_dir + '/tiny_test16'\n",
    "\n",
    "# train_descrs_dir      = base_dir + '/tiny_sifts/tiny_train16'\n",
    "# validation_descrs_dir = base_dir + '/tiny_sifts/tiny_validation16'\n",
    "# test_descrs_dir       = base_dir + '/tiny_sifts/tiny_test16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_data(data_dir):\n",
    "    files = listdir(data_dir + '/class0')\n",
    "    files.sort()\n",
    "\n",
    "    images = []\n",
    "\n",
    "    for file in files:\n",
    "        image = imageio.imread(data_dir + '/class0/' + file)\n",
    "    #     image = np.expand_dims(image, axis=0)\n",
    "        images.append(image)\n",
    "\n",
    "    images = np.array(images)\n",
    "    images = images.astype(np.float64) / 255\n",
    "    print(images.shape)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = loading_data(train_data_dir)\n",
    "x_validation = loading_data(validation_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loading_descrs(descrs_dir):\n",
    "#     files = listdir(descrs_dir + '/class0')\n",
    "#     files.sort()\n",
    "\n",
    "#     descrs = []\n",
    "\n",
    "#     for file in files:\n",
    "#         descr = np.load(descrs_dir + '/class0/' + file)\n",
    "#         descrs.append(descr)\n",
    "\n",
    "#     descrs = np.array(descrs)\n",
    "#     print(descrs.shape)\n",
    "#     return descrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157086, 128)\n",
      "(3932, 128)\n"
     ]
    }
   ],
   "source": [
    "# y_train = loading_descrs(train_descrs_dir)\n",
    "# y_validation = loading_descrs(validation_descrs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_shape = (img_width, img_height, 3)\n",
    "input_img = Input(shape=input_shape)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", trainable=False)(input_img)\n",
    "x = MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", trainable=False)(x)\n",
    "x = MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", trainable=False)(x)\n",
    "x = MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "x = Flatten(data_format=\"channels_last\")(x)\n",
    "encoded = Dense(128, activation=\"relu\", trainable=False)(x)\n",
    "\n",
    "x = Reshape((2, 2, 32))(encoded) #, input_shape=(128,))\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(3, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='rmsprop', metrics=['accuracy'], loss='mean_squared_error')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fixed_generator(generator):\n",
    "#     for batch in generator:\n",
    "#         yield (batch, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_generator(x_train, batch_size):\n",
    "    while True:\n",
    "        batch_list_x = []\n",
    "        \n",
    "        for i in range(x_train.shape[0]):\n",
    "            batch_list_x.append(x_train[i])\n",
    "            if len(batch_list_x) == batch_size:\n",
    "                yield (np.array(batch_list_x),np.array(batch_list_x))\n",
    "                batch_list_x = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_datagen = ImageDataGenerator(\n",
    "#         rescale=1./255#,\n",
    "#         #shear_range=0.2,\n",
    "#         #zoom_range=0.2,\n",
    "#         #horizontal_flip=True\n",
    "#         )\n",
    "# test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# train_generator = train_datagen.flow_from_directory(\n",
    "#         train_data_dir,\n",
    "#         target_size=(img_width, img_height),\n",
    "#         batch_size=batch_size,\n",
    "#         class_mode=None)\n",
    "\n",
    "# validation_generator = test_datagen.flow_from_directory(\n",
    "#         validation_data_dir,\n",
    "#         target_size=(img_width, img_height),\n",
    "#         batch_size=batch_size,\n",
    "#         class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0813 17:54:30.981144 140519722301248 deprecation_wrapper.py:119] From /scratch/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0813 17:54:30.985974 140519722301248 deprecation_wrapper.py:119] From /scratch/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_version = '0.0.5.1_relu_rmsprop_mse_generated_ae_decoder_trained'\n",
    "\n",
    "os.system('mkdir ' + base_dir + '/weights' + model_version)\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(base_dir + '/weights' + model_version + '/weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "autoencoder.fit_generator(fixed_generator(x_train, 32),\n",
    "                steps_per_epoch=157086,\n",
    "                epochs=50,\n",
    "                validation_data=fixed_generator(x_validation, 32),\n",
    "                validation_steps=3932,\n",
    "                callbacks=[checkpointer]\n",
    "                )\n",
    "\n",
    "# autoencoder.fit_generator(\n",
    "#         fixed_generator(train_generator),\n",
    "#         steps_per_epoch=157086,\n",
    "#         epochs=50,\n",
    "#         validation_data=fixed_generator(validation_generator),\n",
    "#         validation_steps=3932,\n",
    "#         callbacks=[checkpointer]\n",
    "#         )\n",
    "\n",
    "autoencoder.save(base_dir + '/encoder' + model_version + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "        311629.72 , 324981.62 , 587550.9  , 300621.44 , 277802.44 ,\n",
       "        620930.5  , 369696.8  , 174378.53 , 356632.44 , 179965.12 ,\n",
       "        311662.3  ,      0.   , 297744.97 , 465017.12 , 118608.24 ,\n",
       "        175118.34 ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   , 203758.33 ,  46789.83 , 370677.12 ,\n",
       "         99011.67 , 282624.1  , 581373.44 , 212476.52 , 272498.88 ,\n",
       "        324719.53 ,  39623.863, 252202.44 ,      0.   , 309481.34 ,\n",
       "        482388.97 ,      0.   , 176703.72 ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ]], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.predict(imageio.imread(\"/home/niaki/Code/ImageNet/tiny-imagenet-200/tiny_validation16/class0/patch000010.png\").reshape(1,16,16,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
