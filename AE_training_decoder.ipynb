{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, UpSampling2D, Conv2D, Flatten, Dense, Reshape\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras import backend as K\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import listdir\n",
    "from os import system\n",
    "import os\n",
    "import random\n",
    "\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 16, 16\n",
    "\n",
    "nb_epoch = 50\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/niaki/Code/ImageNet/tiny-imagenet-200'\n",
    "\n",
    "train_data_dir      = base_dir + '/tiny_train16'\n",
    "validation_data_dir = base_dir + '/tiny_validation16'\n",
    "test_data_dir       = base_dir + '/tiny_test16'\n",
    "\n",
    "# train_descrs_dir      = base_dir + '/tiny_sifts/tiny_train16'\n",
    "# validation_descrs_dir = base_dir + '/tiny_sifts/tiny_validation16'\n",
    "# test_descrs_dir       = base_dir + '/tiny_sifts/tiny_test16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_data(data_dir):\n",
    "    files = listdir(data_dir + '/class0')\n",
    "    files.sort()\n",
    "\n",
    "    images = []\n",
    "\n",
    "    for file in files:\n",
    "        image = imageio.imread(data_dir + '/class0/' + file)\n",
    "    #     image = np.expand_dims(image, axis=0)\n",
    "        images.append(image)\n",
    "\n",
    "    images = np.array(images)\n",
    "    images = images.astype(np.float64) / 255\n",
    "    print(images.shape)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157086, 16, 16, 3)\n",
      "(3932, 16, 16, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train = loading_data(train_data_dir)\n",
    "x_validation = loading_data(validation_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loading_descrs(descrs_dir):\n",
    "#     files = listdir(descrs_dir + '/class0')\n",
    "#     files.sort()\n",
    "\n",
    "#     descrs = []\n",
    "\n",
    "#     for file in files:\n",
    "#         descr = np.load(descrs_dir + '/class0/' + file)\n",
    "#         descrs.append(descr)\n",
    "\n",
    "#     descrs = np.array(descrs)\n",
    "#     print(descrs.shape)\n",
    "#     return descrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157086, 128)\n",
      "(3932, 128)\n"
     ]
    }
   ],
   "source": [
    "# y_train = loading_descrs(train_descrs_dir)\n",
    "# y_validation = loading_descrs(validation_descrs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_30 (InputLayer)        (None, 16, 16, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_185 (Conv2D)          (None, 16, 16, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_88 (MaxPooling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_186 (Conv2D)          (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_89 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_187 (Conv2D)          (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_90 (MaxPooling (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_30 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "reshape_30 (Reshape)         (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_188 (Conv2D)          (None, 2, 2, 32)          9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_73 (UpSampling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_189 (Conv2D)          (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_74 (UpSampling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_190 (Conv2D)          (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_75 (UpSampling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_191 (Conv2D)          (None, 16, 16, 3)         867       \n",
      "=================================================================\n",
      "Total params: 81,027\n",
      "Trainable params: 45,123\n",
      "Non-trainable params: 35,904\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (img_width, img_height, 3)\n",
    "input_img = Input(shape=input_shape)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", trainable=False)(input_img)\n",
    "x = MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", trainable=False)(x)\n",
    "x = MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", trainable=False)(x)\n",
    "x = MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "x = Flatten(data_format=\"channels_last\")(x)\n",
    "encoded = Dense(128, activation=\"relu\", trainable=False)(x)\n",
    "\n",
    "x = Dense(128, activation=\"relu\")(encoded)\n",
    "x = Reshape((2, 2, 32))(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(3, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='rmsprop', metrics=['accuracy'], loss='mean_squared_error')\n",
    "\n",
    "model_version_encoder = '0.0.5.1_encoder_relu_rmsprop_mse_generated'\n",
    "encoder = load_model(base_dir + '/ae' + model_version_encoder + '.h5')\n",
    "for i in range(len(encoder.layers)):\n",
    "    autoencoder.get_layer(index=i).set_weights(encoder.get_layer(index=i).get_weights())\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fixed_generator(generator):\n",
    "#     for batch in generator:\n",
    "#         yield (batch, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_datagen = ImageDataGenerator(\n",
    "#         rescale=1./255#,\n",
    "#         #shear_range=0.2,\n",
    "#         #zoom_range=0.2,\n",
    "#         #horizontal_flip=True\n",
    "#         )\n",
    "# test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# train_generator = train_datagen.flow_from_directory(\n",
    "#         train_data_dir,\n",
    "#         target_size=(img_width, img_height),\n",
    "#         batch_size=batch_size,\n",
    "#         class_mode=None)\n",
    "\n",
    "# validation_generator = test_datagen.flow_from_directory(\n",
    "#         validation_data_dir,\n",
    "#         target_size=(img_width, img_height),\n",
    "#         batch_size=batch_size,\n",
    "#         class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_generator(x_train, batch_size):\n",
    "    while True:\n",
    "        batch_list_x = []\n",
    "        \n",
    "        for i in range(x_train.shape[0]):\n",
    "            batch_list_x.append(x_train[i])\n",
    "            if len(batch_list_x) == batch_size:\n",
    "                yield (np.array(batch_list_x),np.array(batch_list_x))\n",
    "                batch_list_x = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "157086/157086 [==============================] - 1061s 7ms/step - loss: 0.3069 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5258\n",
      "Epoch 2/50\n",
      "157086/157086 [==============================] - 1168s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3156 - val_acc: 0.5260\n",
      "Epoch 3/50\n",
      "157086/157086 [==============================] - 1168s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5260\n",
      "Epoch 4/50\n",
      "157086/157086 [==============================] - 1117s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3157 - val_acc: 0.5259\n",
      "Epoch 5/50\n",
      "157086/157086 [==============================] - 1110s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5258\n",
      "Epoch 6/50\n",
      "157086/157086 [==============================] - 1113s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5260\n",
      "Epoch 7/50\n",
      "157086/157086 [==============================] - 1114s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5260\n",
      "Epoch 8/50\n",
      "157086/157086 [==============================] - 1118s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3156 - val_acc: 0.5259\n",
      "Epoch 9/50\n",
      "157086/157086 [==============================] - 1119s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3156 - val_acc: 0.5258\n",
      "Epoch 10/50\n",
      "157086/157086 [==============================] - 1121s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5259\n",
      "Epoch 11/50\n",
      "157086/157086 [==============================] - 1122s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5260\n",
      "Epoch 12/50\n",
      "157086/157086 [==============================] - 1117s 7ms/step - loss: 0.3069 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5260\n",
      "Epoch 13/50\n",
      "157086/157086 [==============================] - 1108s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3156 - val_acc: 0.5258\n",
      "Epoch 14/50\n",
      "157086/157086 [==============================] - 1123s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5258\n",
      "Epoch 15/50\n",
      "157086/157086 [==============================] - 1122s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5260\n",
      "Epoch 16/50\n",
      "157086/157086 [==============================] - 1123s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5260\n",
      "Epoch 17/50\n",
      "157086/157086 [==============================] - 1108s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3157 - val_acc: 0.5259\n",
      "Epoch 18/50\n",
      "157086/157086 [==============================] - 1106s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5258\n",
      "Epoch 19/50\n",
      "157086/157086 [==============================] - 1108s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5260\n",
      "Epoch 20/50\n",
      "157086/157086 [==============================] - 1106s 7ms/step - loss: 0.3069 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5260\n",
      "Epoch 21/50\n",
      "157086/157086 [==============================] - 1107s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5260\n",
      "Epoch 22/50\n",
      "157086/157086 [==============================] - 1106s 7ms/step - loss: 0.3069 - acc: 0.5256 - val_loss: 0.3156 - val_acc: 0.5258\n",
      "Epoch 23/50\n",
      "157086/157086 [==============================] - 1105s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5260\n",
      "Epoch 24/50\n",
      "157086/157086 [==============================] - 1106s 7ms/step - loss: 0.3069 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5260\n",
      "Epoch 25/50\n",
      "157086/157086 [==============================] - 1108s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5260\n",
      "Epoch 26/50\n",
      "157086/157086 [==============================] - 1107s 7ms/step - loss: 0.3069 - acc: 0.5256 - val_loss: 0.3157 - val_acc: 0.5258\n",
      "Epoch 27/50\n",
      "157086/157086 [==============================] - 1108s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5258\n",
      "Epoch 28/50\n",
      "157086/157086 [==============================] - 1106s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5260\n",
      "Epoch 29/50\n",
      "157086/157086 [==============================] - 1107s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5260\n",
      "Epoch 30/50\n",
      "157086/157086 [==============================] - 1106s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3156 - val_acc: 0.5259\n",
      "Epoch 31/50\n",
      "157086/157086 [==============================] - 1107s 7ms/step - loss: 0.3069 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5258\n",
      "Epoch 32/50\n",
      "157086/157086 [==============================] - 1108s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5260\n",
      "Epoch 33/50\n",
      "157086/157086 [==============================] - 1107s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5260\n",
      "Epoch 34/50\n",
      "157086/157086 [==============================] - 1106s 7ms/step - loss: 0.3069 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5259\n",
      "Epoch 35/50\n",
      "157086/157086 [==============================] - 1108s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3156 - val_acc: 0.5258\n",
      "Epoch 36/50\n",
      "157086/157086 [==============================] - 1107s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5259\n",
      "Epoch 37/50\n",
      "157086/157086 [==============================] - 1108s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3156 - val_acc: 0.5260\n",
      "Epoch 38/50\n",
      "157086/157086 [==============================] - 1106s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5260\n",
      "Epoch 39/50\n",
      "157086/157086 [==============================] - 1107s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3157 - val_acc: 0.5259\n",
      "Epoch 40/50\n",
      "157086/157086 [==============================] - 1106s 7ms/step - loss: 0.3069 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5258\n",
      "Epoch 41/50\n",
      "157086/157086 [==============================] - 1107s 7ms/step - loss: 0.3069 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5260\n",
      "Epoch 42/50\n",
      "157086/157086 [==============================] - 1107s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5260\n",
      "Epoch 43/50\n",
      "157086/157086 [==============================] - 1106s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3156 - val_acc: 0.5260\n",
      "Epoch 44/50\n",
      "157086/157086 [==============================] - 1105s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3156 - val_acc: 0.5257\n",
      "Epoch 45/50\n",
      "157086/157086 [==============================] - 1104s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5261\n",
      "Epoch 46/50\n",
      "157086/157086 [==============================] - 1105s 7ms/step - loss: 0.3069 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5259\n",
      "Epoch 47/50\n",
      "157086/157086 [==============================] - 1105s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3156 - val_acc: 0.5260\n",
      "Epoch 48/50\n",
      "157086/157086 [==============================] - 1104s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3156 - val_acc: 0.5259\n",
      "Epoch 49/50\n",
      "157086/157086 [==============================] - 1103s 7ms/step - loss: 0.3069 - acc: 0.5256 - val_loss: 0.3155 - val_acc: 0.5258\n",
      "Epoch 50/50\n",
      "157086/157086 [==============================] - 1104s 7ms/step - loss: 0.3070 - acc: 0.5256 - val_loss: 0.3156 - val_acc: 0.5260\n"
     ]
    }
   ],
   "source": [
    "model_version = '0.0.5.1_relu_rmsprop_mse_generated__decoder4_rmsprop_mse_relulast_denselast_generated'\n",
    "\n",
    "os.system('mkdir ' + base_dir + '/weights' + model_version)\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(base_dir + '/weights' + model_version + '/weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "autoencoder.fit_generator(fixed_generator(x_train, 32),\n",
    "                steps_per_epoch=157086,\n",
    "                epochs=50,\n",
    "                validation_data=fixed_generator(x_validation, 32),\n",
    "                validation_steps=3932,\n",
    "                callbacks=[checkpointer]\n",
    "                )\n",
    "\n",
    "autoencoder.save(base_dir + '/ae' + model_version + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [1., 1., 1.],\n",
       "         [0., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 0., 0.]]]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.predict(imageio.imread(\"/home/niaki/Code/ImageNet/tiny-imagenet-200/tiny_validation16/class0/patch000010.png\").reshape((1,16,16,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 157086 samples, validate on 3932 samples\n",
      "Epoch 1/50\n",
      "157086/157086 [==============================] - 8s 50us/step - loss: 4.0123 - acc: 0.0231 - val_loss: 0.7159 - val_acc: 0.0299\n",
      "Epoch 2/50\n",
      "157086/157086 [==============================] - 6s 39us/step - loss: 0.6688 - acc: 0.0382 - val_loss: 0.6548 - val_acc: 0.0408\n",
      "Epoch 3/50\n",
      "157086/157086 [==============================] - 6s 39us/step - loss: 0.6484 - acc: 0.0405 - val_loss: 0.6497 - val_acc: 0.0403\n",
      "Epoch 4/50\n",
      "157086/157086 [==============================] - 6s 39us/step - loss: 0.6416 - acc: 0.0404 - val_loss: 0.6431 - val_acc: 0.0394\n",
      "Epoch 5/50\n",
      "157086/157086 [==============================] - 6s 39us/step - loss: 0.6383 - acc: 0.0400 - val_loss: 0.6474 - val_acc: 0.0389\n",
      "Epoch 6/50\n",
      "157086/157086 [==============================] - 6s 38us/step - loss: 0.6351 - acc: 0.0406 - val_loss: 0.6394 - val_acc: 0.0420\n",
      "Epoch 7/50\n",
      "157086/157086 [==============================] - 6s 38us/step - loss: 0.6340 - acc: 0.0405 - val_loss: 0.6386 - val_acc: 0.0390\n",
      "Epoch 8/50\n",
      "157086/157086 [==============================] - 6s 39us/step - loss: 0.6325 - acc: 0.0403 - val_loss: 0.6423 - val_acc: 0.0384\n",
      "Epoch 9/50\n",
      "157086/157086 [==============================] - 6s 38us/step - loss: 0.6307 - acc: 0.0405 - val_loss: 0.6479 - val_acc: 0.0410\n",
      "Epoch 10/50\n",
      "157086/157086 [==============================] - 6s 39us/step - loss: 0.6302 - acc: 0.0408 - val_loss: 0.6303 - val_acc: 0.0400\n",
      "Epoch 11/50\n",
      "157086/157086 [==============================] - 6s 38us/step - loss: 0.6295 - acc: 0.0410 - val_loss: 0.6325 - val_acc: 0.0398\n",
      "Epoch 12/50\n",
      "157086/157086 [==============================] - 6s 41us/step - loss: 0.6285 - acc: 0.0409 - val_loss: 0.6302 - val_acc: 0.0403\n",
      "Epoch 13/50\n",
      "157086/157086 [==============================] - 6s 39us/step - loss: 0.6278 - acc: 0.0412 - val_loss: 0.6370 - val_acc: 0.0396\n",
      "Epoch 14/50\n",
      "157086/157086 [==============================] - 6s 39us/step - loss: 0.6280 - acc: 0.0415 - val_loss: 0.6299 - val_acc: 0.0418\n",
      "Epoch 15/50\n",
      "157086/157086 [==============================] - 6s 39us/step - loss: 0.6268 - acc: 0.0415 - val_loss: 0.6302 - val_acc: 0.0406\n",
      "Epoch 16/50\n",
      "157086/157086 [==============================] - 6s 39us/step - loss: 0.6263 - acc: 0.0417 - val_loss: 0.6361 - val_acc: 0.0420\n",
      "Epoch 17/50\n",
      "157086/157086 [==============================] - 6s 38us/step - loss: 0.6261 - acc: 0.0418 - val_loss: 0.6275 - val_acc: 0.0407\n",
      "Epoch 18/50\n",
      "157086/157086 [==============================] - 6s 39us/step - loss: 0.6256 - acc: 0.0415 - val_loss: 0.6303 - val_acc: 0.0402\n",
      "Epoch 19/50\n",
      "157086/157086 [==============================] - 6s 38us/step - loss: 0.6251 - acc: 0.0419 - val_loss: 0.6297 - val_acc: 0.0421\n",
      "Epoch 20/50\n",
      "157086/157086 [==============================] - 6s 39us/step - loss: 0.6246 - acc: 0.0421 - val_loss: 0.6271 - val_acc: 0.0437\n",
      "Epoch 21/50\n",
      "157086/157086 [==============================] - 6s 39us/step - loss: 0.6245 - acc: 0.0425 - val_loss: 0.6256 - val_acc: 0.0428\n",
      "Epoch 22/50\n",
      "157086/157086 [==============================] - 6s 39us/step - loss: 0.6237 - acc: 0.0419 - val_loss: 0.6289 - val_acc: 0.0400\n",
      "Epoch 23/50\n",
      "157086/157086 [==============================] - 6s 39us/step - loss: 0.6239 - acc: 0.0423 - val_loss: 0.6276 - val_acc: 0.0422\n",
      "Epoch 24/50\n",
      "157086/157086 [==============================] - 7s 42us/step - loss: 0.6238 - acc: 0.0424 - val_loss: 0.6269 - val_acc: 0.0406\n",
      "Epoch 25/50\n",
      "157086/157086 [==============================] - 6s 39us/step - loss: 0.6231 - acc: 0.0422 - val_loss: 0.6262 - val_acc: 0.0422\n",
      "Epoch 26/50\n",
      "157086/157086 [==============================] - 6s 39us/step - loss: 0.6229 - acc: 0.0427 - val_loss: 0.6324 - val_acc: 0.0438\n",
      "Epoch 27/50\n",
      "157086/157086 [==============================] - 6s 39us/step - loss: 0.6226 - acc: 0.0426 - val_loss: 0.6266 - val_acc: 0.0427\n",
      "Epoch 28/50\n",
      "157086/157086 [==============================] - 6s 39us/step - loss: 0.6224 - acc: 0.0425 - val_loss: 0.6258 - val_acc: 0.0428\n",
      "Epoch 29/50\n",
      "157086/157086 [==============================] - 6s 38us/step - loss: 0.6226 - acc: 0.0425 - val_loss: 0.6248 - val_acc: 0.0435\n",
      "Epoch 30/50\n",
      "157086/157086 [==============================] - 6s 38us/step - loss: 0.6225 - acc: 0.0423 - val_loss: 0.6246 - val_acc: 0.0408\n",
      "Epoch 31/50\n",
      "157086/157086 [==============================] - 6s 38us/step - loss: 0.6219 - acc: 0.0428 - val_loss: 0.6254 - val_acc: 0.0409\n",
      "Epoch 32/50\n",
      "157086/157086 [==============================] - 6s 38us/step - loss: 0.6216 - acc: 0.0425 - val_loss: 0.6259 - val_acc: 0.0440\n",
      "Epoch 33/50\n",
      "157086/157086 [==============================] - 6s 38us/step - loss: 0.6212 - acc: 0.0427 - val_loss: 0.6313 - val_acc: 0.0437\n",
      "Epoch 34/50\n",
      "157086/157086 [==============================] - 6s 39us/step - loss: 0.6214 - acc: 0.0426 - val_loss: 0.6243 - val_acc: 0.0423\n",
      "Epoch 35/50\n",
      "157086/157086 [==============================] - 6s 39us/step - loss: 0.6212 - acc: 0.0425 - val_loss: 0.6270 - val_acc: 0.0426\n",
      "Epoch 36/50\n",
      "157086/157086 [==============================] - 6s 39us/step - loss: 0.6210 - acc: 0.0430 - val_loss: 0.6352 - val_acc: 0.0434\n",
      "Epoch 37/50\n",
      "157086/157086 [==============================] - 6s 39us/step - loss: 0.6207 - acc: 0.0428 - val_loss: 0.6241 - val_acc: 0.0427\n",
      "Epoch 38/50\n",
      "157086/157086 [==============================] - 6s 38us/step - loss: 0.6204 - acc: 0.0426 - val_loss: 0.6242 - val_acc: 0.0439\n",
      "Epoch 39/50\n",
      "157086/157086 [==============================] - 6s 39us/step - loss: 0.6204 - acc: 0.0426 - val_loss: 0.6322 - val_acc: 0.0433\n",
      "Epoch 40/50\n",
      "157086/157086 [==============================] - 6s 40us/step - loss: 0.6201 - acc: 0.0428 - val_loss: 0.6249 - val_acc: 0.0434\n",
      "Epoch 41/50\n",
      "157086/157086 [==============================] - 6s 40us/step - loss: 0.6200 - acc: 0.0431 - val_loss: 0.6242 - val_acc: 0.0429\n",
      "Epoch 42/50\n",
      "157086/157086 [==============================] - 6s 38us/step - loss: 0.6202 - acc: 0.0430 - val_loss: 0.6226 - val_acc: 0.0437\n",
      "Epoch 43/50\n",
      "157086/157086 [==============================] - 6s 40us/step - loss: 0.6199 - acc: 0.0427 - val_loss: 0.6307 - val_acc: 0.0408\n",
      "Epoch 44/50\n",
      "157086/157086 [==============================] - 6s 40us/step - loss: 0.6193 - acc: 0.0425 - val_loss: 0.6245 - val_acc: 0.0428\n",
      "Epoch 45/50\n",
      "157086/157086 [==============================] - 6s 39us/step - loss: 0.6197 - acc: 0.0430 - val_loss: 0.6244 - val_acc: 0.0414\n",
      "Epoch 46/50\n",
      "157086/157086 [==============================] - 6s 39us/step - loss: 0.6190 - acc: 0.0428 - val_loss: 0.6378 - val_acc: 0.0430\n",
      "Epoch 47/50\n",
      "157086/157086 [==============================] - 6s 39us/step - loss: 0.6194 - acc: 0.0425 - val_loss: 0.6238 - val_acc: 0.0413\n",
      "Epoch 48/50\n",
      "157086/157086 [==============================] - 6s 39us/step - loss: 0.6194 - acc: 0.0427 - val_loss: 0.6229 - val_acc: 0.0434\n",
      "Epoch 49/50\n",
      "157086/157086 [==============================] - 7s 44us/step - loss: 0.6192 - acc: 0.0429 - val_loss: 0.6250 - val_acc: 0.0437\n",
      "Epoch 50/50\n",
      "157086/157086 [==============================] - 7s 42us/step - loss: 0.6192 - acc: 0.0431 - val_loss: 0.6223 - val_acc: 0.0438\n"
     ]
    }
   ],
   "source": [
    "model_version = '0.0.5.1_relu_rmsprop_mse_generated__decoder7_adadelta_bce_relulast_densefirst'\n",
    "\n",
    "os.system('mkdir ' + base_dir + '/weights' + model_version)\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(base_dir + '/weights' + model_version + '/weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_validation, x_validation),\n",
    "                callbacks=[checkpointer]\n",
    "                )\n",
    "\n",
    "autoencoder.save(base_dir + '/ae' + model_version + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "        311629.53 , 324981.12 , 587550.25 , 300621.5  , 277802.1  ,\n",
       "        620929.94 , 369696.34 , 174378.16 , 356632.16 , 179964.34 ,\n",
       "        311661.97 ,      0.   , 297744.62 , 465016.53 , 118607.75 ,\n",
       "        175117.81 ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   , 203758.11 ,  46789.29 , 370676.94 ,\n",
       "         99011.61 , 282623.8  , 581372.75 , 212475.84 , 272498.44 ,\n",
       "        324719.22 ,  39623.344, 252202.27 ,      0.   , 309481.1  ,\n",
       "        482388.22 ,      0.   , 176703.27 ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ,      0.   ,      0.   ,\n",
       "             0.   ,      0.   ,      0.   ]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.predict(imageio.imread(\"/home/niaki/Code/ImageNet/tiny-imagenet-200/tiny_validation16/class0/patch000010.png\").reshape((1,16,16,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7f4a80d730f0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f4a80d73128>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f4a80d73198>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f4a80d732b0>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f4a80d73358>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f4a80bb7978>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f4a80bb7b70>\n",
      "<keras.layers.core.Flatten object at 0x7f4a80b4e320>\n",
      "<keras.layers.core.Dense object at 0x7f4a80b63400>\n",
      "<keras.layers.core.Dense object at 0x7f4a80affa58>\n",
      "<keras.layers.core.Reshape object at 0x7f4a80b16780>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f4a80b30780>\n",
      "<keras.layers.convolutional.UpSampling2D object at 0x7f4a80b16320>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f4a80ae28d0>\n",
      "<keras.layers.convolutional.UpSampling2D object at 0x7f4a80acd898>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f4a80a808d0>\n",
      "<keras.layers.convolutional.UpSampling2D object at 0x7f4a80a96630>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f4a80a4f860>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_31 (InputLayer)        (None, 16, 16, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_192 (Conv2D)          (None, 16, 16, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_91 (MaxPooling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_193 (Conv2D)          (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_92 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_194 (Conv2D)          (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_93 (MaxPooling (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_31 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "reshape_31 (Reshape)         (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_195 (Conv2D)          (None, 2, 2, 32)          9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_76 (UpSampling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_196 (Conv2D)          (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_77 (UpSampling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_197 (Conv2D)          (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_78 (UpSampling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_198 (Conv2D)          (None, 16, 16, 3)         867       \n",
      "=================================================================\n",
      "Total params: 81,027\n",
      "Trainable params: 45,123\n",
      "Non-trainable params: 35,904\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (img_width, img_height, 3)\n",
    "input_img = Input(shape=input_shape)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", trainable=False)(input_img)\n",
    "x = MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", trainable=False)(x)\n",
    "x = MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", trainable=False)(x)\n",
    "x = MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "x = Flatten(data_format=\"channels_last\")(x)\n",
    "encoded = Dense(128, activation=\"relu\", trainable=False)(x)\n",
    "\n",
    "x = Dense(128, activation=\"relu\")(encoded)\n",
    "x = Reshape((2, 2, 32))(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "end_layer = Conv2D(3, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "\n",
    "autoencoder_incomplete = Model(input_img, end_layer)\n",
    "autoencoder_incomplete.compile(optimizer='rmsprop', metrics=['accuracy'], loss='mean_squared_error')\n",
    "\n",
    "for i in range(len(autoencoder_incomplete.layers)):\n",
    "    autoencoder_incomplete.get_layer(index=i).set_weights(autoencoder.get_layer(index=i).get_weights())\n",
    "    print(autoencoder.get_layer(index=i))\n",
    "\n",
    "autoencoder_incomplete.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_mid_result = autoencoder_incomplete.predict(imageio.imread(\"/home/niaki/Code/ImageNet/tiny-imagenet-200/tiny_validation16/class0/patch000010.png\").reshape((1,16,16,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "---\n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "---\n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "---\n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "---\n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "---\n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "---\n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "---\n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "---\n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "---\n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "---\n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "---\n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "---\n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "---\n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "---\n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "---\n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 \n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for i in range(predicted_mid_result.shape[1]):\n",
    "    for j in range(predicted_mid_result.shape[2]):\n",
    "        for k in range(predicted_mid_result.shape[3]):\n",
    "            print(predicted_mid_result[0,i,j,k], end=' ')\n",
    "        print()\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4c96349c18>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(predicted_mid_result.reshape((16,16,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4c96328e10>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(imageio.imread(\"/home/niaki/Code/ImageNet/tiny-imagenet-200/tiny_validation16/class0/patch000064.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(predicted_mid_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4a80d8eb38>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((predicted_mid_result/np.max(predicted_mid_result)).reshape((16,16,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]]], dtype=float32)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.predict(imageio.imread(\"/home/niaki/Code/ImageNet/tiny-imagenet-200/tiny_validation16/class0/patch000010.png\").reshape((1,16,16,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
