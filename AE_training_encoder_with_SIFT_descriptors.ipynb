{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, UpSampling2D, Conv2D, Flatten, Dense\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras import backend as K\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import listdir\n",
    "from os import system\n",
    "import os\n",
    "import random\n",
    "\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 16, 16\n",
    "\n",
    "nb_epoch = 50\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/niaki/Code/ImageNet/tiny-imagenet-200'\n",
    "\n",
    "train_data_dir      = base_dir + '/tiny_train16'\n",
    "validation_data_dir = base_dir + '/tiny_validation16'\n",
    "test_data_dir       = base_dir + '/tiny_test16'\n",
    "\n",
    "train_descrs_dir      = base_dir + '/tiny_sifts/tiny_train16'\n",
    "validation_descrs_dir = base_dir + '/tiny_sifts/tiny_validation16'\n",
    "test_descrs_dir       = base_dir + '/tiny_sifts/tiny_test16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_data(data_dir):\n",
    "    files = listdir(data_dir + '/class0')\n",
    "    files.sort()\n",
    "\n",
    "    images = []\n",
    "\n",
    "    for file in files:\n",
    "        image = imageio.imread(data_dir + '/class0/' + file)\n",
    "    #     image = np.expand_dims(image, axis=0)\n",
    "        images.append(image)\n",
    "\n",
    "    images = np.array(images)\n",
    "    images = images.astype(np.float64) / 255\n",
    "    print(images.shape)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157086, 16, 16, 3)\n",
      "(3932, 16, 16, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train = loading_data(train_data_dir)\n",
    "x_validation = loading_data(validation_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_descrs(descrs_dir):\n",
    "    files = listdir(descrs_dir + '/class0')\n",
    "    files.sort()\n",
    "\n",
    "    descrs = []\n",
    "\n",
    "    for file in files:\n",
    "        descr = np.load(descrs_dir + '/class0/' + file)\n",
    "        descrs.append(descr)\n",
    "\n",
    "    descrs = np.array(descrs)\n",
    "    descrs = descrs.astype(np.float64) / 255\n",
    "    print(descrs.shape)\n",
    "    return descrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157086, 128)\n",
      "(3932, 128)\n"
     ]
    }
   ],
   "source": [
    "y_train = loading_descrs(train_descrs_dir)\n",
    "y_validation = loading_descrs(validation_descrs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0817 00:37:07.890718 140532395018048 deprecation_wrapper.py:119] From /scratch/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0817 00:37:07.911880 140532395018048 deprecation_wrapper.py:119] From /scratch/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0817 00:37:07.915203 140532395018048 deprecation_wrapper.py:119] From /scratch/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0817 00:37:07.926973 140532395018048 deprecation_wrapper.py:119] From /scratch/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0817 00:37:07.962017 140532395018048 deprecation_wrapper.py:119] From /scratch/tensorflow/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0817 00:37:07.972335 140532395018048 deprecation_wrapper.py:119] From /scratch/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0817 00:37:07.976181 140532395018048 deprecation.py:323] From /scratch/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 16, 16, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "=================================================================\n",
      "Total params: 35,904\n",
      "Trainable params: 35,904\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (img_width, img_height, 3)\n",
    "input_img = Input(shape=input_shape)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(input_img)\n",
    "x = MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "x = Flatten(data_format=\"channels_last\")(x)\n",
    "encoded = Dense(128, activation=\"sigmoid\")(x)\n",
    "\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "encoder.compile(optimizer='adadelta', metrics=['accuracy'], loss='binary_crossentropy')\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_generator(x_train, y_train, batch_size):\n",
    "    while True:\n",
    "        batch_list_x = []\n",
    "        batch_list_y = []\n",
    "        \n",
    "        for i in range(x_train.shape[0]):\n",
    "            batch_list_x.append(x_train[i])\n",
    "            batch_list_y.append(y_train[i])\n",
    "            if len(batch_list_x) == batch_size:\n",
    "                yield (np.array(batch_list_x),np.array(batch_list_y))\n",
    "                batch_list_x = []\n",
    "                batch_list_y = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0817 00:37:55.105670 140532395018048 deprecation_wrapper.py:119] From /scratch/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "157086/157086 [==============================] - 888s 6ms/step - loss: 0.1141 - acc: 0.7726 - val_loss: 0.1117 - val_acc: 0.7741\n",
      "Epoch 2/50\n",
      "157086/157086 [==============================] - 883s 6ms/step - loss: 0.1113 - acc: 0.7727 - val_loss: 0.1095 - val_acc: 0.7744\n",
      "Epoch 3/50\n",
      "157086/157086 [==============================] - 885s 6ms/step - loss: 0.1108 - acc: 0.7727 - val_loss: 0.1096 - val_acc: 0.7744\n",
      "Epoch 4/50\n",
      "157086/157086 [==============================] - 884s 6ms/step - loss: 0.1105 - acc: 0.7727 - val_loss: 0.1092 - val_acc: 0.7744\n",
      "Epoch 5/50\n",
      "157086/157086 [==============================] - 880s 6ms/step - loss: 0.1103 - acc: 0.7727 - val_loss: 0.1090 - val_acc: 0.7744\n",
      "Epoch 6/50\n",
      "157086/157086 [==============================] - 882s 6ms/step - loss: 0.1102 - acc: 0.7727 - val_loss: 0.1110 - val_acc: 0.7744\n",
      "Epoch 7/50\n",
      "157086/157086 [==============================] - 883s 6ms/step - loss: 0.1101 - acc: 0.7727 - val_loss: 0.1090 - val_acc: 0.7744\n",
      "Epoch 8/50\n",
      "157086/157086 [==============================] - 886s 6ms/step - loss: 0.1100 - acc: 0.7727 - val_loss: 0.1090 - val_acc: 0.7744\n",
      "Epoch 9/50\n",
      "157086/157086 [==============================] - 886s 6ms/step - loss: 0.1099 - acc: 0.7727 - val_loss: 0.1087 - val_acc: 0.7744\n",
      "Epoch 10/50\n",
      "157086/157086 [==============================] - 887s 6ms/step - loss: 0.1098 - acc: 0.7727 - val_loss: 0.1087 - val_acc: 0.7744\n",
      "Epoch 11/50\n",
      "157086/157086 [==============================] - 886s 6ms/step - loss: 0.1098 - acc: 0.7727 - val_loss: 0.1088 - val_acc: 0.7744\n",
      "Epoch 12/50\n",
      "157086/157086 [==============================] - 886s 6ms/step - loss: 0.1098 - acc: 0.7727 - val_loss: 0.1090 - val_acc: 0.7744\n",
      "Epoch 13/50\n",
      "157086/157086 [==============================] - 886s 6ms/step - loss: 0.1097 - acc: 0.7727 - val_loss: 0.1085 - val_acc: 0.7744\n",
      "Epoch 14/50\n",
      "157086/157086 [==============================] - 884s 6ms/step - loss: 0.1097 - acc: 0.7727 - val_loss: 0.1084 - val_acc: 0.7744\n",
      "Epoch 15/50\n",
      "157086/157086 [==============================] - 888s 6ms/step - loss: 0.1096 - acc: 0.7727 - val_loss: 0.1084 - val_acc: 0.7744\n",
      "Epoch 16/50\n",
      "157086/157086 [==============================] - 886s 6ms/step - loss: 0.1096 - acc: 0.7727 - val_loss: 0.1086 - val_acc: 0.7744\n",
      "Epoch 17/50\n",
      "157086/157086 [==============================] - 885s 6ms/step - loss: 0.1095 - acc: 0.7727 - val_loss: 0.1086 - val_acc: 0.7745\n",
      "Epoch 18/50\n",
      "157086/157086 [==============================] - 888s 6ms/step - loss: 0.1095 - acc: 0.7727 - val_loss: 0.1092 - val_acc: 0.7744\n",
      "Epoch 19/50\n",
      "157086/157086 [==============================] - 885s 6ms/step - loss: 0.1094 - acc: 0.7727 - val_loss: 0.1085 - val_acc: 0.7744\n",
      "Epoch 20/50\n",
      "157086/157086 [==============================] - 886s 6ms/step - loss: 0.1095 - acc: 0.7727 - val_loss: 0.1088 - val_acc: 0.7743\n",
      "Epoch 21/50\n",
      "157086/157086 [==============================] - 888s 6ms/step - loss: 0.1095 - acc: 0.7727 - val_loss: 0.1082 - val_acc: 0.7744\n",
      "Epoch 22/50\n",
      "157086/157086 [==============================] - 888s 6ms/step - loss: 0.1095 - acc: 0.7727 - val_loss: 0.1086 - val_acc: 0.7744\n",
      "Epoch 23/50\n",
      "157086/157086 [==============================] - 887s 6ms/step - loss: 0.1095 - acc: 0.7727 - val_loss: 0.1083 - val_acc: 0.7744\n",
      "Epoch 24/50\n",
      "157086/157086 [==============================] - 886s 6ms/step - loss: 0.1095 - acc: 0.7727 - val_loss: 0.1083 - val_acc: 0.7744\n",
      "Epoch 25/50\n",
      "157086/157086 [==============================] - 886s 6ms/step - loss: 0.1095 - acc: 0.7727 - val_loss: 0.1083 - val_acc: 0.7744\n",
      "Epoch 26/50\n",
      "157086/157086 [==============================] - 888s 6ms/step - loss: 0.1094 - acc: 0.7727 - val_loss: 0.1083 - val_acc: 0.7744\n",
      "Epoch 27/50\n",
      "157086/157086 [==============================] - 887s 6ms/step - loss: 0.1094 - acc: 0.7727 - val_loss: 0.1086 - val_acc: 0.7744\n",
      "Epoch 28/50\n",
      "157086/157086 [==============================] - 887s 6ms/step - loss: 0.1094 - acc: 0.7727 - val_loss: 0.1083 - val_acc: 0.7744\n",
      "Epoch 29/50\n",
      "157086/157086 [==============================] - 887s 6ms/step - loss: 0.1094 - acc: 0.7727 - val_loss: 0.1084 - val_acc: 0.7744\n",
      "Epoch 30/50\n",
      "157086/157086 [==============================] - 887s 6ms/step - loss: 0.1094 - acc: 0.7727 - val_loss: 0.1082 - val_acc: 0.7745\n",
      "Epoch 31/50\n",
      "157086/157086 [==============================] - 887s 6ms/step - loss: 0.1094 - acc: 0.7727 - val_loss: 0.1087 - val_acc: 0.7744\n",
      "Epoch 32/50\n",
      "157086/157086 [==============================] - 888s 6ms/step - loss: 0.1093 - acc: 0.7727 - val_loss: 0.1082 - val_acc: 0.7744\n",
      "Epoch 33/50\n",
      "157086/157086 [==============================] - 887s 6ms/step - loss: 0.1093 - acc: 0.7727 - val_loss: 0.1083 - val_acc: 0.7744\n",
      "Epoch 34/50\n",
      "157086/157086 [==============================] - 886s 6ms/step - loss: 0.1093 - acc: 0.7727 - val_loss: 0.1082 - val_acc: 0.7744\n",
      "Epoch 35/50\n",
      "157086/157086 [==============================] - 888s 6ms/step - loss: 0.1093 - acc: 0.7727 - val_loss: 0.1084 - val_acc: 0.7744\n",
      "Epoch 36/50\n",
      "157086/157086 [==============================] - 888s 6ms/step - loss: 0.1093 - acc: 0.7727 - val_loss: 0.1084 - val_acc: 0.7744\n",
      "Epoch 37/50\n",
      "157086/157086 [==============================] - 887s 6ms/step - loss: 0.1093 - acc: 0.7727 - val_loss: 0.1089 - val_acc: 0.7744\n",
      "Epoch 38/50\n",
      "157086/157086 [==============================] - 886s 6ms/step - loss: 0.1093 - acc: 0.7727 - val_loss: 0.1084 - val_acc: 0.7744\n",
      "Epoch 39/50\n",
      "157086/157086 [==============================] - 886s 6ms/step - loss: 0.1093 - acc: 0.7727 - val_loss: 0.1091 - val_acc: 0.7744\n",
      "Epoch 40/50\n",
      "157086/157086 [==============================] - 887s 6ms/step - loss: 0.1093 - acc: 0.7727 - val_loss: 0.1082 - val_acc: 0.7744\n",
      "Epoch 41/50\n",
      "157086/157086 [==============================] - 888s 6ms/step - loss: 0.1093 - acc: 0.7727 - val_loss: 0.1094 - val_acc: 0.7742\n",
      "Epoch 42/50\n",
      "157086/157086 [==============================] - 888s 6ms/step - loss: 0.1093 - acc: 0.7727 - val_loss: 0.1087 - val_acc: 0.7744\n",
      "Epoch 43/50\n",
      "157086/157086 [==============================] - 886s 6ms/step - loss: 0.1093 - acc: 0.7727 - val_loss: 0.1080 - val_acc: 0.7745\n",
      "Epoch 44/50\n",
      "157086/157086 [==============================] - 887s 6ms/step - loss: 0.1093 - acc: 0.7727 - val_loss: 0.1083 - val_acc: 0.7744\n",
      "Epoch 45/50\n",
      "157086/157086 [==============================] - 886s 6ms/step - loss: 0.1093 - acc: 0.7727 - val_loss: 0.1084 - val_acc: 0.7744\n",
      "Epoch 46/50\n",
      "157086/157086 [==============================] - 887s 6ms/step - loss: 0.1093 - acc: 0.7727 - val_loss: 0.1083 - val_acc: 0.7744\n",
      "Epoch 47/50\n",
      "157086/157086 [==============================] - 888s 6ms/step - loss: 0.1093 - acc: 0.7727 - val_loss: 0.1083 - val_acc: 0.7745\n",
      "Epoch 48/50\n",
      "157086/157086 [==============================] - 886s 6ms/step - loss: 0.1093 - acc: 0.7727 - val_loss: 0.1087 - val_acc: 0.7744\n",
      "Epoch 49/50\n",
      "157086/157086 [==============================] - 890s 6ms/step - loss: 0.1093 - acc: 0.7727 - val_loss: 0.1084 - val_acc: 0.7744\n",
      "Epoch 50/50\n",
      "157086/157086 [==============================] - 886s 6ms/step - loss: 0.1093 - acc: 0.7727 - val_loss: 0.1080 - val_acc: 0.7744\n"
     ]
    }
   ],
   "source": [
    "model_version = '0.1.5.3_sigmoid_adadelta_bce_generated'\n",
    "\n",
    "os.system('mkdir ' + base_dir + '/weights' + model_version)\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(base_dir + '/weights' + model_version + '/weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "encoder.fit_generator(fixed_generator(x_train, y_train, 32),\n",
    "                steps_per_epoch=157086,\n",
    "                epochs=50,\n",
    "                validation_data=fixed_generator(x_validation, y_validation, 32),\n",
    "                validation_steps=3932,\n",
    "                callbacks=[checkpointer]\n",
    "                )\n",
    "\n",
    "encoder.save(base_dir + '/ae' + model_version + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.predict(imageio.imread(\"/home/niaki/Code/ImageNet/tiny-imagenet-200/tiny_validation16/class0/patch0000.png\").reshape(1,16,16,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
