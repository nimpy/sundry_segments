{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import listdir\n",
    "from os import system\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import imageio\n",
    "from skimage.measure import block_reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 16\n",
    "nb_channels = 3\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/niaki/Code/ImageNet/tiny-imagenet-200'\n",
    "\n",
    "train_data_dir      = base_dir + '/tiny_train16'\n",
    "validation_data_dir = base_dir + '/tiny_validation16'\n",
    "test_data_dir       = base_dir + '/tiny_test16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_data(dir_patches):\n",
    "    \"\"\"Load all the patches from dir_patches into tensors for training the autoencoder.\n",
    "    Return:\n",
    "        patches_in  -- tensor of stacked patches in their original shape, 16x16\n",
    "        patches_out -- tensor of the original patches downsampled to 8x8\n",
    "    \n",
    "    \"\"\"\n",
    "    files_patches = listdir(dir_patches + '/class0')\n",
    "    files_patches.sort()\n",
    "    \n",
    "    patches_in = []\n",
    "    patches_out = []\n",
    "\n",
    "    \n",
    "    for file_patch in files_patches:\n",
    "        patch_in = imageio.imread(dir_patches + '/class0/' + file_patch)\n",
    "        \n",
    "        patch_out = block_reduce(patch_in, (2, 2, 1), func=np.mean)  # downsample (mean-pool)\n",
    "        \n",
    "        patches_in.append(patch_in)\n",
    "        patches_out.append(patch_out)\n",
    "        \n",
    "\n",
    "    patches_in = np.array(patches_in)\n",
    "    patches_in = patches_in.astype(np.float64) / 255\n",
    "#     patches_in = np.expand_dims(patches_in, -1)  # need this if grayscale\n",
    "    \n",
    "    patches_out = np.array(patches_out)\n",
    "    patches_out = patches_out.astype(np.float64) / 255\n",
    "#     patches_out = np.expand_dims(patches_out, -1)  # need this if grayscale\n",
    "        \n",
    "    print(\"in\", patches_in.shape, \"; out\", patches_out.shape)\n",
    "    \n",
    "    return patches_in, patches_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in (157086, 16, 16, 3) ; out (157086, 8, 8, 3)\n",
      "in (3932, 16, 16, 3) ; out (3932, 8, 8, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train, _ = loading_data(train_data_dir)  # y_train\n",
    "x_validation, _ = loading_data(validation_data_dir)  # y_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do I copy or do I just point to the same thing?\n",
    "#   I think I can just point to the same thing\n",
    "y_train = x_train\n",
    "y_validation = x_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_index = np.random.randint(x_train.shape[0]) #  5429\n",
    "# print(np.array(np.round(x_train[temp_index] * 255), dtype=np.uint8))\n",
    "plt.imshow(np.array(np.round(x_train[temp_index] * 255), dtype=np.uint8))\n",
    "plt.show()\n",
    "plt.imshow(np.array(np.round(y_train[temp_index] * 255), dtype=np.uint8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 16, 16, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 16, 16, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 2, 32)          9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 16, 3)         867       \n",
      "=================================================================\n",
      "Total params: 48,003\n",
      "Trainable params: 48,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (patch_size, patch_size, nb_channels)\n",
    "input_img = Input(shape=input_shape)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation=\"elu\", padding=\"same\")(input_img)\n",
    "x = Conv2D(32, (3, 3), activation=\"elu\", padding=\"same\")(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"elu\", padding=\"same\")(x)\n",
    "x = MaxPool2D((2, 2), padding=\"same\")(x)\n",
    "x = MaxPool2D((2, 2), padding=\"same\")(x)\n",
    "encoded = MaxPool2D((2, 2), padding=\"same\")(x)\n",
    "\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation=\"elu\", padding=\"same\")(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"elu\", padding=\"same\")(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"elu\", padding=\"same\")(x)  # decoded = Conv2D(3, (3, 3), activation=\"elu\", padding=\"same\")(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(3, (3, 3), activation=\"elu\", padding=\"same\")(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7fdb18c75208>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdb18b1db70>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdb118ee1d0>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdb118ee860>\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fdb118eea90>\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fdb118eebe0>\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fdb118eed30>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdb118eee80>\n",
      "<tensorflow.python.keras.layers.convolutional.UpSampling2D object at 0x7fdb118f10b8>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdb118f11d0>\n",
      "<tensorflow.python.keras.layers.convolutional.UpSampling2D object at 0x7fdb1922fe80>\n"
     ]
    }
   ],
   "source": [
    "model_version_dwnsmpld_output = 'patch_desc_ae_20201026_14251116_alex_3conv3mp_2020_augm_elu_lastelu_dwnsmpl'\n",
    "autoencoder_dwnsmpld_output = load_model(base_dir + '/' + model_version_dwnsmpld_output + '.h5')\n",
    "\n",
    "for i in range(11):\n",
    "    print(autoencoder_dwnsmpld_output.get_layer(index=i))\n",
    "    autoencoder.get_layer(index=i).set_weights(autoencoder_dwnsmpld_output.get_layer(index=i).get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datagen = ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n",
    "    width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
    "    horizontal_flip=False, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "# os.environ['WANDB_MODE'] = 'dryrun'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: wandb version 0.10.8 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.7<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">prime-music-6</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nimpy/patch-desc-ae\" target=\"_blank\">https://wandb.ai/nimpy/patch-desc-ae</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/nimpy/patch-desc-ae/runs/2bdam0x2\" target=\"_blank\">https://wandb.ai/nimpy/patch-desc-ae/runs/2bdam0x2</a><br/>\n",
       "                Run data is saved locally in <code>wandb/run-20201028_104308-2bdam0x2</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "  project=\"patch-desc-ae\",\n",
    "  config={\n",
    "    \"augmentation\": True,\n",
    "    \"elus\": False,\n",
    "    \"last_layer_activation\": \"elu\",\n",
    "    \"downsampling_output\": False,\n",
    "    \"optimizer\": \"adadelta\", \n",
    "    \"loss\": \"binary_crossentropy\",\n",
    "    \"epochs\": 1000 }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://wandb.ai/nimpy/patch-desc-ae/runs/2bdam0x2?jupyter=true\" style=\"border:none;width:100%;height:420px\">\n",
       "                </iframe>"
      ],
      "text/plain": [
       "<wandb.jupyter.Run at 0x7fdb62b531d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/niaki/Code/ImageNet/tiny-imagenet-200/weights_patch_desc_ae_20201028_10450816_alex_3conv3mp_2020_augm_elu_lastelu_NOTdwnsmpl_500moreepochs\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 4909 steps, validate for 123 steps\n",
      "Epoch 1/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5373 - val_loss: 0.5330\n",
      "Epoch 2/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5374 - val_loss: 0.5333\n",
      "Epoch 3/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5374 - val_loss: 0.5330\n",
      "Epoch 4/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5373 - val_loss: 0.5329\n",
      "Epoch 5/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5373 - val_loss: 0.5330\n",
      "Epoch 6/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5374 - val_loss: 0.5328\n",
      "Epoch 7/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5373 - val_loss: 0.5334\n",
      "Epoch 8/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5374 - val_loss: 0.5329\n",
      "Epoch 9/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5373 - val_loss: 0.5331\n",
      "Epoch 10/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5373 - val_loss: 0.5330\n",
      "Epoch 11/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5373 - val_loss: 0.5328\n",
      "Epoch 12/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5374 - val_loss: 0.5330\n",
      "Epoch 13/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5374 - val_loss: 0.5329\n",
      "Epoch 14/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5373 - val_loss: 0.5332\n",
      "Epoch 15/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5373 - val_loss: 0.5330\n",
      "Epoch 16/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5373 - val_loss: 0.5329\n",
      "Epoch 17/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5373 - val_loss: 0.5329\n",
      "Epoch 18/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5373 - val_loss: 0.5329\n",
      "Epoch 19/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5373 - val_loss: 0.5331\n",
      "Epoch 20/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5373 - val_loss: 0.5330\n",
      "Epoch 21/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5373 - val_loss: 0.5328\n",
      "Epoch 22/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5373 - val_loss: 0.5331\n",
      "Epoch 23/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5373 - val_loss: 0.5326\n",
      "Epoch 24/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5373 - val_loss: 0.5330\n",
      "Epoch 25/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5373 - val_loss: 0.5329\n",
      "Epoch 26/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5372 - val_loss: 0.5327\n",
      "Epoch 27/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5373 - val_loss: 0.5331\n",
      "Epoch 28/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5372 - val_loss: 0.5329\n",
      "Epoch 29/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5373 - val_loss: 0.5330\n",
      "Epoch 30/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5373 - val_loss: 0.5332\n",
      "Epoch 31/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5373 - val_loss: 0.5330\n",
      "Epoch 32/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5373 - val_loss: 0.5328\n",
      "Epoch 33/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5372 - val_loss: 0.5329\n",
      "Epoch 34/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5373 - val_loss: 0.5327\n",
      "Epoch 35/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5373 - val_loss: 0.5328\n",
      "Epoch 36/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5373 - val_loss: 0.5327\n",
      "Epoch 37/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5373 - val_loss: 0.5327\n",
      "Epoch 38/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5372 - val_loss: 0.5332\n",
      "Epoch 39/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5373 - val_loss: 0.5332\n",
      "Epoch 40/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5373 - val_loss: 0.5326\n",
      "Epoch 41/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5372 - val_loss: 0.5328\n",
      "Epoch 42/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5372 - val_loss: 0.5329\n",
      "Epoch 43/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5372 - val_loss: 0.5327\n",
      "Epoch 44/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5373 - val_loss: 0.5329\n",
      "Epoch 45/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5372 - val_loss: 0.5328\n",
      "Epoch 46/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5372 - val_loss: 0.5328\n",
      "Epoch 47/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5371 - val_loss: 0.5331\n",
      "Epoch 48/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5372 - val_loss: 0.5334\n",
      "Epoch 49/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5373 - val_loss: 0.5330\n",
      "Epoch 50/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5373 - val_loss: 0.5330\n",
      "Epoch 51/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5372 - val_loss: 0.5331\n",
      "Epoch 52/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5372 - val_loss: 0.5330\n",
      "Epoch 53/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5372 - val_loss: 0.5327\n",
      "Epoch 54/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5372 - val_loss: 0.5329\n",
      "Epoch 55/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5372 - val_loss: 0.5327\n",
      "Epoch 56/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5372 - val_loss: 0.5331\n",
      "Epoch 57/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5372 - val_loss: 0.5332\n",
      "Epoch 58/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5372 - val_loss: 0.5328\n",
      "Epoch 59/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5372 - val_loss: 0.5333\n",
      "Epoch 60/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5372 - val_loss: 0.5330\n",
      "Epoch 61/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5372 - val_loss: 0.5328\n",
      "Epoch 62/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5372 - val_loss: 0.5328\n",
      "Epoch 63/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5371 - val_loss: 0.5326\n",
      "Epoch 64/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5371 - val_loss: 0.5329\n",
      "Epoch 65/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5372 - val_loss: 0.5329\n",
      "Epoch 66/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5372 - val_loss: 0.5328\n",
      "Epoch 67/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5372 - val_loss: 0.5323\n",
      "Epoch 68/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5372 - val_loss: 0.5328\n",
      "Epoch 69/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5372 - val_loss: 0.5331\n",
      "Epoch 70/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5372 - val_loss: 0.5327\n",
      "Epoch 71/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5372 - val_loss: 0.5331\n",
      "Epoch 72/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5372 - val_loss: 0.5328\n",
      "Epoch 73/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5371 - val_loss: 0.5329\n",
      "Epoch 74/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5372 - val_loss: 0.5332\n",
      "Epoch 75/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5372 - val_loss: 0.5330\n",
      "Epoch 76/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5372 - val_loss: 0.5327\n",
      "Epoch 77/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5372 - val_loss: 0.5329\n",
      "Epoch 78/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5372 - val_loss: 0.5330\n",
      "Epoch 79/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5326\n",
      "Epoch 80/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5372 - val_loss: 0.5329\n",
      "Epoch 81/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5331\n",
      "Epoch 82/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5372 - val_loss: 0.5327\n",
      "Epoch 83/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5326\n",
      "Epoch 84/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5330\n",
      "Epoch 85/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5372 - val_loss: 0.5330\n",
      "Epoch 86/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5330\n",
      "Epoch 87/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5327\n",
      "Epoch 88/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5329\n",
      "Epoch 89/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5329\n",
      "Epoch 90/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5372 - val_loss: 0.5330\n",
      "Epoch 91/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5329\n",
      "Epoch 92/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5372 - val_loss: 0.5326\n",
      "Epoch 93/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5371 - val_loss: 0.5327\n",
      "Epoch 94/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5372 - val_loss: 0.5329\n",
      "Epoch 95/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5332\n",
      "Epoch 96/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5328\n",
      "Epoch 97/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5372 - val_loss: 0.5329\n",
      "Epoch 98/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5328\n",
      "Epoch 99/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5324\n",
      "Epoch 100/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5330\n",
      "Epoch 101/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5327\n",
      "Epoch 102/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5372 - val_loss: 0.5327\n",
      "Epoch 103/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5371 - val_loss: 0.5330\n",
      "Epoch 104/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5329\n",
      "Epoch 105/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5326\n",
      "Epoch 106/500\n",
      "4909/4909 [==============================] - 60s 12ms/step - loss: 0.5371 - val_loss: 0.5329\n",
      "Epoch 107/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5330\n",
      "Epoch 108/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5328\n",
      "Epoch 109/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5324\n",
      "Epoch 110/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5330\n",
      "Epoch 111/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5327\n",
      "Epoch 112/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5371 - val_loss: 0.5327\n",
      "Epoch 113/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5371 - val_loss: 0.5328\n",
      "Epoch 114/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5371 - val_loss: 0.5327\n",
      "Epoch 115/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5371 - val_loss: 0.5330\n",
      "Epoch 116/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5371 - val_loss: 0.5328\n",
      "Epoch 117/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5329\n",
      "Epoch 118/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5331\n",
      "Epoch 119/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5326\n",
      "Epoch 120/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5330\n",
      "Epoch 121/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5323\n",
      "Epoch 122/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5324\n",
      "Epoch 123/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5324\n",
      "Epoch 124/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5370 - val_loss: 0.5325\n",
      "Epoch 125/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5330\n",
      "Epoch 126/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5330\n",
      "Epoch 127/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5327\n",
      "Epoch 128/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5329\n",
      "Epoch 129/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5329\n",
      "Epoch 130/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5327\n",
      "Epoch 131/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5370 - val_loss: 0.5330\n",
      "Epoch 132/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5327\n",
      "Epoch 133/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5324\n",
      "Epoch 134/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5370 - val_loss: 0.5327\n",
      "Epoch 135/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5329\n",
      "Epoch 136/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5327\n",
      "Epoch 137/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5328\n",
      "Epoch 138/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5326\n",
      "Epoch 139/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5327\n",
      "Epoch 140/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5325\n",
      "Epoch 141/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5370 - val_loss: 0.5326\n",
      "Epoch 142/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5370 - val_loss: 0.5325\n",
      "Epoch 143/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5371 - val_loss: 0.5325\n",
      "Epoch 144/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5370 - val_loss: 0.5329\n",
      "Epoch 145/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5328\n",
      "Epoch 146/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5326\n",
      "Epoch 147/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5370 - val_loss: 0.5330\n",
      "Epoch 148/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5370 - val_loss: 0.5327\n",
      "Epoch 149/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5371 - val_loss: 0.5328\n",
      "Epoch 150/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5323\n",
      "Epoch 151/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5370 - val_loss: 0.5327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5326\n",
      "Epoch 153/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5331\n",
      "Epoch 154/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5370 - val_loss: 0.5328\n",
      "Epoch 155/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5331\n",
      "Epoch 156/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5328\n",
      "Epoch 157/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5326\n",
      "Epoch 158/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5325\n",
      "Epoch 159/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5328\n",
      "Epoch 160/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5329\n",
      "Epoch 161/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5326\n",
      "Epoch 162/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5371 - val_loss: 0.5325\n",
      "Epoch 163/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5326\n",
      "Epoch 164/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5324\n",
      "Epoch 165/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5326\n",
      "Epoch 166/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5328\n",
      "Epoch 167/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5323\n",
      "Epoch 168/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5326\n",
      "Epoch 169/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5329\n",
      "Epoch 170/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5369 - val_loss: 0.5327\n",
      "Epoch 171/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5326\n",
      "Epoch 172/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5329\n",
      "Epoch 173/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5328\n",
      "Epoch 174/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5323\n",
      "Epoch 175/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5325\n",
      "Epoch 176/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5330\n",
      "Epoch 177/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5323\n",
      "Epoch 178/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5327\n",
      "Epoch 179/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5326\n",
      "Epoch 180/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5328\n",
      "Epoch 181/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5325\n",
      "Epoch 182/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5326\n",
      "Epoch 183/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5327\n",
      "Epoch 184/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5370 - val_loss: 0.5327\n",
      "Epoch 185/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5325\n",
      "Epoch 186/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5327\n",
      "Epoch 187/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5329\n",
      "Epoch 188/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5328\n",
      "Epoch 189/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5329\n",
      "Epoch 190/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5327\n",
      "Epoch 191/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5323\n",
      "Epoch 192/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5323\n",
      "Epoch 193/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5370 - val_loss: 0.5328\n",
      "Epoch 194/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5330\n",
      "Epoch 195/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5324\n",
      "Epoch 196/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5326\n",
      "Epoch 197/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5327\n",
      "Epoch 198/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5326\n",
      "Epoch 199/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5328\n",
      "Epoch 200/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5328\n",
      "Epoch 201/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5326\n",
      "Epoch 202/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5369 - val_loss: 0.5326\n",
      "Epoch 203/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5326\n",
      "Epoch 204/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5327\n",
      "Epoch 205/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5328\n",
      "Epoch 206/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5370 - val_loss: 0.5329\n",
      "Epoch 207/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5328\n",
      "Epoch 208/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5326\n",
      "Epoch 209/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5369 - val_loss: 0.5322\n",
      "Epoch 210/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5329\n",
      "Epoch 211/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5326\n",
      "Epoch 212/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5328\n",
      "Epoch 213/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5369 - val_loss: 0.5328\n",
      "Epoch 214/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5369 - val_loss: 0.5327\n",
      "Epoch 215/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5327\n",
      "Epoch 216/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5324\n",
      "Epoch 217/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5325\n",
      "Epoch 218/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5325\n",
      "Epoch 219/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5323\n",
      "Epoch 220/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5325\n",
      "Epoch 221/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5324\n",
      "Epoch 222/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5325\n",
      "Epoch 223/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5325\n",
      "Epoch 224/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5328\n",
      "Epoch 225/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5370 - val_loss: 0.5325\n",
      "Epoch 226/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5326\n",
      "Epoch 227/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5325\n",
      "Epoch 228/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5325\n",
      "Epoch 229/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5325\n",
      "Epoch 230/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5322\n",
      "Epoch 231/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5326\n",
      "Epoch 232/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5324\n",
      "Epoch 233/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5324\n",
      "Epoch 234/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5325\n",
      "Epoch 235/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5327\n",
      "Epoch 236/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5326\n",
      "Epoch 237/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5326\n",
      "Epoch 238/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5328\n",
      "Epoch 239/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5326\n",
      "Epoch 240/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5326\n",
      "Epoch 241/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5326\n",
      "Epoch 242/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5323\n",
      "Epoch 243/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5323\n",
      "Epoch 244/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5327\n",
      "Epoch 245/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5323\n",
      "Epoch 246/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5327\n",
      "Epoch 247/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5325\n",
      "Epoch 248/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5325\n",
      "Epoch 249/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5327\n",
      "Epoch 250/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5328\n",
      "Epoch 251/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5325\n",
      "Epoch 252/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5319\n",
      "Epoch 253/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5369 - val_loss: 0.5324\n",
      "Epoch 254/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5329\n",
      "Epoch 255/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5325\n",
      "Epoch 256/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5326\n",
      "Epoch 257/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5322\n",
      "Epoch 258/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5327\n",
      "Epoch 259/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5325\n",
      "Epoch 260/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5327\n",
      "Epoch 261/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5321\n",
      "Epoch 262/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5325\n",
      "Epoch 263/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5325\n",
      "Epoch 264/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5326\n",
      "Epoch 265/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5325\n",
      "Epoch 266/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5324\n",
      "Epoch 267/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5327\n",
      "Epoch 268/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5327\n",
      "Epoch 269/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5368 - val_loss: 0.5326\n",
      "Epoch 270/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5323\n",
      "Epoch 271/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5328\n",
      "Epoch 272/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5327\n",
      "Epoch 273/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5326\n",
      "Epoch 274/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5326\n",
      "Epoch 275/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5368 - val_loss: 0.5324\n",
      "Epoch 276/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5325\n",
      "Epoch 277/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5326\n",
      "Epoch 278/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5326\n",
      "Epoch 279/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5369 - val_loss: 0.5323\n",
      "Epoch 280/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5369 - val_loss: 0.5322\n",
      "Epoch 281/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5330\n",
      "Epoch 282/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5327\n",
      "Epoch 283/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5326\n",
      "Epoch 284/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5323\n",
      "Epoch 285/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5323\n",
      "Epoch 286/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5323\n",
      "Epoch 287/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5323\n",
      "Epoch 288/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5328\n",
      "Epoch 289/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5326\n",
      "Epoch 290/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5326\n",
      "Epoch 291/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5325\n",
      "Epoch 292/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5325\n",
      "Epoch 293/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5326\n",
      "Epoch 294/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5327\n",
      "Epoch 295/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5325\n",
      "Epoch 296/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5326\n",
      "Epoch 297/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5323\n",
      "Epoch 298/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5325\n",
      "Epoch 299/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5326\n",
      "Epoch 300/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5368 - val_loss: 0.5325\n",
      "Epoch 301/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5325\n",
      "Epoch 302/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5327\n",
      "Epoch 303/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5330\n",
      "Epoch 304/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5327\n",
      "Epoch 305/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5324\n",
      "Epoch 306/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5369 - val_loss: 0.5324\n",
      "Epoch 307/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5326\n",
      "Epoch 308/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5368 - val_loss: 0.5324\n",
      "Epoch 309/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5327\n",
      "Epoch 310/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5327\n",
      "Epoch 311/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5322\n",
      "Epoch 312/500\n",
      "4909/4909 [==============================] - 60s 12ms/step - loss: 0.5368 - val_loss: 0.5325\n",
      "Epoch 313/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5327\n",
      "Epoch 314/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5327\n",
      "Epoch 315/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5327\n",
      "Epoch 316/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5327\n",
      "Epoch 317/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5322\n",
      "Epoch 318/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5324\n",
      "Epoch 319/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5328\n",
      "Epoch 320/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5322\n",
      "Epoch 321/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5326\n",
      "Epoch 322/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5326\n",
      "Epoch 323/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5328\n",
      "Epoch 324/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5326\n",
      "Epoch 325/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5328\n",
      "Epoch 326/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5327\n",
      "Epoch 327/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5327\n",
      "Epoch 328/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5326\n",
      "Epoch 329/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5367 - val_loss: 0.5324\n",
      "Epoch 330/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5319\n",
      "Epoch 331/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5327\n",
      "Epoch 332/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5324\n",
      "Epoch 333/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5323\n",
      "Epoch 334/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5327\n",
      "Epoch 335/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5327\n",
      "Epoch 336/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5328\n",
      "Epoch 337/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5326\n",
      "Epoch 338/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5325\n",
      "Epoch 339/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5324\n",
      "Epoch 340/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5325\n",
      "Epoch 341/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5323\n",
      "Epoch 342/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5322\n",
      "Epoch 343/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5367 - val_loss: 0.5325\n",
      "Epoch 344/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5328\n",
      "Epoch 345/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5327\n",
      "Epoch 346/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5329\n",
      "Epoch 347/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5324\n",
      "Epoch 348/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5324\n",
      "Epoch 349/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5321\n",
      "Epoch 350/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5326\n",
      "Epoch 351/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5325\n",
      "Epoch 352/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5326\n",
      "Epoch 353/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5322\n",
      "Epoch 354/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5326\n",
      "Epoch 355/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5324\n",
      "Epoch 356/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5326\n",
      "Epoch 357/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5367 - val_loss: 0.5321\n",
      "Epoch 358/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5326\n",
      "Epoch 359/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5324\n",
      "Epoch 360/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5325\n",
      "Epoch 361/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5325\n",
      "Epoch 362/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5323\n",
      "Epoch 363/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5325\n",
      "Epoch 364/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5326\n",
      "Epoch 365/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5367 - val_loss: 0.5324\n",
      "Epoch 366/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5368 - val_loss: 0.5322\n",
      "Epoch 367/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5324\n",
      "Epoch 368/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5322\n",
      "Epoch 369/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5321\n",
      "Epoch 370/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5327\n",
      "Epoch 371/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5325\n",
      "Epoch 372/500\n",
      "4909/4909 [==============================] - 60s 12ms/step - loss: 0.5367 - val_loss: 0.5322\n",
      "Epoch 373/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5327\n",
      "Epoch 374/500\n",
      "4909/4909 [==============================] - 60s 12ms/step - loss: 0.5367 - val_loss: 0.5326\n",
      "Epoch 375/500\n",
      "4909/4909 [==============================] - 60s 12ms/step - loss: 0.5367 - val_loss: 0.5323\n",
      "Epoch 376/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5323\n",
      "Epoch 377/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5322\n",
      "Epoch 378/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5367 - val_loss: 0.5322\n",
      "Epoch 379/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5367 - val_loss: 0.5326\n",
      "Epoch 380/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5367 - val_loss: 0.5326\n",
      "Epoch 381/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5325\n",
      "Epoch 382/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5323\n",
      "Epoch 383/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5367 - val_loss: 0.5325\n",
      "Epoch 384/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5367 - val_loss: 0.5323\n",
      "Epoch 385/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5367 - val_loss: 0.5320\n",
      "Epoch 386/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5367 - val_loss: 0.5322\n",
      "Epoch 387/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5367 - val_loss: 0.5325\n",
      "Epoch 388/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5367 - val_loss: 0.5324\n",
      "Epoch 389/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5367 - val_loss: 0.5327\n",
      "Epoch 390/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5367 - val_loss: 0.5325\n",
      "Epoch 391/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5367 - val_loss: 0.5325\n",
      "Epoch 392/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5324\n",
      "Epoch 393/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5367 - val_loss: 0.5322\n",
      "Epoch 394/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5367 - val_loss: 0.5323\n",
      "Epoch 395/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5367 - val_loss: 0.5325\n",
      "Epoch 396/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5367 - val_loss: 0.5322\n",
      "Epoch 397/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5324\n",
      "Epoch 398/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5324\n",
      "Epoch 399/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5323\n",
      "Epoch 400/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5324\n",
      "Epoch 401/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5367 - val_loss: 0.5324\n",
      "Epoch 402/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5325\n",
      "Epoch 403/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5321\n",
      "Epoch 404/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5324\n",
      "Epoch 405/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5366 - val_loss: 0.5323\n",
      "Epoch 406/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5325\n",
      "Epoch 407/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5323\n",
      "Epoch 408/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5322\n",
      "Epoch 409/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5320\n",
      "Epoch 410/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5323\n",
      "Epoch 411/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5366 - val_loss: 0.5325\n",
      "Epoch 412/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5325\n",
      "Epoch 413/500\n",
      "4909/4909 [==============================] - 60s 12ms/step - loss: 0.5366 - val_loss: 0.5323\n",
      "Epoch 414/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5323\n",
      "Epoch 415/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5325\n",
      "Epoch 416/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5322\n",
      "Epoch 417/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5367 - val_loss: 0.5325\n",
      "Epoch 418/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5367 - val_loss: 0.5326\n",
      "Epoch 419/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5366 - val_loss: 0.5324\n",
      "Epoch 420/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5366 - val_loss: 0.5319\n",
      "Epoch 421/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5367 - val_loss: 0.5322\n",
      "Epoch 422/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5367 - val_loss: 0.5324\n",
      "Epoch 423/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5367 - val_loss: 0.5324\n",
      "Epoch 424/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5366 - val_loss: 0.5322\n",
      "Epoch 425/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5323\n",
      "Epoch 426/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5366 - val_loss: 0.5325\n",
      "Epoch 427/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5366 - val_loss: 0.5320\n",
      "Epoch 428/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5366 - val_loss: 0.5324\n",
      "Epoch 429/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5326\n",
      "Epoch 430/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5366 - val_loss: 0.5322\n",
      "Epoch 431/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5367 - val_loss: 0.5321\n",
      "Epoch 432/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5367 - val_loss: 0.5326\n",
      "Epoch 433/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5323\n",
      "Epoch 434/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5327\n",
      "Epoch 435/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5322\n",
      "Epoch 436/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5320\n",
      "Epoch 437/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5367 - val_loss: 0.5323\n",
      "Epoch 438/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5322\n",
      "Epoch 439/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5325\n",
      "Epoch 440/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5324\n",
      "Epoch 441/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5322\n",
      "Epoch 442/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5324\n",
      "Epoch 443/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5366 - val_loss: 0.5323\n",
      "Epoch 444/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5367 - val_loss: 0.5323\n",
      "Epoch 445/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5323\n",
      "Epoch 446/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5331\n",
      "Epoch 447/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5367 - val_loss: 0.5322\n",
      "Epoch 448/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5323\n",
      "Epoch 449/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5325\n",
      "Epoch 450/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5321\n",
      "Epoch 451/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5367 - val_loss: 0.5322\n",
      "Epoch 452/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5323\n",
      "Epoch 453/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5323\n",
      "Epoch 454/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5326\n",
      "Epoch 455/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5323\n",
      "Epoch 456/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5323\n",
      "Epoch 457/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5321\n",
      "Epoch 458/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5367 - val_loss: 0.5323\n",
      "Epoch 459/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5326\n",
      "Epoch 460/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5367 - val_loss: 0.5322\n",
      "Epoch 461/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5326\n",
      "Epoch 462/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5321\n",
      "Epoch 463/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5326\n",
      "Epoch 464/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5320\n",
      "Epoch 465/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5367 - val_loss: 0.5323\n",
      "Epoch 466/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5367 - val_loss: 0.5324\n",
      "Epoch 467/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5322\n",
      "Epoch 468/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5324\n",
      "Epoch 469/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5366 - val_loss: 0.5324\n",
      "Epoch 470/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5324\n",
      "Epoch 471/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5323\n",
      "Epoch 472/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5322\n",
      "Epoch 473/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5322\n",
      "Epoch 474/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5366 - val_loss: 0.5321\n",
      "Epoch 475/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5325\n",
      "Epoch 476/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5322\n",
      "Epoch 477/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5365 - val_loss: 0.5327\n",
      "Epoch 478/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5322\n",
      "Epoch 479/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5323\n",
      "Epoch 480/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5321\n",
      "Epoch 481/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5366 - val_loss: 0.5321\n",
      "Epoch 482/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5322\n",
      "Epoch 483/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5324\n",
      "Epoch 484/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5325\n",
      "Epoch 485/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5323\n",
      "Epoch 486/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5322\n",
      "Epoch 487/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5323\n",
      "Epoch 488/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5365 - val_loss: 0.5325\n",
      "Epoch 489/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5320\n",
      "Epoch 490/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5322\n",
      "Epoch 491/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5366 - val_loss: 0.5325\n",
      "Epoch 492/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5321\n",
      "Epoch 493/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5323\n",
      "Epoch 494/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5320\n",
      "Epoch 495/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5366 - val_loss: 0.5323\n",
      "Epoch 496/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5326\n",
      "Epoch 497/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5324\n",
      "Epoch 498/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5324\n",
      "Epoch 499/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5319\n",
      "Epoch 500/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5366 - val_loss: 0.5324\n"
     ]
    }
   ],
   "source": [
    "%%wandb\n",
    "\n",
    "model_version = 'patch_desc_ae_' + datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + '16_alex_3conv3mp_2020_augm_elu_lastelu_NOTdwnsmpl_500moreepochs'\n",
    "\n",
    "os.system('mkdir ' + base_dir + '/weights_' + model_version)\n",
    "print(base_dir + '/weights_' + model_version)\n",
    "\n",
    "# checkpointer = ModelCheckpoint(base_dir + '/weights' + model_version + '/weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "history_callback = autoencoder.fit(image_datagen.flow(x_train, y_train, batch_size),\n",
    "                epochs=500,#wandb.config.epochs,\n",
    "                validation_data=image_datagen.flow(x_validation, y_validation, batch_size),\n",
    "                callbacks=[WandbCallback(data_type=\"image\", predictions=1)]\n",
    "                )\n",
    "autoencoder.save(base_dir + '/' + model_version + '.h5')\n",
    "\n",
    "# autoencoder = load_model(base_dir + '/' + model_version + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.5373435755432614,\n",
       "  0.5373800206262248,\n",
       "  0.5373584119542304,\n",
       "  0.5373311023749161,\n",
       "  0.5373463065569325,\n",
       "  0.5374247160637902,\n",
       "  0.5373397593301347,\n",
       "  0.5373659492769903,\n",
       "  0.5373262869619335,\n",
       "  0.5373255755381565,\n",
       "  0.5373322435618191,\n",
       "  0.5373605004006443,\n",
       "  0.5373842533065354,\n",
       "  0.5373109773932319,\n",
       "  0.5373075901103612,\n",
       "  0.5372797005185772,\n",
       "  0.5373263320495997,\n",
       "  0.5372873707730589,\n",
       "  0.5373090409681446,\n",
       "  0.5372899403052159,\n",
       "  0.5372951971009025,\n",
       "  0.5373098743498714,\n",
       "  0.5372720264272026,\n",
       "  0.5372631904698477,\n",
       "  0.5372953976590009,\n",
       "  0.5372433258876771,\n",
       "  0.5372648283841313,\n",
       "  0.5372255572386425,\n",
       "  0.5372599915089081,\n",
       "  0.5372577717726076,\n",
       "  0.537279012511534,\n",
       "  0.5373297580159555,\n",
       "  0.5372395601172472,\n",
       "  0.5372635390556714,\n",
       "  0.537280502683431,\n",
       "  0.5372785964291019,\n",
       "  0.5372627720732137,\n",
       "  0.5372129588996326,\n",
       "  0.53725750047521,\n",
       "  0.5373044582715233,\n",
       "  0.5372284339775995,\n",
       "  0.5372233747526837,\n",
       "  0.5372349500209148,\n",
       "  0.5372533811353971,\n",
       "  0.5371964296630233,\n",
       "  0.5371897961159993,\n",
       "  0.5371373606757494,\n",
       "  0.5371946003400677,\n",
       "  0.5372525557029293,\n",
       "  0.5372836273398572,\n",
       "  0.5371922468604241,\n",
       "  0.5372003839762182,\n",
       "  0.537247494629384,\n",
       "  0.5372357184630765,\n",
       "  0.5372128298768973,\n",
       "  0.5372369219262583,\n",
       "  0.5371517825656801,\n",
       "  0.5372338055772821,\n",
       "  0.5372257531542979,\n",
       "  0.5371969772136787,\n",
       "  0.5372113132129088,\n",
       "  0.5371729473495311,\n",
       "  0.537147857160848,\n",
       "  0.5371366460183882,\n",
       "  0.5371901066151963,\n",
       "  0.537196173701435,\n",
       "  0.5371905853605561,\n",
       "  0.5372130709849442,\n",
       "  0.5371975221135692,\n",
       "  0.5371540584328561,\n",
       "  0.5371844015063421,\n",
       "  0.5371932624638321,\n",
       "  0.5371487471621685,\n",
       "  0.5371597314896908,\n",
       "  0.5371607496194075,\n",
       "  0.537191016074937,\n",
       "  0.5371887584838474,\n",
       "  0.5371565758376047,\n",
       "  0.53712217961716,\n",
       "  0.537182695260683,\n",
       "  0.5371425210270029,\n",
       "  0.5371719188254468,\n",
       "  0.5371089487227855,\n",
       "  0.5371120186545393,\n",
       "  0.5371908742320769,\n",
       "  0.5371355890822481,\n",
       "  0.5371429101024439,\n",
       "  0.537150143156784,\n",
       "  0.5371265882246286,\n",
       "  0.5371657865974016,\n",
       "  0.5371330878245506,\n",
       "  0.5371542095446662,\n",
       "  0.5370658678461362,\n",
       "  0.5371601910141596,\n",
       "  0.5371044888363352,\n",
       "  0.5371265286362997,\n",
       "  0.5371552480297982,\n",
       "  0.5371192989221661,\n",
       "  0.5370966979933012,\n",
       "  0.5371131270669697,\n",
       "  0.5371215498396725,\n",
       "  0.5371582149706482,\n",
       "  0.5371301241882399,\n",
       "  0.5370963307735795,\n",
       "  0.5371268058286705,\n",
       "  0.5370932379870419,\n",
       "  0.5371227822798956,\n",
       "  0.5371076977799505,\n",
       "  0.5370835926349916,\n",
       "  0.5370667966736111,\n",
       "  0.5371148025939598,\n",
       "  0.5371155574992353,\n",
       "  0.5370810018735699,\n",
       "  0.53707278329172,\n",
       "  0.5370726690170422,\n",
       "  0.5371369678286789,\n",
       "  0.5370973812076432,\n",
       "  0.5370578241297725,\n",
       "  0.5370523720699285,\n",
       "  0.5370771103997422,\n",
       "  0.5370777564749182,\n",
       "  0.537103088042568,\n",
       "  0.5371037024622387,\n",
       "  0.5370054948309132,\n",
       "  0.5370146297346685,\n",
       "  0.5371166240492359,\n",
       "  0.5370571203399402,\n",
       "  0.5370378892401051,\n",
       "  0.5369930927183196,\n",
       "  0.5370581107474223,\n",
       "  0.5370499143111837,\n",
       "  0.5370896213227044,\n",
       "  0.5370650300116859,\n",
       "  0.5370499674220996,\n",
       "  0.5370442017478596,\n",
       "  0.5370241165754577,\n",
       "  0.5370374905121007,\n",
       "  0.5370558015688667,\n",
       "  0.5370232203972403,\n",
       "  0.5370213754246789,\n",
       "  0.5370091290993497,\n",
       "  0.5370286986243756,\n",
       "  0.53705081442381,\n",
       "  0.5370125634475256,\n",
       "  0.5370240260521792,\n",
       "  0.5370232385071322,\n",
       "  0.5370189949991341,\n",
       "  0.5370079704696096,\n",
       "  0.5370674565569726,\n",
       "  0.5370841430663522,\n",
       "  0.5370007692570795,\n",
       "  0.5370257924207975,\n",
       "  0.5370138176262212,\n",
       "  0.5369898627040455,\n",
       "  0.5370478760300963,\n",
       "  0.5369796168410614,\n",
       "  0.5370192559689453,\n",
       "  0.5370134904654531,\n",
       "  0.5370034194626431,\n",
       "  0.5370112985834321,\n",
       "  0.5369983178251102,\n",
       "  0.537057690104506,\n",
       "  0.5370230421786466,\n",
       "  0.5369449689952639,\n",
       "  0.5370132103973099,\n",
       "  0.5370192890697358,\n",
       "  0.5369706754249277,\n",
       "  0.5370031272801326,\n",
       "  0.5370283936217403,\n",
       "  0.5369369451926478,\n",
       "  0.5369809222790078,\n",
       "  0.5369802332417861,\n",
       "  0.5369436632769116,\n",
       "  0.5369744606943777,\n",
       "  0.5369880503298966,\n",
       "  0.5369916555844861,\n",
       "  0.5369500383792947,\n",
       "  0.5369736119138547,\n",
       "  0.5370212107748444,\n",
       "  0.5370055938908231,\n",
       "  0.5369883297093571,\n",
       "  0.5369752701281554,\n",
       "  0.5369830315509627,\n",
       "  0.5369943630615205,\n",
       "  0.5368953151221781,\n",
       "  0.5369646654955691,\n",
       "  0.5369383814685684,\n",
       "  0.5370265035049762,\n",
       "  0.5369804409724309,\n",
       "  0.5369364113173741,\n",
       "  0.5369744592506102,\n",
       "  0.5369690022034124,\n",
       "  0.5369767175804686,\n",
       "  0.536868622912298,\n",
       "  0.536902254642444,\n",
       "  0.5369552355600915,\n",
       "  0.5369356347495139,\n",
       "  0.5369132936365845,\n",
       "  0.5369584884765795,\n",
       "  0.5369405656965344,\n",
       "  0.5369424575317802,\n",
       "  0.5369161485554893,\n",
       "  0.5369933993650667,\n",
       "  0.5369253660484414,\n",
       "  0.5369725186141231,\n",
       "  0.5370180333125716,\n",
       "  0.5369432183938775,\n",
       "  0.5369053887085923,\n",
       "  0.536890055360792,\n",
       "  0.5369006408696239,\n",
       "  0.5368876672546313,\n",
       "  0.536878259440481,\n",
       "  0.5369320900656224,\n",
       "  0.5368770941276716,\n",
       "  0.5368668340474662,\n",
       "  0.5368455825267643,\n",
       "  0.5368494649555114,\n",
       "  0.5369333732612005,\n",
       "  0.5368701314608328,\n",
       "  0.5368864137930764,\n",
       "  0.5368495407003774,\n",
       "  0.5368892158097571,\n",
       "  0.5369024225596327,\n",
       "  0.5368442844727119,\n",
       "  0.5369544496925469,\n",
       "  0.5368911799961613,\n",
       "  0.5368824482367076,\n",
       "  0.5369287298713222,\n",
       "  0.5368925547000429,\n",
       "  0.5368363462572449,\n",
       "  0.5368143590961735,\n",
       "  0.5369031683287622,\n",
       "  0.536819786497378,\n",
       "  0.5369141707096399,\n",
       "  0.5368711927533187,\n",
       "  0.5368681848910491,\n",
       "  0.5368753243342317,\n",
       "  0.5368912830705419,\n",
       "  0.5368485742047978,\n",
       "  0.5368800690079152,\n",
       "  0.5368565233094217,\n",
       "  0.5368265585724781,\n",
       "  0.5368058816340862,\n",
       "  0.536874718224667,\n",
       "  0.5368639443791059,\n",
       "  0.5368926188192598,\n",
       "  0.5368752480376606,\n",
       "  0.5368490402909152,\n",
       "  0.5369003239628307,\n",
       "  0.5368653275949554,\n",
       "  0.5368576290316255,\n",
       "  0.5368892319606026,\n",
       "  0.5368907475583659,\n",
       "  0.5368574491268024,\n",
       "  0.5368493959043391,\n",
       "  0.5368682425943222,\n",
       "  0.5368152222832583,\n",
       "  0.5368816329663905,\n",
       "  0.5368516098549451,\n",
       "  0.5368030445461852,\n",
       "  0.5368380684864166,\n",
       "  0.5368152674468123,\n",
       "  0.536861536054887,\n",
       "  0.5368155547004028,\n",
       "  0.5368828350009822,\n",
       "  0.5368431305222207,\n",
       "  0.5368922576508405,\n",
       "  0.5368340018943959,\n",
       "  0.5368472976057767,\n",
       "  0.5368514905367564,\n",
       "  0.5368158972869074,\n",
       "  0.5368366561724844,\n",
       "  0.5368445292040273,\n",
       "  0.5368510282359282,\n",
       "  0.5368319837774863,\n",
       "  0.536845264601176,\n",
       "  0.5368102237030312,\n",
       "  0.5368129753908468,\n",
       "  0.5368506926747474,\n",
       "  0.536855851666469,\n",
       "  0.5368256583065582,\n",
       "  0.5368134942239976,\n",
       "  0.5367656998954706,\n",
       "  0.5368013286047066,\n",
       "  0.5368176793939203,\n",
       "  0.5368208455580004,\n",
       "  0.5368022106112355,\n",
       "  0.5368044855874874,\n",
       "  0.5367472700562848,\n",
       "  0.5367756450112341,\n",
       "  0.5367963136402788,\n",
       "  0.5368004312217687,\n",
       "  0.5367556642162082,\n",
       "  0.536851693587014,\n",
       "  0.5367637470858032,\n",
       "  0.5367831857952419,\n",
       "  0.5367960984077342,\n",
       "  0.5367820144106406,\n",
       "  0.5367646444607729,\n",
       "  0.5368086573666081,\n",
       "  0.5367682138158255,\n",
       "  0.5367844014035255,\n",
       "  0.5367718616795819,\n",
       "  0.5367654646247223,\n",
       "  0.536778993232698,\n",
       "  0.5368628266434657,\n",
       "  0.5367324988747727,\n",
       "  0.5367709426477191,\n",
       "  0.5367562537651327,\n",
       "  0.5367894482275971,\n",
       "  0.5367340393307608,\n",
       "  0.536791496433306,\n",
       "  0.5367518427117967,\n",
       "  0.5367590894798419,\n",
       "  0.536766388689851,\n",
       "  0.5368466769143492,\n",
       "  0.5367058385397138,\n",
       "  0.5367269251085472,\n",
       "  0.5367478934220024,\n",
       "  0.536774103673808,\n",
       "  0.5367857878271572,\n",
       "  0.5367536804021538,\n",
       "  0.5367358084104749,\n",
       "  0.5367916566357293,\n",
       "  0.5367878269077239,\n",
       "  0.5367529928337427,\n",
       "  0.5367741207595924,\n",
       "  0.5367909446219237,\n",
       "  0.5367448613932263,\n",
       "  0.5366919768703051,\n",
       "  0.5367398439404337,\n",
       "  0.5367931883976185,\n",
       "  0.5367493977329562,\n",
       "  0.5367948913554336,\n",
       "  0.5367179139965733,\n",
       "  0.5367265696518319,\n",
       "  0.5367650636307049,\n",
       "  0.5367505295272119,\n",
       "  0.5367116035825663,\n",
       "  0.5367728866972652,\n",
       "  0.5367157392519407,\n",
       "  0.5366990012192203,\n",
       "  0.5367405604308674,\n",
       "  0.5366840467676356,\n",
       "  0.536721897183602,\n",
       "  0.536700424439384,\n",
       "  0.5367546876097024,\n",
       "  0.5366698555439541,\n",
       "  0.536733782213779,\n",
       "  0.5367350678282844,\n",
       "  0.5367130634831536,\n",
       "  0.5367492787418443,\n",
       "  0.5367646817816905,\n",
       "  0.5367073307613434,\n",
       "  0.536715480988672,\n",
       "  0.5367313460595646,\n",
       "  0.5367246945601161,\n",
       "  0.5367036063289577,\n",
       "  0.5367709891727024,\n",
       "  0.5367011193746145,\n",
       "  0.5367265078134263,\n",
       "  0.5367071364681717,\n",
       "  0.5366883759713025,\n",
       "  0.5366920029738506,\n",
       "  0.5366952568438702,\n",
       "  0.5367897443429989,\n",
       "  0.5367002783384531,\n",
       "  0.5366686032393104,\n",
       "  0.5366960463380983,\n",
       "  0.5367255914998686,\n",
       "  0.5367172401798113,\n",
       "  0.5366897819224125,\n",
       "  0.5366809118765857,\n",
       "  0.5367112675706113,\n",
       "  0.5367502108025238,\n",
       "  0.5367420900128762,\n",
       "  0.5366873530853108,\n",
       "  0.5366780575754085,\n",
       "  0.5366681815775989,\n",
       "  0.5366804889399572,\n",
       "  0.5367196967391475,\n",
       "  0.5366801203588064,\n",
       "  0.5366534586589033,\n",
       "  0.5367185514880674,\n",
       "  0.536703318395791,\n",
       "  0.536714311196199,\n",
       "  0.5367024753573271,\n",
       "  0.5366510885897822,\n",
       "  0.5367335473771094,\n",
       "  0.5366950359891695,\n",
       "  0.5366655916130002,\n",
       "  0.5366930565030028,\n",
       "  0.5367327950303951,\n",
       "  0.5367366244260114,\n",
       "  0.5366898228574919,\n",
       "  0.5366868951226152,\n",
       "  0.536690432832787,\n",
       "  0.5366980755555126,\n",
       "  0.5367066834400878,\n",
       "  0.5366811535640368,\n",
       "  0.5366799950671005,\n",
       "  0.536695853498939,\n",
       "  0.5366798736733773,\n",
       "  0.5366902749586049,\n",
       "  0.5366331641561394,\n",
       "  0.5366974682343973,\n",
       "  0.5366597287616295,\n",
       "  0.5366708320988561,\n",
       "  0.5366509112765314,\n",
       "  0.5366522225954118,\n",
       "  0.5366299189646617,\n",
       "  0.5367078754369851,\n",
       "  0.536648799583752,\n",
       "  0.536693234447641,\n",
       "  0.5366763612741018,\n",
       "  0.5367117175969487,\n",
       "  0.536684469761939,\n",
       "  0.536683226561189,\n",
       "  0.5366437569505905,\n",
       "  0.536643278265941,\n",
       "  0.5366628734820615,\n",
       "  0.5367158991993806,\n",
       "  0.5366594188027545,\n",
       "  0.536648051193454,\n",
       "  0.5366664923323504,\n",
       "  0.5366264991778589,\n",
       "  0.5366234199073382,\n",
       "  0.5366292641995606,\n",
       "  0.5366778366288835,\n",
       "  0.5366091912242437,\n",
       "  0.5367133610495323,\n",
       "  0.5366773906200523,\n",
       "  0.5366859052323094,\n",
       "  0.5366344333894795,\n",
       "  0.5366079142116333,\n",
       "  0.5365998227333134,\n",
       "  0.5366917884334038,\n",
       "  0.5366481657352573,\n",
       "  0.5366323885368781,\n",
       "  0.5366282709261714,\n",
       "  0.5366096190882745,\n",
       "  0.5366618222617991,\n",
       "  0.536613908442818,\n",
       "  0.5366537498434878,\n",
       "  0.5365941755504633,\n",
       "  0.5365677391917545,\n",
       "  0.5366559335527599,\n",
       "  0.5365928566841504,\n",
       "  0.5366076226149775,\n",
       "  0.5365998560530406,\n",
       "  0.5366676541171306,\n",
       "  0.5366410639161646,\n",
       "  0.5366417446797064,\n",
       "  0.5366384671470761,\n",
       "  0.5366072918768531,\n",
       "  0.5365923545463408,\n",
       "  0.5365664690652135,\n",
       "  0.5366617064864377,\n",
       "  0.5366042309507181,\n",
       "  0.5367087432532327,\n",
       "  0.5366466310516834,\n",
       "  0.5365675921171815,\n",
       "  0.5366202402780861,\n",
       "  0.5365843420164951,\n",
       "  0.5366855990279888,\n",
       "  0.5366518163875151,\n",
       "  0.5366232010864337,\n",
       "  0.5365889598651573,\n",
       "  0.5366083090378606,\n",
       "  0.5365577355994201,\n",
       "  0.5366478547541721,\n",
       "  0.5365893241225942,\n",
       "  0.5366144238355901,\n",
       "  0.5366269907046407,\n",
       "  0.536607097030838,\n",
       "  0.5365564933681383,\n",
       "  0.536539740157835,\n",
       "  0.5365964209304286,\n",
       "  0.5366314172243132,\n",
       "  0.5365575921522895,\n",
       "  0.5366142011736187,\n",
       "  0.5365792894302541,\n",
       "  0.5365842560510449,\n",
       "  0.5365637066089027,\n",
       "  0.536597811289987,\n",
       "  0.5365829853473764,\n",
       "  0.5366341982944116,\n",
       "  0.5365481430752238,\n",
       "  0.5365914361090598,\n",
       "  0.5365674551023105,\n",
       "  0.5365696776931351,\n",
       "  0.5366130864507288,\n",
       "  0.5365833905797338,\n",
       "  0.5366229347338926,\n",
       "  0.5366152035778416,\n",
       "  0.5365715732624458,\n",
       "  0.5365845501372037,\n",
       "  0.536566633071898,\n",
       "  0.5366446031262609,\n",
       "  0.5366070241837521],\n",
       " 'val_loss': [0.5330026370238482,\n",
       "  0.5332856214627987,\n",
       "  0.5330344816533531,\n",
       "  0.5329220847385686,\n",
       "  0.5330023797062354,\n",
       "  0.5328087629826088,\n",
       "  0.5333845125950449,\n",
       "  0.5329211664393665,\n",
       "  0.5331397499979996,\n",
       "  0.5330003487869976,\n",
       "  0.532845345939078,\n",
       "  0.532954562001112,\n",
       "  0.5328833846057334,\n",
       "  0.5332247702086844,\n",
       "  0.5330301457788886,\n",
       "  0.5329421060841258,\n",
       "  0.5329368017553314,\n",
       "  0.5329027864021983,\n",
       "  0.533117798528051,\n",
       "  0.5329711015631513,\n",
       "  0.5327960008043584,\n",
       "  0.5330683664093173,\n",
       "  0.5325612585719038,\n",
       "  0.532968895706704,\n",
       "  0.5328860871675538,\n",
       "  0.5327381765454765,\n",
       "  0.5331454565369986,\n",
       "  0.5328762228411388,\n",
       "  0.5329506923028124,\n",
       "  0.5332382192941216,\n",
       "  0.5329633977839617,\n",
       "  0.5328185449286205,\n",
       "  0.5329346315162938,\n",
       "  0.5326853426006751,\n",
       "  0.532785209940701,\n",
       "  0.5326894955421851,\n",
       "  0.532659492841581,\n",
       "  0.5331878727529107,\n",
       "  0.5331560690713123,\n",
       "  0.5326487671553604,\n",
       "  0.5327681249719325,\n",
       "  0.532943003788227,\n",
       "  0.5327416408837327,\n",
       "  0.5329477309696073,\n",
       "  0.5327822745330935,\n",
       "  0.5327521707953476,\n",
       "  0.5331339111657647,\n",
       "  0.533391697135398,\n",
       "  0.5329993403539425,\n",
       "  0.5330334829121102,\n",
       "  0.533058839842556,\n",
       "  0.5329684680554925,\n",
       "  0.5326857990850278,\n",
       "  0.5328767973233045,\n",
       "  0.5326993467846537,\n",
       "  0.5331142760389219,\n",
       "  0.5332485296861912,\n",
       "  0.5327629509980116,\n",
       "  0.5332650421111564,\n",
       "  0.5330483465175319,\n",
       "  0.5328263528947907,\n",
       "  0.5327841440836588,\n",
       "  0.5325920431594539,\n",
       "  0.5328801659549155,\n",
       "  0.5328661397220643,\n",
       "  0.5328038230659516,\n",
       "  0.5323074607829738,\n",
       "  0.5328473601399398,\n",
       "  0.5331212177993806,\n",
       "  0.5326565431385506,\n",
       "  0.5330610289806272,\n",
       "  0.5327906363863286,\n",
       "  0.5328972933253622,\n",
       "  0.5331617482309419,\n",
       "  0.532988913660127,\n",
       "  0.5327434098817468,\n",
       "  0.5329494573236481,\n",
       "  0.5330266925862165,\n",
       "  0.5325719588171176,\n",
       "  0.5329036448544603,\n",
       "  0.533111981986984,\n",
       "  0.5327166910093974,\n",
       "  0.53261701774791,\n",
       "  0.5329572987265703,\n",
       "  0.5329657616169472,\n",
       "  0.5330227194278221,\n",
       "  0.5326557043122082,\n",
       "  0.5329280442338649,\n",
       "  0.5329340609108529,\n",
       "  0.532974970534565,\n",
       "  0.5329276817600902,\n",
       "  0.5325936091140033,\n",
       "  0.5327198558706578,\n",
       "  0.5329339181989189,\n",
       "  0.5331537214721122,\n",
       "  0.5328421149311996,\n",
       "  0.5328772690722613,\n",
       "  0.53279274193252,\n",
       "  0.5323705796788378,\n",
       "  0.5329578320185343,\n",
       "  0.5326938163943407,\n",
       "  0.5327441968568941,\n",
       "  0.5330286166532253,\n",
       "  0.5328969260056814,\n",
       "  0.5326116632639877,\n",
       "  0.5328971675740994,\n",
       "  0.5330252395412787,\n",
       "  0.5327869949302053,\n",
       "  0.5324484255255723,\n",
       "  0.5330069564222321,\n",
       "  0.5326594969606012,\n",
       "  0.5327214862757582,\n",
       "  0.5327905426180459,\n",
       "  0.5327370811284073,\n",
       "  0.5329874647342092,\n",
       "  0.5328419252139766,\n",
       "  0.5329128036169501,\n",
       "  0.5330713686904287,\n",
       "  0.5326063601466698,\n",
       "  0.5330408184024377,\n",
       "  0.5323393795548416,\n",
       "  0.5324176164661966,\n",
       "  0.5324435643548888,\n",
       "  0.5324980076250991,\n",
       "  0.5329926639068417,\n",
       "  0.532982789404024,\n",
       "  0.5326529411765618,\n",
       "  0.5328502153478017,\n",
       "  0.5329273568420876,\n",
       "  0.5327283551053303,\n",
       "  0.5329732652602157,\n",
       "  0.5327203465186483,\n",
       "  0.5324141424361283,\n",
       "  0.5327266491040951,\n",
       "  0.5328803290196551,\n",
       "  0.5327442164828138,\n",
       "  0.5328282636355578,\n",
       "  0.5326410825174999,\n",
       "  0.5327479340196625,\n",
       "  0.5324832026551409,\n",
       "  0.5325859358640221,\n",
       "  0.5325284576028343,\n",
       "  0.5324523533747448,\n",
       "  0.5328968281183786,\n",
       "  0.5327520716965684,\n",
       "  0.5326353481145409,\n",
       "  0.5329747124900662,\n",
       "  0.5327440623830004,\n",
       "  0.5327662840122129,\n",
       "  0.5323306455360195,\n",
       "  0.5327243574751102,\n",
       "  0.532575379542219,\n",
       "  0.5330560558695134,\n",
       "  0.5328361295103058,\n",
       "  0.5330797605882815,\n",
       "  0.5327771727631732,\n",
       "  0.5325884300518812,\n",
       "  0.5325404311098704,\n",
       "  0.5327557831760344,\n",
       "  0.5329114673583488,\n",
       "  0.5326239936720065,\n",
       "  0.5324971089518167,\n",
       "  0.5326000871212502,\n",
       "  0.532435501736354,\n",
       "  0.5325513610510322,\n",
       "  0.5327851590586872,\n",
       "  0.5323431169599052,\n",
       "  0.5325913722437572,\n",
       "  0.5328897736906036,\n",
       "  0.5327483771777735,\n",
       "  0.5326374056862622,\n",
       "  0.5328692490977001,\n",
       "  0.5328255186720592,\n",
       "  0.532288955963724,\n",
       "  0.5324910750718621,\n",
       "  0.5330383133112899,\n",
       "  0.5323430837654486,\n",
       "  0.5326955349949317,\n",
       "  0.532620917248532,\n",
       "  0.5328144004674462,\n",
       "  0.5325411916748295,\n",
       "  0.5325908040612694,\n",
       "  0.5327310789891375,\n",
       "  0.5327219374296142,\n",
       "  0.5325344343010973,\n",
       "  0.5327055606900192,\n",
       "  0.5328874789117798,\n",
       "  0.532788768289535,\n",
       "  0.5328564898269933,\n",
       "  0.532675963591754,\n",
       "  0.5323443342515124,\n",
       "  0.5323401437542303,\n",
       "  0.5327853785782326,\n",
       "  0.5330301198532911,\n",
       "  0.5324160030217675,\n",
       "  0.5326259938197407,\n",
       "  0.5327128690432726,\n",
       "  0.53258763605017,\n",
       "  0.5327572800764223,\n",
       "  0.5327943270283986,\n",
       "  0.5325573290266642,\n",
       "  0.5325904151773065,\n",
       "  0.532566094786171,\n",
       "  0.5326593898660769,\n",
       "  0.5328028630919572,\n",
       "  0.532865234749104,\n",
       "  0.5327874926047597,\n",
       "  0.5325624811940077,\n",
       "  0.5321952235407945,\n",
       "  0.5329299154804974,\n",
       "  0.5325671633084615,\n",
       "  0.5327933437940551,\n",
       "  0.5328342800702506,\n",
       "  0.5326877178215399,\n",
       "  0.5327421690874953,\n",
       "  0.532393219509745,\n",
       "  0.5324789595797779,\n",
       "  0.5325148437565904,\n",
       "  0.5323122839132944,\n",
       "  0.5324807307584499,\n",
       "  0.5324305152989984,\n",
       "  0.5325474436205577,\n",
       "  0.5324660277948147,\n",
       "  0.5327617097191695,\n",
       "  0.5324574735591082,\n",
       "  0.5326158554573369,\n",
       "  0.5325384176358944,\n",
       "  0.5324943853103048,\n",
       "  0.532501135415178,\n",
       "  0.5322335648342846,\n",
       "  0.5325506002437778,\n",
       "  0.5323526309273108,\n",
       "  0.5323957808134032,\n",
       "  0.5325091454556318,\n",
       "  0.5326644909091112,\n",
       "  0.5326454055503131,\n",
       "  0.5326119283350502,\n",
       "  0.5327508044921285,\n",
       "  0.5325688702788779,\n",
       "  0.5326478600017424,\n",
       "  0.5326306863528926,\n",
       "  0.5322872487510123,\n",
       "  0.5323085901213855,\n",
       "  0.532709194634988,\n",
       "  0.5322937100398831,\n",
       "  0.5326936608407555,\n",
       "  0.5325238382428642,\n",
       "  0.5324619155589158,\n",
       "  0.5326580160517034,\n",
       "  0.5327670993359108,\n",
       "  0.5325363554605623,\n",
       "  0.5318634132059609,\n",
       "  0.5323514327770327,\n",
       "  0.5328861484682657,\n",
       "  0.532532483581605,\n",
       "  0.5326291993866122,\n",
       "  0.5322284831748745,\n",
       "  0.5326573519202752,\n",
       "  0.532475279356406,\n",
       "  0.5327464814593152,\n",
       "  0.5321363542622667,\n",
       "  0.5325296412153941,\n",
       "  0.5325210225291368,\n",
       "  0.5326302805082584,\n",
       "  0.5324781086386704,\n",
       "  0.53242399610155,\n",
       "  0.5327029477774612,\n",
       "  0.5326739108659387,\n",
       "  0.5326270296321651,\n",
       "  0.5322992804089213,\n",
       "  0.532755739805175,\n",
       "  0.5326643045840225,\n",
       "  0.5326214784044561,\n",
       "  0.5325920005154804,\n",
       "  0.5324057936668396,\n",
       "  0.5325397902387914,\n",
       "  0.53264803348518,\n",
       "  0.5326092909506666,\n",
       "  0.5323015747031545,\n",
       "  0.5321719365391305,\n",
       "  0.5330205252015494,\n",
       "  0.5326592607226798,\n",
       "  0.5326115103756509,\n",
       "  0.5323169512477347,\n",
       "  0.5322969592199093,\n",
       "  0.5323377004483851,\n",
       "  0.5322784185409546,\n",
       "  0.532796490725463,\n",
       "  0.5325575083251891,\n",
       "  0.5326416419773568,\n",
       "  0.5325271041412664,\n",
       "  0.532520581793979,\n",
       "  0.5326344317537013,\n",
       "  0.5326811651873394,\n",
       "  0.5324532442945775,\n",
       "  0.5326046362155821,\n",
       "  0.5322930999403077,\n",
       "  0.5324797448588581,\n",
       "  0.5326492117672432,\n",
       "  0.5325302050365666,\n",
       "  0.53251409409492,\n",
       "  0.532667787579017,\n",
       "  0.5329886214519904,\n",
       "  0.5326746624659716,\n",
       "  0.5323591535168934,\n",
       "  0.5324064878428855,\n",
       "  0.5325732429822286,\n",
       "  0.5324491107366919,\n",
       "  0.5326788912459117,\n",
       "  0.5326860983197282,\n",
       "  0.5321796795701593,\n",
       "  0.5325462440165077,\n",
       "  0.5327274183916851,\n",
       "  0.532692746902869,\n",
       "  0.5326537131294002,\n",
       "  0.5326938287514013,\n",
       "  0.5321990697364497,\n",
       "  0.5323593965390834,\n",
       "  0.5327645467548836,\n",
       "  0.532223523147707,\n",
       "  0.5325690818026783,\n",
       "  0.5326312540507898,\n",
       "  0.5327559884001569,\n",
       "  0.5325912973745083,\n",
       "  0.5327659789624253,\n",
       "  0.5327335118762846,\n",
       "  0.5327165507204165,\n",
       "  0.5326399987306052,\n",
       "  0.5324438684354953,\n",
       "  0.5319433473959202,\n",
       "  0.5326837303677225,\n",
       "  0.5323511236082248,\n",
       "  0.5323227806304528,\n",
       "  0.5326523596678323,\n",
       "  0.5327084936746737,\n",
       "  0.5328016424082159,\n",
       "  0.5326317354915587,\n",
       "  0.5325242591098072,\n",
       "  0.5323742366418606,\n",
       "  0.5325092825947738,\n",
       "  0.532283794589159,\n",
       "  0.5322409327921829,\n",
       "  0.5325305129938979,\n",
       "  0.5327665233999733,\n",
       "  0.53267698074744,\n",
       "  0.5328569775674401,\n",
       "  0.5323813736923342,\n",
       "  0.5324014243556232,\n",
       "  0.5321222701208378,\n",
       "  0.5326011384405741,\n",
       "  0.5325337493322729,\n",
       "  0.5325559377670288,\n",
       "  0.5322233806780683,\n",
       "  0.5325509743477271,\n",
       "  0.532397999753797,\n",
       "  0.5325671744540454,\n",
       "  0.5320621956654681,\n",
       "  0.5325709011981158,\n",
       "  0.532449282281767,\n",
       "  0.5324586751015206,\n",
       "  0.5324947894588719,\n",
       "  0.532334906541235,\n",
       "  0.5324820173465139,\n",
       "  0.5325853570205409,\n",
       "  0.5323943369756869,\n",
       "  0.5322236646481646,\n",
       "  0.5324403927093599,\n",
       "  0.5322326855446265,\n",
       "  0.5321438508789714,\n",
       "  0.5327480369951667,\n",
       "  0.5324584059114379,\n",
       "  0.532203065912898,\n",
       "  0.5327254812407299,\n",
       "  0.5325746717976361,\n",
       "  0.5322926558130155,\n",
       "  0.5322648638147649,\n",
       "  0.5322088291489981,\n",
       "  0.5321708057469469,\n",
       "  0.5325790081566911,\n",
       "  0.5326216584298669,\n",
       "  0.5325099115933829,\n",
       "  0.5322734144160418,\n",
       "  0.5325202718982852,\n",
       "  0.5322808838956724,\n",
       "  0.5320314391841733,\n",
       "  0.5322324025437115,\n",
       "  0.5325061940565342,\n",
       "  0.5323750018104305,\n",
       "  0.5327336773639773,\n",
       "  0.5324665271654362,\n",
       "  0.5324865044132481,\n",
       "  0.5324406754679796,\n",
       "  0.5322017301388873,\n",
       "  0.5322535042840291,\n",
       "  0.5325013042950049,\n",
       "  0.5321902014860292,\n",
       "  0.5323501384355188,\n",
       "  0.5323842664559683,\n",
       "  0.5323094042336068,\n",
       "  0.5324338216607164,\n",
       "  0.5324097018900925,\n",
       "  0.5324790325106644,\n",
       "  0.5321286129273051,\n",
       "  0.532441671301679,\n",
       "  0.5323205578133343,\n",
       "  0.5324575147493099,\n",
       "  0.5323290383912683,\n",
       "  0.5322298257331538,\n",
       "  0.5320452005882573,\n",
       "  0.5322651235553307,\n",
       "  0.532452536065404,\n",
       "  0.5325222117144887,\n",
       "  0.5323315047151674,\n",
       "  0.5323164976709257,\n",
       "  0.5324545219177153,\n",
       "  0.5322411370471241,\n",
       "  0.5324698647832483,\n",
       "  0.5326428074177688,\n",
       "  0.5323727436181975,\n",
       "  0.5318927692203987,\n",
       "  0.5321892012910145,\n",
       "  0.532416407654925,\n",
       "  0.5324400234513167,\n",
       "  0.5321692041749877,\n",
       "  0.5322602005993448,\n",
       "  0.5325183597037463,\n",
       "  0.5320305233079243,\n",
       "  0.5323833704479342,\n",
       "  0.5325697413304957,\n",
       "  0.5321504175662994,\n",
       "  0.5321057361315905,\n",
       "  0.5326027278977681,\n",
       "  0.5323421712813339,\n",
       "  0.5326666267422157,\n",
       "  0.5322233082317724,\n",
       "  0.5320085502736936,\n",
       "  0.5322642999935926,\n",
       "  0.5321714284458781,\n",
       "  0.5325056181205967,\n",
       "  0.532382335604691,\n",
       "  0.532167422093027,\n",
       "  0.532404899597168,\n",
       "  0.5323187922074543,\n",
       "  0.5322754889484343,\n",
       "  0.5323436875653461,\n",
       "  0.5331040250092018,\n",
       "  0.5321620285995607,\n",
       "  0.5323459760444921,\n",
       "  0.5325136291302317,\n",
       "  0.5321122621133075,\n",
       "  0.532231215296722,\n",
       "  0.532312598412599,\n",
       "  0.5322788672718576,\n",
       "  0.5325977264381037,\n",
       "  0.532313786144179,\n",
       "  0.5322597455687639,\n",
       "  0.5320846969034614,\n",
       "  0.5322817862033844,\n",
       "  0.532603746507226,\n",
       "  0.5321605375142602,\n",
       "  0.5325580542165089,\n",
       "  0.532076295798387,\n",
       "  0.5325612401574608,\n",
       "  0.5320151731735323,\n",
       "  0.532250353233601,\n",
       "  0.5324462429294742,\n",
       "  0.532171101589513,\n",
       "  0.5324434625908612,\n",
       "  0.5323694505827213,\n",
       "  0.5323555566431061,\n",
       "  0.5322834015861759,\n",
       "  0.5321519437844191,\n",
       "  0.5322217265280281,\n",
       "  0.5321106486688785,\n",
       "  0.5325269410765268,\n",
       "  0.5322166337230341,\n",
       "  0.5326807947178197,\n",
       "  0.5321966574444035,\n",
       "  0.5323088321743942,\n",
       "  0.5321283265342557,\n",
       "  0.5321025017315779,\n",
       "  0.5322308273819404,\n",
       "  0.5323714553340664,\n",
       "  0.532482242196556,\n",
       "  0.5322591165701548,\n",
       "  0.5321714519485226,\n",
       "  0.5323397740115964,\n",
       "  0.5325080461618377,\n",
       "  0.5319905448250655,\n",
       "  0.532165216478875,\n",
       "  0.5325027619435535,\n",
       "  0.532091610073074,\n",
       "  0.5322961703063996,\n",
       "  0.5319614056649247,\n",
       "  0.5322703023751577,\n",
       "  0.5325855913200999,\n",
       "  0.5323898208335163,\n",
       "  0.5323991012282487,\n",
       "  0.5318561339281439,\n",
       "  0.5323900137005783]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_callback.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAExVJREFUeJzt3X2QVfV9x/H3d5/YXR4XEHZhwQVFKYlp4hBHsTFJKVato6mTP3Sa1sZMnUxjmnTMJGTsNJn+1TRp0odkkjEPrW0dTWu0cTLawJBkOk4Fgwgo8oyIwPIgsuzyzMK3f9yDc1l34f5+59wj5Pd5zezsfTjf+/vtufez595zz+/8zN0RkfQ0vNsdEJF3h8IvkiiFXyRRCr9IohR+kUQp/CKJUvhFEqXwiyRK4RdJVFOZjTU2Nntz06jgOif8KMQpl00JrgFoaAj/f2hRLUFra2tU3ZkzZ4Jrjh87FtVWY0NjZF34ejx9+nRUWzFHqcb0D+L72Noa/rq3iFdW7/499A301VRYavibm0bRPf19wXUxK/yzn3kguAZgdFt7cE1D5BHS837r6qi6Y4ePBNesf2VdVFvjxoyOqhvfPia4pu+tg1FtnYl4fYxtb4tq6/DAQFTdVVdcGVwTsyG676/+rPbHD350EfmNkCv8ZnaLmW00sy1mtrioTolI/UWH38wage8AtwLzgHvMbF5RHROR+sqz5b8O2OLu29z9JPA4cGcx3RKRessT/unAG1XXd2a3icglIM/e/uG+TnjHfm8zux+4H6CpsSVHcyJSpDxb/p3AjKrr3cDuoQu5+8PuPt/d5zc2NudoTkSKlCf8vwbmmNksM2sB7gaeLqZbIlJv0W/73X3QzB4Afg40Aj9y97gjSUSkdLmO8HP3Z4BnCuqLiJRIR/iJJErhF0lUqQN7ZsyYwbe+8a3gupgBDgOH+oNrIG4QUVtL+IgtgMETJ6PqJnZ0BNfEzs/QPS3u0I3+g33BNXPnzo1qi4i/baAvbhDRjO7uqLo9e/YE1zRGjOobHByseVlt+UUSpfCLJErhF0mUwi+SKIVfJFEKv0iiFH6RRCn8IolS+EUSpfCLJErhF0mUwi+SqFIH9jRYA2NGhc+Ucvjw4eCaJov7v3Z44FBwTWNb7YMpqg22xU3XtWnDxuCa6Z1dUW319PRE1f3n848H1xyNmIkIoHVU+OnhPrTgxqi2Dr71VlRdY2P4tGe7du0KrgkZ4qQtv0iiFH6RRCn8IonKM13XDDP7pZmtN7N1Zva5IjsmIvWVZ4ffIPCgu68ys7HAi2a21N1fLahvIlJH0Vt+d+9191XZ5QFgPZquS+SSUchnfjPrAT4ArBjmvvvNbKWZrTzUH3feNBEpXu7wm9kY4CfA5939HWfNrJ6ua/y48BNPikh95Aq/mTVTCf6j7v5kMV0SkTLk2dtvwA+B9e7+zeK6JCJlyLPlvxH4Y+B3zWx19nNbQf0SkTrLM1HncxAxq4CIXBR0hJ9Iokod1TeqpYWe7hnBdWvWrAmuaRg8E1wD0BzxXuZY5Gi0gabw0WgAJ44eC6656r3viWpr2ZKlUXUf/tBNwTV79+yOauuaa64Jrlm2bFlUW62tcSMxx4weHVwT83e1tdU+alZbfpFEKfwiiVL4RRKl8IskSuEXSZTCL5IohV8kUQq/SKIUfpFEKfwiiVL4RRKl8IskqtSBPQY0e/jImWmTpwTXbN4cPqUVQHfEtFYnT5yIamv//v1RddOnTg2ueeH55VFtnTh2PKpu0qRJwTU7Xn8tqq2Yaa06Ozuj2rrqqqui6ra9tiW45tUN64Jrjh+vfdCXtvwiiVL4RRKl8IskqohTdzea2Utm9rMiOiQi5Shiy/85KrP1iMglJO95+7uBPwB+UEx3RKQsebf8/wB8EYg7YZ6IvGvyTNpxO7DP3V+8wHJvz9V34OCbsc2JSMHyTtpxh5ltBx6nMnnHfwxdqHquvkkdk3M0JyJFyjNF95fdvdvde4C7gV+4+ycK65mI1JW+5xdJVCHH9rv7r4BfFfFYIlIObflFElXqqL6jR46wduXK4LrKbOBhZnZOC64BcPfgmobGuGm3xrbWPrVStdOnBoNrXn9te1Rbc668MqpuxfL/C29rzpyotrZsCR8xt2DBgqi2Nm3dFFXX39cXXBMzMrKxsbHmZbXlF0mUwi+SKIVfJFEKv0iiFH6RRCn8IolS+EUSpfCLJErhF0mUwi+SKIVfJFEKv0iiFH6RRJU6qq+luYUZXeGj7foiRkRNnxo3F9vq1auDa7q64toa29YeVRfjug9+MKpuwoRxUXWbN28Ortm7d29UW1dcMSu4ZuPGuLPN79u3L6puYGAguKZzWnhWrKH27bm2/CKJUvhFEpV30o4JZvaEmW0ws/VmdkNRHROR+sr7mf8fgf9x94+bWQtQ3odYEcklOvxmNg64CfhTAHc/CZwsplsiUm953vbPBvYD/5LN0vsDMxtdUL9EpM7yhL8JuBb4rrt/ADgCLB66UPV0XQf738rRnIgUKU/4dwI73X1Fdv0JKv8MzlE9XVfHuIk5mhORIuWZrmsP8IaZXZ3dtBB4tZBeiUjd5d3b/1ng0WxP/zbgk/m7JCJlyBV+d18NzC+oLyJSIh3hJ5KoUgf2DJ46xb494YM3Tpw4EVyz7NW4gRvNzeGrZOFHPxrV1pIlS6LqOqd1Bdc0HO6PauvowOGoOk6fCS7p64v7Nihm8FFLS0tUWx0dHVF1N9wQfvBrzOCowYCp3LTlF0mUwi+SKIVfJFEKv0iiFH6RRCn8IolS+EUSpfCLJErhF0mUwi+SKIVfJFEKv0iiFH6RRJU6qs9xzgyeCq574/XtwTWXX355cA3A1KlTg2teWbs2qq22traous2bNgTXxI5ie/PAgai6qZ2XBde0trZGtRUzzVd3d3dUW1u2boqq65oW/rqaOGlCcE1jU2PNy2rLL5IohV8kUXmn6/pLM1tnZq+Y2WNmFve+TURKFx1+M5sO/AUw393fCzQCdxfVMRGpr7xv+5uANjNrojJP3+78XRKRMuQ5b/8u4BvADqAXOOTucSelE5HS5Xnb3wHcCcwCpgGjzewTwyz39nRdhwYOxfdURAqV523/7wGvuft+dz8FPAksGLpQ9XRd48eOz9GciBQpT/h3ANebWbuZGZXpuuLOly0ipcvzmX8Flck5VwEvZ4/1cEH9EpE6yztd11eArxTUFxEpkY7wE0mUwi+SqFJH9Z0eHORAxCixWbNmBdfMmTMnuAZg//79wTUxfxPA+Ilx335YQ/gIsd7e3si2PKpuwoTwEWnLX3ghqq1FixYF12zY+GpUWz09PVF1L730UnDNGQ9f98eOHa15WW35RRKl8IskSuEXSZTCL5IohV8kUQq/SKIUfpFEKfwiiVL4RRKl8IskSuEXSZTCL5KoUgf2NDU309nZGVy3b9++4Jp16+NOKtQyKnyVtI9tj2qrsbH2qZWqHT5yJLhm/4HwdQjQ1dUVVTd9+vTgmgcffDCqrYe//73gmtjputasWRNVd9dddwXXrFu3Lrimubm55mW15RdJlMIvkqgLht/MfmRm+8zslarbJprZUjPbnP3uqG83RaRotWz5/xW4Zchti4Fl7j4HWJZdF5FLyAXD7+7/C7w15OY7gUeyy48AHyu4XyJSZ7Gf+ae6ey9A9ntKcV0SkTLUfYefpusSuTjFhn+vmXUBZL9H/BJZ03WJXJxiw/80cG92+V7gp8V0R0TKUstXfY8BzwNXm9lOM/sU8LfAIjPbDCzKrovIJeSCx7K6+z0j3LWw4L6ISIl0hJ9IohR+kUSVOqrv1KlTvNG7O7huypTwwwg6OuK+WdizZ09wTX9/f1RbM2fOjKrr7ApfH29GjupraIp7iWzfsSO4ZvXLq6Pamj9/fnDNjoj+QfxowFWrXgyuGTVqVFRbtdKWXyRRCr9IohR+kUQp/CKJUvhFEqXwiyRK4RdJlMIvkiiFXyRRCr9IohR+kUQp/CKJKnVgT1tbG9e8/5rguoMHDwbXHD1xPLgGYMKkicE1/UcOR7W18qVVUXXNzeHTfJ06dSqqrUktLVF1MQOJYp5ngJ6enuCalsi/q729LapuYGAguCbmOXP3mpfVll8kUQq/SKIUfpFExc7V93Uz22Bma83sKTObUN9uikjRYufqWwq8193fB2wCvlxwv0SkzqLm6nP3Je4+mF1dDsSd20hE3jVFfOa/D3h2pDurp+s62B/3VY6IFC9X+M3sIWAQeHSkZaqn6+oY15GnOREpUPRBPmZ2L3A7sNBDjiwQkYtCVPjN7BbgS8CH3f1osV0SkTLEztX3bWAssNTMVpvZ9+rcTxEpWOxcfT+sQ19EpEQ6wk8kUaWO6jt67BirX14bXHfZZZcF1xw/Hjeqr3d3+HRisSPm5s67Oqquvb09uOa5556LauvQQF9U3XvmzQuuaWuLGzF39Gj4bqetW7dEtTV37tyoumnTpgXXNDSEb5ubm5trf/zgRxeR3wgKv0iiFH6RRCn8IolS+EUSpfCLJErhF0mUwi+SKIVfJFEKv0iiFH6RRCn8IolS+EUSVeqovpZRLcyc1RNcZ2bBNaMi51SbODF8rr7Xd7wW1dbGzZui6qZMmRJcM3Xq1Ki2jh+PO1HTihdeCK553zXh8zgCnDx5Irhm5syZUW1t27Ytqq6/vz+4ZvDEyeCa48dqH82qLb9IohR+kURFTddVdd8XzMzNbHJ9uici9RI7XRdmNgNYBOwouE8iUoKo6boy3wK+COic/SKXoKjP/GZ2B7DL3dfUsOzb03Ud6o87H5yIFC84/GbWDjwE/HUty1dP1zV+nGbyFrlYxGz5rwBmAWvMbDuVGXpXmVlnkR0TkfoKPsjH3V8G3j7KJPsHMN/d3yywXyJSZ7HTdYnIJS52uq7q+3sK642IlEZH+IkkqtSBPYODgxw4cCC47s03w3cnxE7XNXv27OCaSVPCpxMDGDNmTFRdR0dHcE1fX9zXrIcOhg+qgrippk6fPh3V1q5du4JrYl8fo0ePjqqb3BE+YGzv3r1RbdVKW36RRCn8IolS+EUSpfCLJErhF0mUwi+SKIVfJFEKv0iiFH6RRCn8IolS+EUSpfCLJErhF0mUuZd38l0z2w+8PsLdk4GL4WxA6se51I9zXez9uNzdaxpmWmr4z8fMVrr7fPVD/VA/yumH3vaLJErhF0nUxRT+h9/tDmTUj3OpH+f6jenHRfOZX0TKdTFt+UWkRKWG38xuMbONZrbFzBYPc/8oM/txdv8KM+upQx9mmNkvzWy9ma0zs88Ns8xHzOyQma3OfmqamiyyP9vN7OWsnZXD3G9m9k/ZOllrZtcW3P7VVX/najPrN7PPD1mmbutjuCngzWyimS01s83Z72HPWGpm92bLbDaze+vQj6+b2YZsvT9lZsPON3eh57CAfnzVzHZVrf/bRqg9b77ewd1L+QEaga3AbKAFWAPMG7LMnwPfyy7fDfy4Dv3oAq7NLo8FNg3Tj48APytpvWwHJp/n/tuAZwEDrgdW1Pk52kPlu+JS1gdwE3At8ErVbX8HLM4uLwa+NkzdRGBb9rsju9xRcD9uBpqyy18brh+1PIcF9OOrwBdqeO7Om6+hP2Vu+a8Dtrj7Nnc/CTwO3DlkmTuBR7LLTwALzSzu3NEjcPded1+VXR4A1gPTi2yjYHcC/+YVy4EJZtZVp7YWAlvdfaQDsQrnw08BX/06eAT42DClvw8sdfe33P0gsBS4pch+uPsSdx/Mri6nMi9lXY2wPmpRS77OUWb4pwNvVF3fyTtD9/Yy2Uo/BEyqV4eyjxUfAFYMc/cNZrbGzJ41s/fUqw+AA0vM7EUzu3+Y+2tZb0W5G3hshPvKWh8AU929Fyr/rKmaG7JKmesF4D4q78CGc6HnsAgPZB8/fjTCx6Dg9VFm+Ifbgg/9qqGWZQphZmOAnwCfd/f+IXevovLW97eBfwb+ux59yNzo7tcCtwKfMbObhnZ1mJrC14mZtQB3AP81zN1lro9alflaeQgYBB4dYZELPYd5fZfK7NjvB3qBvx+um8Pcdt71UWb4dwIzqq53A7tHWsbMmoDxxL0FOi8za6YS/Efd/cmh97t7v7sfzi4/AzSb2eSi+5E9/u7s9z7gKSpv36rVst6KcCuwyt3fMU1Mmesjs/fsR5vs975hlillvWQ7Em8H/sizD9dD1fAc5uLue939tLufAb4/wuMHr48yw/9rYI6Zzcq2MncDTw9Z5mng7F7bjwO/GGmFx8r2IfwQWO/u3xxhmc6z+xrM7Doq6yl8nrEL92W0mY09e5nKDqZXhiz2NPAn2V7/64FDZ98SF+weRnjLX9b6qFL9OrgX+Okwy/wcuNnMOrK3wTdntxXGzG4BvgTc4e5HR1imlucwbz+q9/H84QiPX0u+zlXEHsqAPZm3Udm7vhV4KLvtb6isXIBWKm87twAvALPr0IffofJ2aC2wOvu5Dfg08OlsmQeAdVT2mC4HFtRpfczO2liTtXd2nVT3xYDvZOvsZWB+HfrRTiXM46tuK2V9UPmH0wucorL1+hSV/TzLgM3Z74nZsvOBH1TV3pe9VrYAn6xDP7ZQ+Rx99nVy9puoacAz53sOC+7Hv2fP/Voqge4a2o+R8nW+Hx3hJ5IoHeEnkiiFXyRRCr9IohR+kUQp/CKJUvhFEqXwiyRK4RdJ1P8DmLVi9dm7HJwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_directory = base_dir + '/tiny_test16/class0'\n",
    "files = os.listdir(images_directory)\n",
    "files.sort()\n",
    "\n",
    "images = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for file in files:\n",
    "    counter += 1\n",
    "    if counter > 100:\n",
    "        break\n",
    "    if not file.startswith('.'):\n",
    "        #print(file)\n",
    "        \n",
    "#         img = load_img(images_directory + '/' + file, False, target_size=(patch_size, patch_size))\n",
    "#         x = img_to_array(img)\n",
    "#         x = np.expand_dims(x, axis=0)\n",
    "#         images.append(x)\n",
    "        \n",
    "#         img = load_img(images_directory + '/' + file, False, target_size=(input_patch_size, input_patch_size))\n",
    "        img = imageio.imread(images_directory + '/' + file)\n",
    "        img = np.expand_dims(img, axis=-1)        \n",
    "        images.append(img)\n",
    "        \n",
    "\n",
    "\n",
    "images = np.array(images).reshape(np.array(images).shape[0], input_shape[0], input_shape[1], input_shape[2])\n",
    "images = images / 255\n",
    "predictions = autoencoder.predict_on_batch(np.array(images))\n",
    "print(\"predictions: \")\n",
    "for i, im1 in enumerate(images):\n",
    "    im_1 = im1.reshape(input_shape)\n",
    "    plt.imshow(im_1, interpolation='nearest')\n",
    "    plt.show()\n",
    "    \n",
    "    pred_1 = predictions[i].numpy()#.reshape(input_shape)\n",
    "    plt.imshow(pred_1, interpolation='nearest')\n",
    "    plt.show()\n",
    "    \n",
    "    if i == 2:\n",
    "        break\n",
    "    print(\"next\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdb1adccba8>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdb28ca04a8>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdb1add5a90>\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fdb1add58d0>\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fdb1a927940>\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fdb1a93e668>\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 16, 16, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 16, 16, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 32)          0         \n",
      "=================================================================\n",
      "Total params: 19,392\n",
      "Trainable params: 19,392\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = Model(input_img, encoded)\n",
    "for i in range(1, len(encoder.layers)):\n",
    "    print(encoder.get_layer(index=i))\n",
    "    encoder.get_layer(index=i).set_weights(autoencoder.get_layer(index=i).get_weights())\n",
    "encoder.summary()\n",
    "\n",
    "# encoder.save(base_dir + '/encoder' + model_version + '.h5')\n",
    "encoder.save(base_dir + '/' + model_version + '__encoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = encoder.predict_on_batch(np.array(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 32), dtype=float32, numpy=\n",
       "array([[[ 0.05565583, -0.24996227, -0.0791648 ,  0.16771457,\n",
       "          0.03777337,  0.10455577, -0.01680624,  0.11207959,\n",
       "          0.11137222,  0.06271623,  0.2315485 , -0.0628413 ,\n",
       "          0.14516146,  0.01177703, -0.01242101,  0.02389297,\n",
       "          0.1414031 ,  0.11302765,  0.07147142, -0.03023916,\n",
       "          0.01645315,  0.12330112, -0.01693118, -0.13514245,\n",
       "          0.20743653,  0.1307104 , -0.08437359,  0.0431138 ,\n",
       "         -0.2035501 , -0.04094815,  0.08355999,  0.03386394],\n",
       "        [ 0.11568862, -0.15564966,  0.03081474,  0.0972597 ,\n",
       "         -0.00263065,  0.09159648,  0.05533858,  0.04699807,\n",
       "          0.0105389 ,  0.07237399,  0.24377885, -0.02887267,\n",
       "          0.07086342, -0.10889471,  0.09135725,  0.12757508,\n",
       "          0.10404458,  0.12367651,  0.08487045,  0.07352839,\n",
       "          0.06241041,  0.14231765,  0.06690668,  0.03413185,\n",
       "          0.16080754,  0.16138   , -0.15063149, -0.12105423,\n",
       "         -0.0290063 , -0.10049725,  0.0516034 , -0.07455093]],\n",
       "\n",
       "       [[-0.044855  , -0.14684343, -0.00403541,  0.14141926,\n",
       "         -0.00208563,  0.16037543, -0.09826982,  0.107717  ,\n",
       "          0.16871917,  0.06525075,  0.2568689 ,  0.02447602,\n",
       "          0.1474599 ,  0.01601423,  0.03289345,  0.02249484,\n",
       "         -0.02916694,  0.11426337,  0.05901146,  0.10844556,\n",
       "          0.03232777,  0.14384072,  0.12591983, -0.13374054,\n",
       "          0.16343333,  0.1405417 , -0.1788289 ,  0.03890992,\n",
       "         -0.23213732, -0.15613985,  0.11980007, -0.06380594],\n",
       "        [ 0.19346598, -0.1780802 ,  0.0577054 ,  0.10321472,\n",
       "         -0.03992784,  0.14104596, -0.15003908,  0.01625229,\n",
       "         -0.0043304 ,  0.04750387,  0.234694  ,  0.01933021,\n",
       "          0.07049681, -0.04944205,  0.10767622,  0.16775061,\n",
       "         -0.01441532,  0.10537504,  0.15679242,  0.17120713,\n",
       "          0.0586626 ,  0.19162197,  0.20362128,  0.00786673,\n",
       "          0.17655578,  0.15065041, -0.14890778, -0.04269642,\n",
       "         -0.1034416 , -0.09894454,  0.03796889,  0.01389948]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3659482"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(predictions.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4363702"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(predictions.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([100, 2, 2, 32])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 12810<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 1.38MB of 1.38MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>wandb/run-20201028_104308-2bdam0x2/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>wandb/run-20201028_104308-2bdam0x2/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>499</td></tr><tr><td>loss</td><td>0.53661</td></tr><tr><td>val_loss</td><td>0.53239</td></tr><tr><td>_step</td><td>499</td></tr><tr><td>_runtime</td><td>30774</td></tr><tr><td>_timestamp</td><td>1603908962</td></tr><tr><td>best_val_loss</td><td>0.53186</td></tr><tr><td>best_epoch</td><td>498</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td></td></tr><tr><td>loss</td><td></td></tr><tr><td>val_loss</td><td></td></tr><tr><td>_step</td><td></td></tr><tr><td>_runtime</td><td></td></tr><tr><td>_timestamp</td><td></td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1501 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">prime-music-6</strong>: <a href=\"https://wandb.ai/nimpy/patch-desc-ae/runs/2bdam0x2\" target=\"_blank\">https://wandb.ai/nimpy/patch-desc-ae/runs/2bdam0x2</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  70.,  227.,  870., 1521., 3280., 3529., 2175.,  734.,  289.,\n",
       "         105.]),\n",
       " array([-0.3659482 , -0.28571635, -0.20548452, -0.12525268, -0.04502084,\n",
       "         0.035211  ,  0.11544283,  0.19567467,  0.2759065 ,  0.35613835,\n",
       "         0.4363702 ], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(predictions.numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(history_callback.history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_2",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
