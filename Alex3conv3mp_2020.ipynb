{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import listdir\n",
    "from os import system\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import imageio\n",
    "from skimage.measure import block_reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 16\n",
    "nb_channels = 3\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/niaki/Code/ImageNet/tiny-imagenet-200'\n",
    "\n",
    "train_data_dir      = base_dir + '/tiny_train16'\n",
    "validation_data_dir = base_dir + '/tiny_validation16'\n",
    "test_data_dir       = base_dir + '/tiny_test16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_data(dir_patches):\n",
    "    \"\"\"Load all the patches from dir_patches into tensors for training the autoencoder.\n",
    "    Return:\n",
    "        patches_in  -- tensor of stacked patches in their original shape, 16x16\n",
    "        patches_out -- tensor of the original patches downsampled to 8x8\n",
    "    \n",
    "    \"\"\"\n",
    "    files_patches = listdir(dir_patches + '/class0')\n",
    "    files_patches.sort()\n",
    "    \n",
    "    patches_in = []\n",
    "    patches_out = []\n",
    "\n",
    "    \n",
    "    for file_patch in files_patches:\n",
    "        patch_in = imageio.imread(dir_patches + '/class0/' + file_patch)\n",
    "        \n",
    "        patch_out = block_reduce(patch_in, (2, 2, 1), func=np.mean)  # downsample (mean-pool)\n",
    "        \n",
    "        patches_in.append(patch_in)\n",
    "        patches_out.append(patch_out)\n",
    "        \n",
    "\n",
    "    patches_in = np.array(patches_in)\n",
    "    patches_in = patches_in.astype(np.float64) / 255\n",
    "#     patches_in = np.expand_dims(patches_in, -1)  # need this if grayscale\n",
    "    \n",
    "    patches_out = np.array(patches_out)\n",
    "    patches_out = patches_out.astype(np.float64) / 255\n",
    "#     patches_out = np.expand_dims(patches_out, -1)  # need this if grayscale\n",
    "        \n",
    "    print(\"in\", patches_in.shape, \"; out\", patches_out.shape)\n",
    "    \n",
    "    return patches_in, patches_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in (157086, 16, 16, 3) ; out (157086, 8, 8, 3)\n",
      "in (3932, 16, 16, 3) ; out (3932, 8, 8, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = loading_data(train_data_dir)\n",
    "x_validation, y_validation = loading_data(validation_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAC/dJREFUeJzt3e2PXGUZx/Hfr7stfab2AYVutRCwikQpaUiwgSioKULAFybSBBKJsb4BaTThwXf+ARI0MSRNAUmoECyQGFSQBBBJEPpAeSgtpDSQLgVbiqSlxZbdvXyxU9y2S/Zs55x7Zq98P8mmM7Mnc10z3d/eZ86ec9+OCAHIaVKnGwDQHAIOJEbAgcQIOJAYAQcSI+BAYgQcSIyAA4kRcCCx3iae1HbK0+MsF62X8k2UVPZtTPouhhQRY76TjQRckib1lNk5mDRUbifEUXaHZ7DgDtZQb8HUTS4YuhgoV6ukw9VeF7voQGIEHEiMgAOJEXAgMQIOJEbAgcQIOJAYAQcSqxRw2ytsv257h+1bm24KQD3GDLjtHkm/l3S5pHMlrbR9btONAWhflRH8Qkk7ImJnRByR9ICkq5ttC0AdqgR8oaRdI+73tx4D0OWqXGwy2lUIJ1wtYHuVpFVtdwSgNlUC3i9p0Yj7fZJ2H79RRKyRtEbKe7koMNFU2UXfIOkc22faniLpGkl/brYtAHUYcwSPiAHbN0h6XFKPpLsjYmvjnQFom5tYm8x2MOFD+5jwoQaJJ3yIobFndOFMNiAxAg4kRsCBxAg4kBgBBxIj4EBiBBxIjIADiTWzsskkaWj6UCNPfbyhI2XqSJIOn1KulqRJmlKsVu9gT7FaMXCoWK1pKvjzIem0WdOK1Omv+HPPCA4kRsCBxAg4kBgBBxIj4EBiBBxIjIADiRFwIDECDiRWZWWTu23vsf1qiYYA1KfKCP4HSSsa7gNAA8YMeEQ8I+mDAr0AqBmfwYHEarua7JiliwrOwAvgs9UW8GOWLuph6SKgG7CLDiRW5c9k90t6TtIS2/22f9J8WwDqUGVtspUlGgFQP3bRgcQIOJAYAQcSI+BAYgQcSIyAA4kRcCAxAg4k1sjSRadNnaYfffnsJp76BI9ueqVIHUnap8PFaknS/t7BYrWGppRbumjyx+Xex77CV0X87ILzitT5zaZq868wggOJEXAgMQIOJEbAgcQIOJAYAQcSI+BAYgQcSIyAA4kRcCCxKpMuLrL9lO1ttrfavqlEYwDaV+Vc9AFJv4yIzbZnSdpk+4mIeK3h3gC0qcraZO9GxObW7QOStkla2HRjANo3rqvJbC+WtFTS86N879Oli2ZNmVxDawDaVfkgm+2Zkh6StDoi9h///YhYExHLImLZtN5GrkIFME6VAm57sobDvS4iHm62JQB1qXIU3ZLukrQtIm5vviUAdakygi+XdJ2kS21vaX19v+G+ANSgytpkz4oVv4EJiTPZgMQIOJAYAQcSI+BAYgQcSIyAA4kRcCAxAg4k1shVIYu+MF+/u+WnTTz1CW7ZvbdIHUl68IWXitWSpH+8/VaxWk9ueLlYrRkFh5WzTp1erpikKy7+WpE6d72xo9J2jOBAYgQcSIyAA4kRcCAxAg4kRsCBxAg4kBgBBxIj4EBiVSZdnGr7BdsvtZYu+nWJxgC0r8qpqoclXRoRH7WmT37W9t8i4l8N9wagTVUmXQxJH7XuTm59RZNNAahH1YUPemxvkbRH0hMRMerSRbY32t64d/9HJz4JgOIqBTwiBiPifEl9ki60fd4o23y6dNGC2TPr7hPASRjXUfSI+FDS05JWNNINgFpVOYq+wPac1u1pkr4jaXvTjQFoX5Wj6KdLutd2j4Z/ITwYEY822xaAOlQ5iv6yhtcEBzDBcCYbkBgBBxIj4EBiBBxIjIADiRFwIDECDiRGwIHEGlm6aGBmr/ZePK+Jpz7B9PdnF6kjST//5teL1ZKk1R8MFqu1582dxWpt3vpKsVoeOlisliQNnfJJkTrhaldsM4IDiRFwIDECDiRGwIHECDiQGAEHEiPgQGIEHEiMgAOJVQ54a270F20zHxswQYxnBL9J0ramGgFQv6orm/RJukLS2mbbAVCnqiP4HZJuljTUYC8AalZl4YMrJe2JiE1jbPfp2mT79h2orUEAJ6/KCL5c0lW235L0gKRLbd93/EYj1yabN29WzW0COBljBjwibouIvohYLOkaSU9GxLWNdwagbfwdHEhsXDO6RMTTGl5dFMAEwAgOJEbAgcQIOJAYAQcSI+BAYgQcSIyAA4kRcCCxRpYuisEhHfmgzJIxc06dX6SOJPXMmlysliTFGVOL1VpwRk+xWt/66txitWLPvmK1JGnwwzI/91N6p1TajhEcSIyAA4kRcCAxAg4kRsCBxAg4kBgBBxIj4EBiBBxIrNKZbK0ZVQ9IGpQ0EBHLmmwKQD3Gc6rqtyPi/cY6AVA7dtGBxKoGPCT93fYm26uabAhAfaruoi+PiN22T5P0hO3tEfHMyA1awV8lSQtPL3e1EIDPVmkEj4jdrX/3SHpE0oWjbPP/pYvmsnQR0A2qLD44w/aso7clfU/Sq003BqB9VXbRPy/pEdtHt/9jRDzWaFcAajFmwCNip6RvFOgFQM34MxmQGAEHEiPgQGIEHEiMgAOJEXAgMQIOJEbAgcQaWbpo4NAn+uClvU089QkOnV1uOaG5X1lUrJYkTTt0uFit3X0uVmvB/AXFas2cMa1YLUna/dhzReoMDAxW2o4RHEiMgAOJEXAgMQIOJEbAgcQIOJAYAQcSI+BAYgQcSKxSwG3Psb3e9nbb22xf1HRjANpX9VTV30p6LCJ+aHuKpOkN9gSgJmMG3PZsSZdI+rEkRcQRSUeabQtAHarsop8laa+ke2y/aHtta350AF2uSsB7JV0g6c6IWCrpoKRbj9/I9irbG21v/M+BgzW3CeBkVAl4v6T+iHi+dX+9hgN/jJFLF31uFgM80A3GDHhEvCdpl+0lrYcuk/Rao10BqEXVo+g3SlrXOoK+U9L1zbUEoC6VAh4RWyQta7gXADXjTDYgMQIOJEbAgcQIOJAYAQcSI+BAYgQcSIyAA4kRcCCxRtYm04FPpCffaeSpT/DygTJ1JM276JRitSTp4KJyv3/PnjOnWK3dcweK1fIXy61dJ0mTLzq3SB3f95dK2zGCA4kRcCAxAg4kRsCBxAg4kBgBBxIj4EBiBBxIjIADiY0ZcNtLbG8Z8bXf9uoSzQFoz5inqkbE65LOlyTbPZLekfRIw30BqMF4d9Evk/RmRLzdRDMA6jXegF8j6f7RvnHM0kX//bj9zgC0rXLAW4seXCXpT6N9/5ili6ZOq6s/AG0Yzwh+uaTNEfHvppoBUK/xBHylPmP3HEB3qhRw29MlfVfSw822A6BOVdcmOyRpXsO9AKgZZ7IBiRFwIDECDiRGwIHECDiQGAEHEiPgQGIEHEjMEVH/k9p7JY33ktL5kt6vvZnukPW18bo650sRsWCsjRoJ+MmwvTEilnW6jyZkfW28ru7HLjqQGAEHEuumgK/pdAMNyvraeF1drms+gwOoXzeN4ABq1hUBt73C9uu2d9i+tdP91MH2IttP2d5me6vtmzrdU51s99h+0fajne6lTrbn2F5ve3vr/+6iTvfUjo7vorfmWn9DwzPG9EvaIGllRLzW0cbaZPt0SadHxGbbsyRtkvSDif66jrL9C0nLJM2OiCs73U9dbN8r6Z8RsbY10ej0iPiw032drG4YwS+UtCMidkbEEUkPSLq6wz21LSLejYjNrdsHJG2TtLCzXdXDdp+kKySt7XQvdbI9W9Ilku6SpIg4MpHDLXVHwBdK2jXifr+SBOEo24slLZX0fGc7qc0dkm6WNNTpRmp2lqS9ku5pffxYa3tGp5tqRzcE3KM8lubQvu2Zkh6StDoi9ne6n3bZvlLSnojY1OleGtAr6QJJd0bEUkkHJU3oY0LdEPB+SYtG3O+TtLtDvdTK9mQNh3tdRGSZkXa5pKtsv6Xhj1OX2r6vsy3Vpl9Sf0Qc3dNar+HAT1jdEPANks6xfWbroMY1kv7c4Z7aZtsa/iy3LSJu73Q/dYmI2yKiLyIWa/j/6smIuLbDbdUiIt6TtMv2ktZDl0ma0AdFK02b3KSIGLB9g6THJfVIujsitna4rTosl3SdpFdsb2k99quI+GsHe8LYbpS0rjXY7JR0fYf7aUvH/0wGoDndsIsOoCEEHEiMgAOJEXAgMQIOJEbAgcQIOJAYAQcS+x96jc43A+8j6gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_index = np.random.randint(x_train.shape[0]) #  5429\n",
    "# print(np.array(np.round(x_train[temp_index] * 255), dtype=np.uint8))\n",
    "plt.imshow(np.array(np.round(x_train[temp_index] * 255), dtype=np.uint8))\n",
    "plt.show()\n",
    "plt.imshow(np.array(np.round(y_train[temp_index] * 255), dtype=np.uint8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 16, 16, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 16, 16, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 2, 32)          9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 3)           867       \n",
      "=================================================================\n",
      "Total params: 38,755\n",
      "Trainable params: 38,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (patch_size, patch_size, nb_channels)\n",
    "input_img = Input(shape=input_shape)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(input_img)\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = MaxPool2D((2, 2), padding=\"same\")(x)\n",
    "x = MaxPool2D((2, 2), padding=\"same\")(x)\n",
    "encoded = MaxPool2D((2, 2), padding=\"same\")(x)\n",
    "\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(3, (3, 3), activation=\"relu\", padding=\"same\")(x)  # 32\n",
    "# x = UpSampling2D((2, 2))(x)\n",
    "# decoded = Conv2D(3, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datagen = ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n",
    "    width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
    "    horizontal_flip=False, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/niaki/Code/ImageNet/tiny-imagenet-200'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "# os.environ['WANDB_MODE'] = 'dryrun'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: nimpy (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.7<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">royal-rain-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nimpy/patch-desc-ae\" target=\"_blank\">https://wandb.ai/nimpy/patch-desc-ae</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/nimpy/patch-desc-ae/runs/21dup709\" target=\"_blank\">https://wandb.ai/nimpy/patch-desc-ae/runs/21dup709</a><br/>\n",
       "                Run data is saved locally in <code>wandb/run-20201022_172530-21dup709</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(21dup709)</h1><p></p><iframe src=\"https://wandb.ai/nimpy/patch-desc-ae/runs/21dup709\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7ff08c8f9630>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "  project=\"patch-desc-ae\",\n",
    "  config={\n",
    "    \"augmentation\": True,\n",
    "    \"elus\": False,\n",
    "    \"downsampling_output\": True,\n",
    "    \"optimizer\": \"adadelta\", \n",
    "    \"loss\": \"binary_crossentropy\",\n",
    "    \"epochs\": 50 }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/niaki/Code/ImageNet/tiny-imagenet-200/weights_patch_desc_ae_20201022_17321416_alex_3conv3mp_2020_augm_relu_dwnsmpl\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 157086 steps, validate for 3932 steps\n",
      "Epoch 1/50\n",
      "  4906/157086 [..............................] - ETA: 26:24 - loss: 0.6261WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:28 - loss: 0.6261Epoch 2/50\n",
      "  4906/157086 [..............................] - ETA: 26:18 - loss: 0.6060WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:21 - loss: 0.6060Epoch 3/50\n",
      "  4907/157086 [..............................] - ETA: 26:28 - loss: 0.5952WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:31 - loss: 0.5952Epoch 4/50\n",
      "  4904/157086 [..............................] - ETA: 26:25 - loss: 0.5882WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:27 - loss: 0.5882Epoch 5/50\n",
      "  4906/157086 [..............................] - ETA: 26:23 - loss: 0.5833WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:26 - loss: 0.5833Epoch 6/50\n",
      "  4907/157086 [..............................] - ETA: 26:26 - loss: 0.5799WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:29 - loss: 0.5799Epoch 7/50\n",
      "  4905/157086 [..............................] - ETA: 26:35 - loss: 0.5770WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:38 - loss: 0.5770Epoch 8/50\n",
      "  4906/157086 [..............................] - ETA: 26:35 - loss: 0.5743WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:38 - loss: 0.5743Epoch 9/50\n",
      "  4907/157086 [..............................] - ETA: 26:28 - loss: 0.5720WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:31 - loss: 0.5720Epoch 10/50\n",
      "  4909/157086 [..............................] - ETA: 26:40 - loss: 0.5699WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:43 - loss: 0.5699Epoch 11/50\n",
      "  4909/157086 [..............................] - ETA: 26:20 - loss: 0.5676WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:23 - loss: 0.5676Epoch 12/50\n",
      "  4905/157086 [..............................] - ETA: 26:27 - loss: 0.5657WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:30 - loss: 0.5657Epoch 13/50\n",
      "  4908/157086 [..............................] - ETA: 26:21 - loss: 0.5641WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:24 - loss: 0.5641Epoch 14/50\n",
      "  4909/157086 [..............................] - ETA: 26:24 - loss: 0.5628WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:27 - loss: 0.5628Epoch 15/50\n",
      "  4907/157086 [..............................] - ETA: 26:27 - loss: 0.5618WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:29 - loss: 0.5618Epoch 16/50\n",
      "  4909/157086 [..............................] - ETA: 26:27 - loss: 0.5608WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:30 - loss: 0.5608Epoch 17/50\n",
      "  4906/157086 [..............................] - ETA: 26:29 - loss: 0.5600WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:32 - loss: 0.5600Epoch 18/50\n",
      "  4905/157086 [..............................] - ETA: 26:20 - loss: 0.5594WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4909/157086 [..............................] - ETA: 26:22 - loss: 0.5594Epoch 19/50\n",
      "  4906/157086 [..............................] - ETA: 26:28 - loss: 0.5588WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:31 - loss: 0.5588Epoch 20/50\n",
      "  4905/157086 [..............................] - ETA: 26:30 - loss: 0.5582WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:32 - loss: 0.5582Epoch 21/50\n",
      "  4907/157086 [..............................] - ETA: 26:29 - loss: 0.5577WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:32 - loss: 0.5577Epoch 22/50\n",
      "  4905/157086 [..............................] - ETA: 26:32 - loss: 0.5571WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:34 - loss: 0.5571Epoch 23/50\n",
      "  4907/157086 [..............................] - ETA: 26:27 - loss: 0.5566WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:29 - loss: 0.5566Epoch 24/50\n",
      "  4905/157086 [..............................] - ETA: 26:33 - loss: 0.5562WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:35 - loss: 0.5562Epoch 25/50\n",
      "  4906/157086 [..............................] - ETA: 26:28 - loss: 0.5558WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:30 - loss: 0.5558Epoch 26/50\n",
      "  4905/157086 [..............................] - ETA: 26:30 - loss: 0.5555WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:32 - loss: 0.5555Epoch 27/50\n",
      "  4907/157086 [..............................] - ETA: 26:25 - loss: 0.5550WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:28 - loss: 0.5550Epoch 28/50\n",
      "  4904/157086 [..............................] - ETA: 26:21 - loss: 0.5548WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:23 - loss: 0.5547Epoch 29/50\n",
      "  4909/157086 [..............................] - ETA: 26:29 - loss: 0.5544WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:32 - loss: 0.5544Epoch 30/50\n",
      "  4906/157086 [..............................] - ETA: 26:38 - loss: 0.5541WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:41 - loss: 0.5541Epoch 31/50\n",
      "  4906/157086 [..............................] - ETA: 26:41 - loss: 0.5539WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:44 - loss: 0.5539Epoch 32/50\n",
      "  4907/157086 [..............................] - ETA: 26:28 - loss: 0.5536WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:31 - loss: 0.5536Epoch 33/50\n",
      "  4909/157086 [..............................] - ETA: 26:43 - loss: 0.5533WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:45 - loss: 0.5533Epoch 34/50\n",
      "  4905/157086 [..............................] - ETA: 26:40 - loss: 0.5531WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:43 - loss: 0.5531Epoch 35/50\n",
      "  4906/157086 [..............................] - ETA: 26:32 - loss: 0.5528WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:35 - loss: 0.5528Epoch 36/50\n",
      "  4908/157086 [..............................] - ETA: 26:33 - loss: 0.5526WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:35 - loss: 0.5526Epoch 37/50\n",
      "  4906/157086 [..............................] - ETA: 26:52 - loss: 0.5523WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4909/157086 [..............................] - ETA: 26:55 - loss: 0.5523Epoch 38/50\n",
      "  4909/157086 [..............................] - ETA: 26:44 - loss: 0.5521WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:47 - loss: 0.5521Epoch 39/50\n",
      "  4908/157086 [..............................] - ETA: 26:37 - loss: 0.5519WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:40 - loss: 0.5519Epoch 40/50\n",
      "  4908/157086 [..............................] - ETA: 26:41 - loss: 0.5518WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:44 - loss: 0.5518Epoch 41/50\n",
      "  4907/157086 [..............................] - ETA: 26:42 - loss: 0.5515WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:45 - loss: 0.5515Epoch 42/50\n",
      "  4909/157086 [..............................] - ETA: 26:42 - loss: 0.5514WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:45 - loss: 0.5514Epoch 43/50\n",
      "  4905/157086 [..............................] - ETA: 26:43 - loss: 0.5512WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:46 - loss: 0.5512Epoch 44/50\n",
      "  4907/157086 [..............................] - ETA: 26:51 - loss: 0.5510WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:54 - loss: 0.5510Epoch 45/50\n",
      "  4904/157086 [..............................] - ETA: 26:40 - loss: 0.5509WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:42 - loss: 0.5509Epoch 46/50\n",
      "  4905/157086 [..............................] - ETA: 26:44 - loss: 0.5507WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:46 - loss: 0.5507Epoch 47/50\n",
      "  4909/157086 [..............................] - ETA: 26:43 - loss: 0.5505WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:45 - loss: 0.5505Epoch 48/50\n",
      "  4907/157086 [..............................] - ETA: 26:47 - loss: 0.5504WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:50 - loss: 0.5504Epoch 49/50\n",
      "  4907/157086 [..............................] - ETA: 26:43 - loss: 0.5502WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:46 - loss: 0.5502Epoch 50/50\n",
      "  4907/157086 [..............................] - ETA: 26:43 - loss: 0.5501WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 7854300 batches). You may need to use the repeat() function when building your dataset.\n",
      "  4909/157086 [..............................] - ETA: 26:46 - loss: 0.5501"
     ]
    }
   ],
   "source": [
    "model_version = 'patch_desc_ae_' + datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + '16_alex_3conv3mp_2020_augm_relu_dwnsmpl'\n",
    "\n",
    "os.system('mkdir ' + base_dir + '/weights_' + model_version)\n",
    "print(base_dir + '/weights_' + model_version)\n",
    "\n",
    "checkpointer = ModelCheckpoint(base_dir + '/weights' + model_version + '/weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "history_callback = autoencoder.fit(image_datagen.flow(x_train, y_train, batch_size),\n",
    "                steps_per_epoch=x_train.shape[0],\n",
    "                epochs=50,\n",
    "                validation_data=image_datagen.flow(x_validation, y_validation, batch_size),\n",
    "                validation_steps=x_validation.shape[0],\n",
    "                callbacks=[WandbCallback(data_type=\"image\", predictions=1)]  # checkpointer,\n",
    "                )\n",
    "autoencoder.save(base_dir + '/' + model_version + '.h5')\n",
    "\n",
    "# autoencoder = load_model(base_dir + '/' + model_version + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.save(\"patch_desc_ae.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-7da56333b3d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'run' is not defined"
     ]
    }
   ],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6260780895730567,\n",
       "  0.6060252179512783,\n",
       "  0.5951909043093382,\n",
       "  0.588207898284687,\n",
       "  0.5833361623148873,\n",
       "  0.5799492780454653,\n",
       "  0.5769948917999261,\n",
       "  0.5743361962744195,\n",
       "  0.5720426948748691,\n",
       "  0.5698638599777025,\n",
       "  0.5676000748724821,\n",
       "  0.5657318284355146,\n",
       "  0.5641393776841065,\n",
       "  0.5627947944526468,\n",
       "  0.5617694119784642,\n",
       "  0.5608027577650637,\n",
       "  0.5600350316976609,\n",
       "  0.5593533768477567,\n",
       "  0.5587979410897435,\n",
       "  0.5582050857955804,\n",
       "  0.5576595787509168,\n",
       "  0.5571195382178122,\n",
       "  0.5566236612007337,\n",
       "  0.5562273534259203,\n",
       "  0.5558319495437104,\n",
       "  0.5555073794478311,\n",
       "  0.5550484862207733,\n",
       "  0.5547436577936862,\n",
       "  0.5544176297240138,\n",
       "  0.5541249228143352,\n",
       "  0.5538740699875232,\n",
       "  0.5535941227033367,\n",
       "  0.5533041276490459,\n",
       "  0.5530735796840777,\n",
       "  0.5528197375556622,\n",
       "  0.5525572038842139,\n",
       "  0.5523434904168886,\n",
       "  0.5521194740207648,\n",
       "  0.5519301754113966,\n",
       "  0.5517560552052996,\n",
       "  0.5515187149046759,\n",
       "  0.5513685217808938,\n",
       "  0.5511926709600107,\n",
       "  0.5510058692489587,\n",
       "  0.5509256292565424,\n",
       "  0.5507246349125703,\n",
       "  0.5505046757507283,\n",
       "  0.5503698822267932,\n",
       "  0.5502059146284369,\n",
       "  0.5500730758269242]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_callback.history  # why is it not lookint at val_loss? this could also explain why the checkpointer didn't see the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# didn't execute from here onward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'base_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7458dc43a9f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimages_directory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/tiny_test16/class0'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'base_dir' is not defined"
     ]
    }
   ],
   "source": [
    "images_directory = base_dir + '/tiny_test16/class0'\n",
    "files = os.listdir(images_directory)\n",
    "files.sort()\n",
    "\n",
    "images = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for file in files:\n",
    "    counter += 1\n",
    "    if counter > 100:\n",
    "        break\n",
    "    if not file.startswith('.'):\n",
    "        #print(file)\n",
    "        \n",
    "        img = load_img(images_directory + '/' + file, False, target_size=(patch_size, patch_size))\n",
    "        x = img_to_array(img)\n",
    "        \n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        images.append(x)\n",
    "        \n",
    "\n",
    "\n",
    "images = np.array(images).reshape(np.array(images).shape[0], input_shape[0], input_shape[1], input_shape[2])\n",
    "images /= 255\n",
    "predictions = autoencoder.predict_on_batch(np.array(images))\n",
    "print(\"predictions: \")\n",
    "for i, im1 in enumerate(images):\n",
    "    im_1 = im1.reshape(input_shape)\n",
    "    plt.imshow(im_1, interpolation='nearest')\n",
    "    plt.show()\n",
    "    \n",
    "    pred_1 = predictions[i].reshape(input_shape)\n",
    "    plt.imshow(pred_1, interpolation='nearest')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"next\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 16, 16, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 32)          0         \n",
      "=================================================================\n",
      "Total params: 19,392\n",
      "Trainable params: 19,392\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = Model(input_img, encoded)\n",
    "for layer in encoder.layers:\n",
    "    encoder.get_layer(layer.name).set_weights(autoencoder.get_layer(layer.name).get_weights())\n",
    "encoder.summary()\n",
    "\n",
    "encoder.save(base_dir + '/encoder' + model_version + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_shape = (8, 2, 2)\n",
    "\n",
    "images_directory = base_dir + '/tiny_test16/class0'\n",
    "files = os.listdir(images_directory)\n",
    "files.sort()\n",
    "\n",
    "images = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for file in files:\n",
    "    counter += 1\n",
    "#     if counter > 100:\n",
    "#         break\n",
    "    if not file.startswith('.'):\n",
    "        #print(file)\n",
    "        \n",
    "        img = load_img(images_directory + '/' + file, False, target_size=(patch_size, patch_size))\n",
    "        x = img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        images.append(x)\n",
    "        \n",
    "\n",
    "\n",
    "images = np.array(images).reshape(np.array(images).shape[0], input_shape[0], input_shape[1], input_shape[2]) #patch_size, patch_size, 3\n",
    "images /= 255\n",
    "predictions = encoder.predict_on_batch(np.array(images))\n",
    "# print(\"predictions: \")\n",
    "\n",
    "# for i, im1 in enumerate(images):\n",
    "#     im_1 = im1.reshape(input_shape)\n",
    "#     plt.imshow(im_1, interpolation='nearest')\n",
    "#     plt.show()\n",
    "    \n",
    "#     pred_1 = predictions[i].reshape(code_shape)\n",
    "#     plt.imshow(pred_1, interpolation='nearest')\n",
    "#     plt.show()\n",
    "    \n",
    "#     print(\"next\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_2",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
