{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import listdir\n",
    "from os import system\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import imageio\n",
    "from skimage.measure import block_reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 16\n",
    "nb_channels = 3\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/niaki/Code/ImageNet/tiny-imagenet-200'\n",
    "\n",
    "train_data_dir      = base_dir + '/tiny_train16'\n",
    "validation_data_dir = base_dir + '/tiny_validation16'\n",
    "test_data_dir       = base_dir + '/tiny_test16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_data(dir_patches):\n",
    "    \"\"\"Load all the patches from dir_patches into tensors for training the autoencoder.\n",
    "    Return:\n",
    "        patches_in  -- tensor of stacked patches in their original shape, 16x16\n",
    "        patches_out -- tensor of the original patches downsampled to 8x8\n",
    "    \n",
    "    \"\"\"\n",
    "    files_patches = listdir(dir_patches + '/class0')\n",
    "    files_patches.sort()\n",
    "    \n",
    "    patches_in = []\n",
    "    patches_out = []\n",
    "\n",
    "    \n",
    "    for file_patch in files_patches:\n",
    "        patch_in = imageio.imread(dir_patches + '/class0/' + file_patch)\n",
    "        \n",
    "        patch_out = block_reduce(patch_in, (2, 2, 1), func=np.mean)  # downsample (mean-pool)\n",
    "        \n",
    "        patches_in.append(patch_in)\n",
    "        patches_out.append(patch_out)\n",
    "        \n",
    "\n",
    "    patches_in = np.array(patches_in)\n",
    "    patches_in = patches_in.astype(np.float64) / 255\n",
    "#     patches_in = np.expand_dims(patches_in, -1)  # need this if grayscale\n",
    "    \n",
    "    patches_out = np.array(patches_out)\n",
    "    patches_out = patches_out.astype(np.float64) / 255\n",
    "#     patches_out = np.expand_dims(patches_out, -1)  # need this if grayscale\n",
    "        \n",
    "    print(\"in\", patches_in.shape, \"; out\", patches_out.shape)\n",
    "    \n",
    "    return patches_in, patches_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in (157086, 16, 16, 3) ; out (157086, 8, 8, 3)\n",
      "in (3932, 16, 16, 3) ; out (3932, 8, 8, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = loading_data(train_data_dir)\n",
    "x_validation, y_validation = loading_data(validation_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAC+ZJREFUeJzt3V2IHfUZx/Hfb9/URJNYq0UTrQpWsYUaCVIbEExUtIpa6EVCFZRCbqooFUR714sWeiP2olgkagWt0kYFK1ZrUVFpa82bNrpaYqpkfVtTzdtGXXfz9GJPwpqs7mzOzP+cffh+YMme3eE8z+Tsb2fO7Mw8jggByKmn0w0AaA4BBxIj4EBiBBxIjIADiRFwIDECDiRGwIHECDiQWF8TTzpv3tw47tijm3jqg7hIlc5wwbXL+v9ol12zUtXeG/5I23funrZcIwE/7tijdduvftrEUx+kp+AL2OveYrUkqbdg7Pp6yq1byf/FvsKvWV9vmXrX3PTrSsuxiw4kRsCBxAg4kBgBBxIj4EBiBBxIjIADiRFwILFKAbd9se03bG+2fUvTTQGox7QBt90r6beSLpF0pqSVts9sujEA7auyBT9H0uaI2BIRo5IelHRFs20BqEOVgC+UtHXS46HW1wB0uSoBn+qKh4Nupm57le21ttfu3DnSfmcA2lYl4EOSTpz0eJGkdw9cKCLujIglEbFk3ry5dfUHoA1VAv6SpNNsn2J7QNIKSY822xaAOkx7PXhEjNm+TtKTmriU9+6IeLXxzgC0rdINHyLicUmPN9wLgJpxJhuQGAEHEiPgQGIEHEiMgAOJEXAgMQIOJEbAgcQamWxiSb3NPPVBelzud1Rf4QE//VGuXv9YsVLq2bu3WK2BwqOLDusrM9mk56DLvb5kuWbbANBJBBxIjIADiRFwIDECDiRGwIHECDiQGAEHEiPgQGJVJpvcbXvY9qYSDQGoT5Ut+O8lXdxwHwAaMG3AI+I5SR8V6AVAzXgPDiRWW8Anjy7awegioCvUFvDJo4vmM7oI6ArsogOJVfkz2QOS/iHpdNtDtn/SfFsA6lBlNtnKEo0AqB+76EBiBBxIjIADiRFwIDECDiRGwIHECDiQGAEHEmtkvlBPWEeMlRld1N9bZlSMJGlsvFwtSXs+3l6s1ptb/lus1q5t24rVGtmxq1gtSRroL/Nzv+OjjystxxYcSIyAA4kRcCAxAg4kRsCBxAg4kBgBBxIj4EBiBBxIjIADiVW56eKJtp+xPWj7Vds3lGgMQPuqnDg7JummiFhv+yhJ62w/FRGvNdwbgDZVmU32XkSsb32+S9KgpIVNNwagfTN6D277ZEmLJb04xff2jy7azugioCtUDrjtIyU9JOnGiNh54Pcnjy5awOgioCtUCrjtfk2E+/6IeLjZlgDUpcpRdEu6S9JgRNzWfEsA6lJlC75U0tWSltne2Pr4QcN9AahBldlkL0hygV4A1Iwz2YDECDiQGAEHEiPgQGIEHEiMgAOJEXAgMQIOJNbIIKX4fFyff3DQ9SiNWP/Ky0XqSNLgpk3FaknS/z4cLlZr/LPPi9U67ugFxWodPjBQrJYkjewu83P/6Z5PKi3HFhxIjIADiRFwIDECDiRGwIHECDiQGAEHEiPgQGIEHEisyk0XD7f9L9svt0YX/aJEYwDaV+VU1c8kLYuI3a3bJ79g+y8R8c+GewPQpio3XQxJu1sP+1sf0WRTAOpRdfBBr+2NkoYlPRURXzm6aMfInrr7BHAIKgU8IsYj4ixJiySdY/s7Uyyzf3TR/Llz6u4TwCGY0VH0iNgu6VlJFzfSDYBaVTmKfqztBa3Pj5B0gaTXm24MQPuqHEU/XtK9tns18QvhjxHxWLNtAahDlaPor2hiJjiAWYYz2YDECDiQGAEHEiPgQGIEHEiMgAOJEXAgMQIOJOaJq0HrNb+/L75/zJG1P+9UeuwidSRJ3luulqQzv31GsVoXXbi8WK0FX5tfrFbp12x8fKxInWt/+TsNvv3OtD/8bMGBxAg4kBgBBxIj4EBiBBxIjIADiRFwIDECDiRGwIHEKge8dW/0Dba5HxswS8xkC36DpMGmGgFQv6qTTRZJulTS6mbbAVCnqlvw2yXdLKnsmfsA2lJl8MFlkoYjYt00y+2fTTa6l98DQDeosgVfKuly229JelDSMtv3HbjQ5NlkAz0cnAe6wbRJjIhbI2JRRJwsaYWkpyPiqsY7A9A2NrVAYlVmk+0XEc9qYroogFmALTiQGAEHEiPgQGIEHEiMgAOJEXAgMQIOJEbAgcRmdKJLVWPj4/po50gTT32QKHhhywknnVCsliSddMa3itXqPeaoYrX2HFZuuzIaZUYJ7fPpZ6NF6oy52sgxtuBAYgQcSIyAA4kRcCAxAg4kRsCBxAg4kBgBBxIj4EBilc5ka91RdZekcUljEbGkyaYA1GMmp6qeHxHbGusEQO3YRQcSqxrwkPRX2+tsr2qyIQD1qbqLvjQi3rV9nKSnbL8eEc9NXqAV/FWSNOCauwRwSCptwSPi3da/w5IekXTOFMvsH13UyDWoAGasyvDBubaP2ve5pIskbWq6MQDtq7Kx/YakR2zvW/4PEfFEo10BqMW0AY+ILZK+W6AXADXjz2RAYgQcSIyAA4kRcCAxAg4kRsCBxAg4kBgBBxJr7rTxapNV2tZbbnKRRt4ZLldM0uP3rilW68/3fV6s1vcuOL9YreVXXlSsliSNH17mSiv3VKvDFhxIjIADiRFwIDECDiRGwIHECDiQGAEHEiPgQGIEHEisUsBtL7C9xvbrtgdtn9t0YwDaV/VU1d9IeiIifmR7QNKcBnsCUJNpA257nqTzJF0jSRExKmm02bYA1KHKLvqpkj6UdI/tDbZXt+6PDqDLVQl4n6SzJd0REYsljUi65cCFbK+yvdb22rFCV5IB+GpVAj4kaSgiXmw9XqOJwH/BF0YXMZsM6ArTBjwi3pe01fbprS8tl/Rao10BqEXVo+jXS7q/dQR9i6Rrm2sJQF0qBTwiNkpa0nAvAGrGmWxAYgQcSIyAA4kRcCAxAg4kRsCBxAg4kBgBBxIj4EBijcwm2ytpd6EryuYU/B0VY8VKSZKOGCu3br0DRxSrteGJ54rV+vvfni9WS5Ku/PEPi9T5dPcnlZZjCw4kRsCBxAg4kBgBBxIj4EBiBBxIjIADiRFwIDECDiQ2bcBtn25746SPnbZvLNEcgPZMe6pqRLwh6SxJst0r6R1JjzTcF4AazHQXfbmkNyPi7SaaAVCvmV5sskLSA1N9w/YqSaskqb/NpgDUo/IWvDX04HJJf5rq+5NHF/UyugjoCjPZRb9E0vqI+KCpZgDUayYBX6kv2T0H0J0qBdz2HEkXSnq42XYA1KnqbLI9ko5puBcANeNMNiAxAg4kRsCBxAg4kBgBBxIj4EBiBBxIjIADiTmi/hlDtj+UNNNLSr8uaVvtzXSHrOvGenXONyPi2OkWaiTgh8L22ohY0uk+mpB13Viv7scuOpAYAQcS66aA39npBhqUdd1Yry7XNe/BAdSvm7bgAGrWFQG3fbHtN2xvtn1Lp/upg+0TbT9je9D2q7Zv6HRPdbLda3uD7cc63UudbC+wvcb2663X7txO99SOju+it+61/h9N3DFmSNJLklZGxGsdbaxNto+XdHxErLd9lKR1kq6c7eu1j+2fSVoiaV5EXNbpfupi+15Jz0fE6taNRudExPZO93WoumELfo6kzRGxJSJGJT0o6YoO99S2iHgvIta3Pt8laVDSws52VQ/biyRdKml1p3upk+15ks6TdJckRcTobA631B0BXyhp66THQ0oShH1snyxpsaQXO9tJbW6XdLOkvZ1upGanSvpQ0j2ttx+rbc/tdFPt6IaAT3UX9TSH9m0fKekhSTdGxM5O99Mu25dJGo6IdZ3upQF9ks6WdEdELJY0ImlWHxPqhoAPSTpx0uNFkt7tUC+1st2viXDfHxFZ7ki7VNLltt/SxNupZbbv62xLtRmSNBQR+/a01mgi8LNWNwT8JUmn2T6ldVBjhaRHO9xT22xbE+/lBiPitk73U5eIuDUiFkXEyZp4rZ6OiKs63FYtIuJ9SVttn9760nJJs/qg6Exnk9UuIsZsXyfpSUm9ku6OiFc73FYdlkq6WtK/bW9sfe3nEfF4B3vC9K6XdH9rY7NF0rUd7qctHf8zGYDmdMMuOoCGEHAgMQIOJEbAgcQIOJAYAQcSI+BAYgQcSOz/9hXSVdjlXbQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_index = np.random.randint(x_train.shape[0]) #  5429\n",
    "# print(np.array(np.round(x_train[temp_index] * 255), dtype=np.uint8))\n",
    "plt.imshow(np.array(np.round(x_train[temp_index] * 255), dtype=np.uint8))\n",
    "plt.show()\n",
    "plt.imshow(np.array(np.round(y_train[temp_index] * 255), dtype=np.uint8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 16, 16, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 16, 16, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 2, 32)          9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 3)           867       \n",
      "=================================================================\n",
      "Total params: 38,755\n",
      "Trainable params: 38,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (patch_size, patch_size, nb_channels)\n",
    "input_img = Input(shape=input_shape)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(input_img)\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = MaxPool2D((2, 2), padding=\"same\")(x)\n",
    "x = MaxPool2D((2, 2), padding=\"same\")(x)\n",
    "encoded = MaxPool2D((2, 2), padding=\"same\")(x)\n",
    "\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(3, (3, 3), activation=\"relu\", padding=\"same\")(x)  # 32\n",
    "# x = UpSampling2D((2, 2))(x)\n",
    "# decoded = Conv2D(3, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datagen = ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n",
    "    width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
    "    horizontal_flip=False, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "# os.environ['WANDB_MODE'] = 'dryrun'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: nimpy (use `wandb login --relogin` to force relogin)\n",
      "wandb: wandb version 0.10.8 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.7<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">curious-brook-3</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nimpy/patch-desc-ae\" target=\"_blank\">https://wandb.ai/nimpy/patch-desc-ae</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/nimpy/patch-desc-ae/runs/183kde2v\" target=\"_blank\">https://wandb.ai/nimpy/patch-desc-ae/runs/183kde2v</a><br/>\n",
       "                Run data is saved locally in <code>wandb/run-20201023_153238-183kde2v</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "  project=\"patch-desc-ae\",\n",
    "  config={\n",
    "    \"augmentation\": True,\n",
    "    \"elus\": False,\n",
    "    \"downsampling_output\": True,\n",
    "    \"optimizer\": \"adadelta\", \n",
    "    \"loss\": \"binary_crossentropy\",\n",
    "    \"epochs\": 500 }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://wandb.ai/nimpy/patch-desc-ae/runs/183kde2v?jupyter=true\" style=\"border:none;width:100%;height:420px\">\n",
       "                </iframe>"
      ],
      "text/plain": [
       "<wandb.jupyter.Run at 0x7f7eb454d898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/niaki/Code/ImageNet/tiny-imagenet-200/weights_patch_desc_ae_20201023_15325716_alex_3conv3mp_2020_augm_relu_dwnsmpl\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 4909 steps, validate for 123 steps\n",
      "Epoch 1/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.6428 - val_loss: 0.6176\n",
      "Epoch 2/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.6112 - val_loss: 0.6013\n",
      "Epoch 3/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5999 - val_loss: 0.5919\n",
      "Epoch 4/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5922 - val_loss: 0.5854\n",
      "Epoch 5/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5868 - val_loss: 0.5800\n",
      "Epoch 6/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5823 - val_loss: 0.5765\n",
      "Epoch 7/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5787 - val_loss: 0.5727\n",
      "Epoch 8/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5753 - val_loss: 0.5693\n",
      "Epoch 9/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5718 - val_loss: 0.5664\n",
      "Epoch 10/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5686 - val_loss: 0.5629\n",
      "Epoch 11/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5658 - val_loss: 0.5605\n",
      "Epoch 12/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5638 - val_loss: 0.5590\n",
      "Epoch 13/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5625 - val_loss: 0.5577\n",
      "Epoch 14/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5615 - val_loss: 0.5566\n",
      "Epoch 15/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5604 - val_loss: 0.5560\n",
      "Epoch 16/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5597 - val_loss: 0.5553\n",
      "Epoch 17/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5589 - val_loss: 0.5545\n",
      "Epoch 18/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5582 - val_loss: 0.5541\n",
      "Epoch 19/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5576 - val_loss: 0.5531\n",
      "Epoch 20/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5571 - val_loss: 0.5527\n",
      "Epoch 21/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5566 - val_loss: 0.5523\n",
      "Epoch 22/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5561 - val_loss: 0.5517\n",
      "Epoch 23/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5557 - val_loss: 0.5512\n",
      "Epoch 24/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5553 - val_loss: 0.5509\n",
      "Epoch 25/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5550 - val_loss: 0.5504\n",
      "Epoch 26/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5546 - val_loss: 0.5503\n",
      "Epoch 27/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5544 - val_loss: 0.5499\n",
      "Epoch 28/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5540 - val_loss: 0.5496\n",
      "Epoch 29/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5538 - val_loss: 0.5495\n",
      "Epoch 30/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5535 - val_loss: 0.5492\n",
      "Epoch 31/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5533 - val_loss: 0.5489\n",
      "Epoch 32/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5530 - val_loss: 0.5488\n",
      "Epoch 33/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5527 - val_loss: 0.5481\n",
      "Epoch 34/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5525 - val_loss: 0.5480\n",
      "Epoch 35/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5522 - val_loss: 0.5476\n",
      "Epoch 36/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5521 - val_loss: 0.5475\n",
      "Epoch 37/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5518 - val_loss: 0.5474\n",
      "Epoch 38/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5517 - val_loss: 0.5471\n",
      "Epoch 39/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5514 - val_loss: 0.5470\n",
      "Epoch 40/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5513 - val_loss: 0.5468\n",
      "Epoch 41/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5510 - val_loss: 0.5469\n",
      "Epoch 42/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5508 - val_loss: 0.5462\n",
      "Epoch 43/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5507 - val_loss: 0.5461\n",
      "Epoch 44/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5505 - val_loss: 0.5462\n",
      "Epoch 45/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5504 - val_loss: 0.5464\n",
      "Epoch 46/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5502 - val_loss: 0.5457\n",
      "Epoch 47/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5501 - val_loss: 0.5458\n",
      "Epoch 48/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5499 - val_loss: 0.5457\n",
      "Epoch 49/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5498 - val_loss: 0.5453\n",
      "Epoch 50/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5496 - val_loss: 0.5452\n",
      "Epoch 51/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5494 - val_loss: 0.5451\n",
      "Epoch 52/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5493 - val_loss: 0.5447\n",
      "Epoch 53/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5491 - val_loss: 0.5446\n",
      "Epoch 54/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5490 - val_loss: 0.5445\n",
      "Epoch 55/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5488 - val_loss: 0.5445\n",
      "Epoch 56/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5487 - val_loss: 0.5445\n",
      "Epoch 57/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5486 - val_loss: 0.5446\n",
      "Epoch 58/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5484 - val_loss: 0.5442\n",
      "Epoch 59/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5482 - val_loss: 0.5439\n",
      "Epoch 60/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5481 - val_loss: 0.5437\n",
      "Epoch 61/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5480 - val_loss: 0.5435\n",
      "Epoch 62/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5479 - val_loss: 0.5435\n",
      "Epoch 63/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5478 - val_loss: 0.5434\n",
      "Epoch 64/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5477 - val_loss: 0.5436\n",
      "Epoch 65/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5476 - val_loss: 0.5433\n",
      "Epoch 66/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5475 - val_loss: 0.5432\n",
      "Epoch 67/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5473 - val_loss: 0.5431\n",
      "Epoch 68/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5472 - val_loss: 0.5424\n",
      "Epoch 69/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5471 - val_loss: 0.5428\n",
      "Epoch 70/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5470 - val_loss: 0.5427\n",
      "Epoch 71/500\n",
      "4909/4909 [==============================] - 54s 11ms/step - loss: 0.5470 - val_loss: 0.5423\n",
      "Epoch 72/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5469 - val_loss: 0.5428\n",
      "Epoch 73/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5468 - val_loss: 0.5422\n",
      "Epoch 74/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5466 - val_loss: 0.5425\n",
      "Epoch 75/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5466 - val_loss: 0.5422\n",
      "Epoch 76/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5465 - val_loss: 0.5423\n",
      "Epoch 77/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5464 - val_loss: 0.5420\n",
      "Epoch 78/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5463 - val_loss: 0.5422\n",
      "Epoch 79/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5463 - val_loss: 0.5418\n",
      "Epoch 80/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5462 - val_loss: 0.5420\n",
      "Epoch 81/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5461 - val_loss: 0.5415\n",
      "Epoch 82/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5460 - val_loss: 0.5420\n",
      "Epoch 83/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5460 - val_loss: 0.5415\n",
      "Epoch 84/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5459 - val_loss: 0.5418\n",
      "Epoch 85/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5458 - val_loss: 0.5412\n",
      "Epoch 86/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5458 - val_loss: 0.5412\n",
      "Epoch 87/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5456 - val_loss: 0.5413\n",
      "Epoch 88/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5457 - val_loss: 0.5409\n",
      "Epoch 89/500\n",
      "4909/4909 [==============================] - 66s 14ms/step - loss: 0.5455 - val_loss: 0.5413\n",
      "Epoch 90/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5455 - val_loss: 0.5410\n",
      "Epoch 91/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5454 - val_loss: 0.5407\n",
      "Epoch 92/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5454 - val_loss: 0.5410\n",
      "Epoch 93/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5453 - val_loss: 0.5409\n",
      "Epoch 94/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5452 - val_loss: 0.5407\n",
      "Epoch 95/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5451 - val_loss: 0.5410\n",
      "Epoch 96/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5451 - val_loss: 0.5408\n",
      "Epoch 97/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5451 - val_loss: 0.5408\n",
      "Epoch 98/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5450 - val_loss: 0.5406\n",
      "Epoch 99/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5450 - val_loss: 0.5406\n",
      "Epoch 100/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5449 - val_loss: 0.5408\n",
      "Epoch 101/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5448 - val_loss: 0.5401\n",
      "Epoch 102/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5448 - val_loss: 0.5404\n",
      "Epoch 103/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5447 - val_loss: 0.5403\n",
      "Epoch 104/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5447 - val_loss: 0.5404\n",
      "Epoch 105/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5446 - val_loss: 0.5402\n",
      "Epoch 106/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5446 - val_loss: 0.5402\n",
      "Epoch 107/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5446 - val_loss: 0.5400\n",
      "Epoch 108/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5445 - val_loss: 0.5402\n",
      "Epoch 109/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5444 - val_loss: 0.5400\n",
      "Epoch 110/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5444 - val_loss: 0.5404\n",
      "Epoch 111/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5443 - val_loss: 0.5404\n",
      "Epoch 112/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5444 - val_loss: 0.5397\n",
      "Epoch 113/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5443 - val_loss: 0.5396\n",
      "Epoch 114/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5443 - val_loss: 0.5397\n",
      "Epoch 115/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5442 - val_loss: 0.5398\n",
      "Epoch 116/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5442 - val_loss: 0.5396\n",
      "Epoch 117/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5441 - val_loss: 0.5398\n",
      "Epoch 118/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5441 - val_loss: 0.5400\n",
      "Epoch 119/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5440 - val_loss: 0.5393\n",
      "Epoch 120/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5439 - val_loss: 0.5397\n",
      "Epoch 121/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5440 - val_loss: 0.5395\n",
      "Epoch 122/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5439 - val_loss: 0.5398\n",
      "Epoch 123/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5439 - val_loss: 0.5394\n",
      "Epoch 124/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5438 - val_loss: 0.5395\n",
      "Epoch 125/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5438 - val_loss: 0.5393\n",
      "Epoch 126/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5438 - val_loss: 0.5391\n",
      "Epoch 127/500\n",
      "4909/4909 [==============================] - 54s 11ms/step - loss: 0.5437 - val_loss: 0.5394\n",
      "Epoch 128/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5437 - val_loss: 0.5390\n",
      "Epoch 129/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5437 - val_loss: 0.5396\n",
      "Epoch 130/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5436 - val_loss: 0.5389\n",
      "Epoch 131/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5436 - val_loss: 0.5389\n",
      "Epoch 132/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5435 - val_loss: 0.5389\n",
      "Epoch 133/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5436 - val_loss: 0.5394\n",
      "Epoch 134/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5434 - val_loss: 0.5395\n",
      "Epoch 135/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5435 - val_loss: 0.5393\n",
      "Epoch 136/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5434 - val_loss: 0.5389\n",
      "Epoch 137/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5434 - val_loss: 0.5392\n",
      "Epoch 138/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5433 - val_loss: 0.5388\n",
      "Epoch 139/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5433 - val_loss: 0.5389\n",
      "Epoch 140/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5433 - val_loss: 0.5391\n",
      "Epoch 141/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5433 - val_loss: 0.5387\n",
      "Epoch 142/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5432 - val_loss: 0.5389\n",
      "Epoch 143/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5432 - val_loss: 0.5389\n",
      "Epoch 144/500\n",
      "4909/4909 [==============================] - 54s 11ms/step - loss: 0.5432 - val_loss: 0.5390\n",
      "Epoch 145/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5431 - val_loss: 0.5388\n",
      "Epoch 146/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5431 - val_loss: 0.5390\n",
      "Epoch 147/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5431 - val_loss: 0.5388\n",
      "Epoch 148/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5430 - val_loss: 0.5386\n",
      "Epoch 149/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5431 - val_loss: 0.5387\n",
      "Epoch 150/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5430 - val_loss: 0.5387\n",
      "Epoch 151/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5430 - val_loss: 0.5385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5430 - val_loss: 0.5385\n",
      "Epoch 153/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5430 - val_loss: 0.5387\n",
      "Epoch 154/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5429 - val_loss: 0.5384\n",
      "Epoch 155/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5428 - val_loss: 0.5387\n",
      "Epoch 156/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5429 - val_loss: 0.5389\n",
      "Epoch 157/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5428 - val_loss: 0.5385\n",
      "Epoch 158/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5428 - val_loss: 0.5384\n",
      "Epoch 159/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5427 - val_loss: 0.5384\n",
      "Epoch 160/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5428 - val_loss: 0.5381\n",
      "Epoch 161/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5427 - val_loss: 0.5381\n",
      "Epoch 162/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5427 - val_loss: 0.5383\n",
      "Epoch 163/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5427 - val_loss: 0.5377\n",
      "Epoch 164/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5427 - val_loss: 0.5382\n",
      "Epoch 165/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5426 - val_loss: 0.5378\n",
      "Epoch 166/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5426 - val_loss: 0.5382\n",
      "Epoch 167/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5426 - val_loss: 0.5379\n",
      "Epoch 168/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5426 - val_loss: 0.5381\n",
      "Epoch 169/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5425 - val_loss: 0.5378\n",
      "Epoch 170/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5425 - val_loss: 0.5379\n",
      "Epoch 171/500\n",
      "4909/4909 [==============================] - 54s 11ms/step - loss: 0.5425 - val_loss: 0.5383\n",
      "Epoch 172/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5425 - val_loss: 0.5381\n",
      "Epoch 173/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5425 - val_loss: 0.5381\n",
      "Epoch 174/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5424 - val_loss: 0.5380\n",
      "Epoch 175/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5424 - val_loss: 0.5380\n",
      "Epoch 176/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5425 - val_loss: 0.5380\n",
      "Epoch 177/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5424 - val_loss: 0.5378\n",
      "Epoch 178/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5424 - val_loss: 0.5379\n",
      "Epoch 179/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5423 - val_loss: 0.5379\n",
      "Epoch 180/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5423 - val_loss: 0.5380\n",
      "Epoch 181/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5423 - val_loss: 0.5379\n",
      "Epoch 182/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5423 - val_loss: 0.5379\n",
      "Epoch 183/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5423 - val_loss: 0.5376\n",
      "Epoch 184/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5423 - val_loss: 0.5377\n",
      "Epoch 185/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5422 - val_loss: 0.5378\n",
      "Epoch 186/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5422 - val_loss: 0.5375\n",
      "Epoch 187/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5422 - val_loss: 0.5377\n",
      "Epoch 188/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5422 - val_loss: 0.5376\n",
      "Epoch 189/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5422 - val_loss: 0.5375\n",
      "Epoch 190/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5421 - val_loss: 0.5375\n",
      "Epoch 191/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5422 - val_loss: 0.5375\n",
      "Epoch 192/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5421 - val_loss: 0.5379\n",
      "Epoch 193/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5421 - val_loss: 0.5377\n",
      "Epoch 194/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5421 - val_loss: 0.5377\n",
      "Epoch 195/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5421 - val_loss: 0.5376\n",
      "Epoch 196/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5421 - val_loss: 0.5376\n",
      "Epoch 197/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5421 - val_loss: 0.5373\n",
      "Epoch 198/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5420 - val_loss: 0.5377\n",
      "Epoch 199/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5420 - val_loss: 0.5377\n",
      "Epoch 200/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5420 - val_loss: 0.5375\n",
      "Epoch 201/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5420 - val_loss: 0.5376\n",
      "Epoch 202/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5419 - val_loss: 0.5375\n",
      "Epoch 203/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5419 - val_loss: 0.5373\n",
      "Epoch 204/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5420 - val_loss: 0.5375\n",
      "Epoch 205/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5419 - val_loss: 0.5376\n",
      "Epoch 206/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5419 - val_loss: 0.5373\n",
      "Epoch 207/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5419 - val_loss: 0.5375\n",
      "Epoch 208/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5418 - val_loss: 0.5375\n",
      "Epoch 209/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5419 - val_loss: 0.5374\n",
      "Epoch 210/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5418 - val_loss: 0.5374\n",
      "Epoch 211/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5418 - val_loss: 0.5375\n",
      "Epoch 212/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5418 - val_loss: 0.5371\n",
      "Epoch 213/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5418 - val_loss: 0.5373\n",
      "Epoch 214/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5418 - val_loss: 0.5372\n",
      "Epoch 215/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5418 - val_loss: 0.5373\n",
      "Epoch 216/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5418 - val_loss: 0.5369\n",
      "Epoch 217/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5418 - val_loss: 0.5371\n",
      "Epoch 218/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5417 - val_loss: 0.5373\n",
      "Epoch 219/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5417 - val_loss: 0.5374\n",
      "Epoch 220/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5417 - val_loss: 0.5374\n",
      "Epoch 221/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5417 - val_loss: 0.5368\n",
      "Epoch 222/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5417 - val_loss: 0.5372\n",
      "Epoch 223/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5416 - val_loss: 0.5371\n",
      "Epoch 224/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5416 - val_loss: 0.5375\n",
      "Epoch 225/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5416 - val_loss: 0.5372\n",
      "Epoch 226/500\n",
      "4909/4909 [==============================] - 54s 11ms/step - loss: 0.5416 - val_loss: 0.5371\n",
      "Epoch 227/500\n",
      "4909/4909 [==============================] - 54s 11ms/step - loss: 0.5415 - val_loss: 0.5373\n",
      "Epoch 228/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5416 - val_loss: 0.5369\n",
      "Epoch 229/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5416 - val_loss: 0.5371\n",
      "Epoch 230/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5416 - val_loss: 0.5369\n",
      "Epoch 231/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5415 - val_loss: 0.5372\n",
      "Epoch 232/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5416 - val_loss: 0.5372\n",
      "Epoch 233/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5415 - val_loss: 0.5370\n",
      "Epoch 234/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5415 - val_loss: 0.5372\n",
      "Epoch 235/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5415 - val_loss: 0.5373\n",
      "Epoch 236/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5415 - val_loss: 0.5371\n",
      "Epoch 237/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5415 - val_loss: 0.5370\n",
      "Epoch 238/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5415 - val_loss: 0.5366\n",
      "Epoch 239/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5415 - val_loss: 0.5371\n",
      "Epoch 240/500\n",
      "4909/4909 [==============================] - 52s 11ms/step - loss: 0.5414 - val_loss: 0.5370\n",
      "Epoch 241/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5414 - val_loss: 0.5367\n",
      "Epoch 242/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5415 - val_loss: 0.5369\n",
      "Epoch 243/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5414 - val_loss: 0.5368\n",
      "Epoch 244/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5414 - val_loss: 0.5370\n",
      "Epoch 245/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5414 - val_loss: 0.5368\n",
      "Epoch 246/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5414 - val_loss: 0.5368\n",
      "Epoch 247/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5414 - val_loss: 0.5371\n",
      "Epoch 248/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5414 - val_loss: 0.5369\n",
      "Epoch 249/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5414 - val_loss: 0.5369\n",
      "Epoch 250/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5413 - val_loss: 0.5367\n",
      "Epoch 251/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5413 - val_loss: 0.5368\n",
      "Epoch 252/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5413 - val_loss: 0.5369\n",
      "Epoch 253/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5413 - val_loss: 0.5366\n",
      "Epoch 254/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5413 - val_loss: 0.5365\n",
      "Epoch 255/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5413 - val_loss: 0.5370\n",
      "Epoch 256/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5412 - val_loss: 0.5369\n",
      "Epoch 257/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5412 - val_loss: 0.5366\n",
      "Epoch 258/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5412 - val_loss: 0.5367\n",
      "Epoch 259/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5412 - val_loss: 0.5366\n",
      "Epoch 260/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5412 - val_loss: 0.5367\n",
      "Epoch 261/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5412 - val_loss: 0.5368\n",
      "Epoch 262/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5412 - val_loss: 0.5368\n",
      "Epoch 263/500\n",
      "4909/4909 [==============================] - 52s 11ms/step - loss: 0.5412 - val_loss: 0.5366\n",
      "Epoch 264/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5411 - val_loss: 0.5366\n",
      "Epoch 265/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5411 - val_loss: 0.5364\n",
      "Epoch 266/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5411 - val_loss: 0.5364\n",
      "Epoch 267/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5411 - val_loss: 0.5362\n",
      "Epoch 268/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5411 - val_loss: 0.5369\n",
      "Epoch 269/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5411 - val_loss: 0.5365\n",
      "Epoch 270/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5411 - val_loss: 0.5366\n",
      "Epoch 271/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5410 - val_loss: 0.5366\n",
      "Epoch 272/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5411 - val_loss: 0.5366\n",
      "Epoch 273/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5411 - val_loss: 0.5369\n",
      "Epoch 274/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5411 - val_loss: 0.5366\n",
      "Epoch 275/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5410 - val_loss: 0.5364\n",
      "Epoch 276/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5410 - val_loss: 0.5367\n",
      "Epoch 277/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5411 - val_loss: 0.5368\n",
      "Epoch 278/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5410 - val_loss: 0.5363\n",
      "Epoch 279/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5410 - val_loss: 0.5366\n",
      "Epoch 280/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5410 - val_loss: 0.5363\n",
      "Epoch 281/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5410 - val_loss: 0.5366\n",
      "Epoch 282/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5410 - val_loss: 0.5364\n",
      "Epoch 283/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5410 - val_loss: 0.5364\n",
      "Epoch 284/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5409 - val_loss: 0.5365\n",
      "Epoch 285/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5409 - val_loss: 0.5364\n",
      "Epoch 286/500\n",
      "4909/4909 [==============================] - 52s 11ms/step - loss: 0.5409 - val_loss: 0.5365\n",
      "Epoch 287/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5409 - val_loss: 0.5362\n",
      "Epoch 288/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5409 - val_loss: 0.5364\n",
      "Epoch 289/500\n",
      "4909/4909 [==============================] - 52s 11ms/step - loss: 0.5409 - val_loss: 0.5360\n",
      "Epoch 290/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5409 - val_loss: 0.5364\n",
      "Epoch 291/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5409 - val_loss: 0.5366\n",
      "Epoch 292/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5409 - val_loss: 0.5369\n",
      "Epoch 293/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5409 - val_loss: 0.5367\n",
      "Epoch 294/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5409 - val_loss: 0.5365\n",
      "Epoch 295/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5409 - val_loss: 0.5363\n",
      "Epoch 296/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5408 - val_loss: 0.5362\n",
      "Epoch 297/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5408 - val_loss: 0.5361\n",
      "Epoch 298/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5408 - val_loss: 0.5362\n",
      "Epoch 299/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5409 - val_loss: 0.5364\n",
      "Epoch 300/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5409 - val_loss: 0.5361\n",
      "Epoch 301/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5408 - val_loss: 0.5366\n",
      "Epoch 302/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5408 - val_loss: 0.5365\n",
      "Epoch 303/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5408 - val_loss: 0.5361\n",
      "Epoch 304/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5408 - val_loss: 0.5363\n",
      "Epoch 305/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5408 - val_loss: 0.5362\n",
      "Epoch 306/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5407 - val_loss: 0.5364\n",
      "Epoch 307/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5407 - val_loss: 0.5363\n",
      "Epoch 308/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5407 - val_loss: 0.5363\n",
      "Epoch 309/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5408 - val_loss: 0.5362\n",
      "Epoch 310/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5407 - val_loss: 0.5363\n",
      "Epoch 311/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5408 - val_loss: 0.5364\n",
      "Epoch 312/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5407 - val_loss: 0.5362\n",
      "Epoch 313/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5407 - val_loss: 0.5362\n",
      "Epoch 314/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5407 - val_loss: 0.5364\n",
      "Epoch 315/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5407 - val_loss: 0.5363\n",
      "Epoch 316/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5407 - val_loss: 0.5362\n",
      "Epoch 317/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5407 - val_loss: 0.5362\n",
      "Epoch 318/500\n",
      "4909/4909 [==============================] - 65s 13ms/step - loss: 0.5407 - val_loss: 0.5362\n",
      "Epoch 319/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5407 - val_loss: 0.5363\n",
      "Epoch 320/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5407 - val_loss: 0.5359\n",
      "Epoch 321/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5407 - val_loss: 0.5359\n",
      "Epoch 322/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5406 - val_loss: 0.5361\n",
      "Epoch 323/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5406 - val_loss: 0.5364\n",
      "Epoch 324/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5406 - val_loss: 0.5360\n",
      "Epoch 325/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5407 - val_loss: 0.5363\n",
      "Epoch 326/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5406 - val_loss: 0.5362\n",
      "Epoch 327/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5407 - val_loss: 0.5363\n",
      "Epoch 328/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5406 - val_loss: 0.5360\n",
      "Epoch 329/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5405 - val_loss: 0.5362\n",
      "Epoch 330/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5405 - val_loss: 0.5361\n",
      "Epoch 331/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5405 - val_loss: 0.5364\n",
      "Epoch 332/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5406 - val_loss: 0.5359\n",
      "Epoch 333/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5405 - val_loss: 0.5358\n",
      "Epoch 334/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5406 - val_loss: 0.5361\n",
      "Epoch 335/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5406 - val_loss: 0.5358\n",
      "Epoch 336/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5406 - val_loss: 0.5362\n",
      "Epoch 337/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5405 - val_loss: 0.5358\n",
      "Epoch 338/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5406 - val_loss: 0.5359\n",
      "Epoch 339/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5405 - val_loss: 0.5358\n",
      "Epoch 340/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5405 - val_loss: 0.5360\n",
      "Epoch 341/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5405 - val_loss: 0.5361\n",
      "Epoch 342/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5405 - val_loss: 0.5359\n",
      "Epoch 343/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5405 - val_loss: 0.5361\n",
      "Epoch 344/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5405 - val_loss: 0.5357\n",
      "Epoch 345/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5405 - val_loss: 0.5357\n",
      "Epoch 346/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5405 - val_loss: 0.5360\n",
      "Epoch 347/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5405 - val_loss: 0.5358\n",
      "Epoch 348/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5404 - val_loss: 0.5358\n",
      "Epoch 349/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5405 - val_loss: 0.5361\n",
      "Epoch 350/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5404 - val_loss: 0.5360\n",
      "Epoch 351/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5404 - val_loss: 0.5359\n",
      "Epoch 352/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5404 - val_loss: 0.5360\n",
      "Epoch 353/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5404 - val_loss: 0.5359\n",
      "Epoch 354/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5404 - val_loss: 0.5362\n",
      "Epoch 355/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5404 - val_loss: 0.5362\n",
      "Epoch 356/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5404 - val_loss: 0.5359\n",
      "Epoch 357/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5404 - val_loss: 0.5360\n",
      "Epoch 358/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5404 - val_loss: 0.5358\n",
      "Epoch 359/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5403 - val_loss: 0.5360\n",
      "Epoch 360/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5403 - val_loss: 0.5358\n",
      "Epoch 361/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5403 - val_loss: 0.5359\n",
      "Epoch 362/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5403 - val_loss: 0.5357\n",
      "Epoch 363/500\n",
      "4909/4909 [==============================] - 52s 11ms/step - loss: 0.5404 - val_loss: 0.5360\n",
      "Epoch 364/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5404 - val_loss: 0.5360\n",
      "Epoch 365/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5403 - val_loss: 0.5358\n",
      "Epoch 366/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5403 - val_loss: 0.5357\n",
      "Epoch 367/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5404 - val_loss: 0.5356\n",
      "Epoch 368/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5403 - val_loss: 0.5354\n",
      "Epoch 369/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5403 - val_loss: 0.5358\n",
      "Epoch 370/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5403 - val_loss: 0.5355\n",
      "Epoch 371/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5403 - val_loss: 0.5359\n",
      "Epoch 372/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5403 - val_loss: 0.5356\n",
      "Epoch 373/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5402 - val_loss: 0.5357\n",
      "Epoch 374/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5403 - val_loss: 0.5359\n",
      "Epoch 375/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5402 - val_loss: 0.5359\n",
      "Epoch 376/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5403 - val_loss: 0.5358\n",
      "Epoch 377/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5403 - val_loss: 0.5359\n",
      "Epoch 378/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5403 - val_loss: 0.5358\n",
      "Epoch 379/500\n",
      "4909/4909 [==============================] - 52s 11ms/step - loss: 0.5402 - val_loss: 0.5360\n",
      "Epoch 380/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5402 - val_loss: 0.5360\n",
      "Epoch 381/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5403 - val_loss: 0.5357\n",
      "Epoch 382/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5403 - val_loss: 0.5357\n",
      "Epoch 383/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5403 - val_loss: 0.5357\n",
      "Epoch 384/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5402 - val_loss: 0.5355\n",
      "Epoch 385/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5402 - val_loss: 0.5356\n",
      "Epoch 386/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5402 - val_loss: 0.5359\n",
      "Epoch 387/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5402 - val_loss: 0.5359\n",
      "Epoch 388/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5402 - val_loss: 0.5357\n",
      "Epoch 389/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5402 - val_loss: 0.5355\n",
      "Epoch 390/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5402 - val_loss: 0.5361\n",
      "Epoch 391/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5402 - val_loss: 0.5357\n",
      "Epoch 392/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5402 - val_loss: 0.5356\n",
      "Epoch 393/500\n",
      "4909/4909 [==============================] - 54s 11ms/step - loss: 0.5402 - val_loss: 0.5357\n",
      "Epoch 394/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5401 - val_loss: 0.5356\n",
      "Epoch 395/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5401 - val_loss: 0.5358\n",
      "Epoch 396/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5402 - val_loss: 0.5357\n",
      "Epoch 397/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5401 - val_loss: 0.5355\n",
      "Epoch 398/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5401 - val_loss: 0.5358\n",
      "Epoch 399/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5401 - val_loss: 0.5357\n",
      "Epoch 400/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5401 - val_loss: 0.5356\n",
      "Epoch 401/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5401 - val_loss: 0.5357\n",
      "Epoch 402/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5402 - val_loss: 0.5361\n",
      "Epoch 403/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5401 - val_loss: 0.5357\n",
      "Epoch 404/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5401 - val_loss: 0.5358\n",
      "Epoch 405/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5401 - val_loss: 0.5355\n",
      "Epoch 406/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5401 - val_loss: 0.5357\n",
      "Epoch 407/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5401 - val_loss: 0.5359\n",
      "Epoch 408/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5401 - val_loss: 0.5357\n",
      "Epoch 409/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5400 - val_loss: 0.5354\n",
      "Epoch 410/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5401 - val_loss: 0.5355\n",
      "Epoch 411/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5401 - val_loss: 0.5359\n",
      "Epoch 412/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5401 - val_loss: 0.5357\n",
      "Epoch 413/500\n",
      "4909/4909 [==============================] - 54s 11ms/step - loss: 0.5400 - val_loss: 0.5356\n",
      "Epoch 414/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5400 - val_loss: 0.5358\n",
      "Epoch 415/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5401 - val_loss: 0.5356\n",
      "Epoch 416/500\n",
      "4909/4909 [==============================] - 54s 11ms/step - loss: 0.5400 - val_loss: 0.5356\n",
      "Epoch 417/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5400 - val_loss: 0.5354\n",
      "Epoch 418/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5400 - val_loss: 0.5354\n",
      "Epoch 419/500\n",
      "4909/4909 [==============================] - 54s 11ms/step - loss: 0.5400 - val_loss: 0.5354\n",
      "Epoch 420/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5400 - val_loss: 0.5358\n",
      "Epoch 421/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5400 - val_loss: 0.5353\n",
      "Epoch 422/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5400 - val_loss: 0.5355\n",
      "Epoch 423/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5399 - val_loss: 0.5354\n",
      "Epoch 424/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5400 - val_loss: 0.5359\n",
      "Epoch 425/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5399 - val_loss: 0.5358\n",
      "Epoch 426/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5399 - val_loss: 0.5355\n",
      "Epoch 427/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5400 - val_loss: 0.5357\n",
      "Epoch 428/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5400 - val_loss: 0.5356\n",
      "Epoch 429/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5399 - val_loss: 0.5357\n",
      "Epoch 430/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5400 - val_loss: 0.5354\n",
      "Epoch 431/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5399 - val_loss: 0.5356\n",
      "Epoch 432/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5399 - val_loss: 0.5356\n",
      "Epoch 433/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5399 - val_loss: 0.5357\n",
      "Epoch 434/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5399 - val_loss: 0.5353\n",
      "Epoch 435/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5400 - val_loss: 0.5358\n",
      "Epoch 436/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5399 - val_loss: 0.5357\n",
      "Epoch 437/500\n",
      "4909/4909 [==============================] - 54s 11ms/step - loss: 0.5399 - val_loss: 0.5353\n",
      "Epoch 438/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5399 - val_loss: 0.5353\n",
      "Epoch 439/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5399 - val_loss: 0.5354\n",
      "Epoch 440/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5398 - val_loss: 0.5357\n",
      "Epoch 441/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5399 - val_loss: 0.5358\n",
      "Epoch 442/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5398 - val_loss: 0.5356\n",
      "Epoch 443/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5398 - val_loss: 0.5355\n",
      "Epoch 444/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5399 - val_loss: 0.5357\n",
      "Epoch 445/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5399 - val_loss: 0.5355\n",
      "Epoch 446/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5399 - val_loss: 0.5355\n",
      "Epoch 447/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5399 - val_loss: 0.5355\n",
      "Epoch 448/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5398 - val_loss: 0.5356\n",
      "Epoch 449/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5398 - val_loss: 0.5352\n",
      "Epoch 450/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5398 - val_loss: 0.5352\n",
      "Epoch 451/500\n",
      "4909/4909 [==============================] - 54s 11ms/step - loss: 0.5399 - val_loss: 0.5354\n",
      "Epoch 452/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5398 - val_loss: 0.5357\n",
      "Epoch 453/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5398 - val_loss: 0.5356\n",
      "Epoch 454/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5398 - val_loss: 0.5352\n",
      "Epoch 455/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5399 - val_loss: 0.5357\n",
      "Epoch 456/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5399 - val_loss: 0.5355\n",
      "Epoch 457/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5398 - val_loss: 0.5356\n",
      "Epoch 458/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5398 - val_loss: 0.5354\n",
      "Epoch 459/500\n",
      "4909/4909 [==============================] - 54s 11ms/step - loss: 0.5398 - val_loss: 0.5354\n",
      "Epoch 460/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5399 - val_loss: 0.5350\n",
      "Epoch 461/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5397 - val_loss: 0.5352\n",
      "Epoch 462/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5397 - val_loss: 0.5356\n",
      "Epoch 463/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5397 - val_loss: 0.5355\n",
      "Epoch 464/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5397 - val_loss: 0.5352\n",
      "Epoch 465/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5397 - val_loss: 0.5351\n",
      "Epoch 466/500\n",
      "4909/4909 [==============================] - 54s 11ms/step - loss: 0.5397 - val_loss: 0.5355\n",
      "Epoch 467/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5398 - val_loss: 0.5352\n",
      "Epoch 468/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5397 - val_loss: 0.5353\n",
      "Epoch 469/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5397 - val_loss: 0.5353\n",
      "Epoch 470/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5397 - val_loss: 0.5352\n",
      "Epoch 471/500\n",
      "4909/4909 [==============================] - 54s 11ms/step - loss: 0.5397 - val_loss: 0.5355\n",
      "Epoch 472/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5397 - val_loss: 0.5354\n",
      "Epoch 473/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5397 - val_loss: 0.5353\n",
      "Epoch 474/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5397 - val_loss: 0.5355\n",
      "Epoch 475/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5397 - val_loss: 0.5349\n",
      "Epoch 476/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5397 - val_loss: 0.5349\n",
      "Epoch 477/500\n",
      "4909/4909 [==============================] - 68s 14ms/step - loss: 0.5397 - val_loss: 0.5346\n",
      "Epoch 478/500\n",
      "4909/4909 [==============================] - 54s 11ms/step - loss: 0.5397 - val_loss: 0.5355\n",
      "Epoch 479/500\n",
      "4909/4909 [==============================] - 54s 11ms/step - loss: 0.5397 - val_loss: 0.5353\n",
      "Epoch 480/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5396 - val_loss: 0.5351\n",
      "Epoch 481/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5397 - val_loss: 0.5354\n",
      "Epoch 482/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5397 - val_loss: 0.5351\n",
      "Epoch 483/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5397 - val_loss: 0.5355\n",
      "Epoch 484/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5397 - val_loss: 0.5351\n",
      "Epoch 485/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5397 - val_loss: 0.5356\n",
      "Epoch 486/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5396 - val_loss: 0.5353\n",
      "Epoch 487/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5396 - val_loss: 0.5352\n",
      "Epoch 488/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5397 - val_loss: 0.5354\n",
      "Epoch 489/500\n",
      "4909/4909 [==============================] - 54s 11ms/step - loss: 0.5396 - val_loss: 0.5350\n",
      "Epoch 490/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5397 - val_loss: 0.5350\n",
      "Epoch 491/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5396 - val_loss: 0.5352\n",
      "Epoch 492/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5396 - val_loss: 0.5354\n",
      "Epoch 493/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5397 - val_loss: 0.5353\n",
      "Epoch 494/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5396 - val_loss: 0.5351\n",
      "Epoch 495/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5396 - val_loss: 0.5354\n",
      "Epoch 496/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5396 - val_loss: 0.5350\n",
      "Epoch 497/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5396 - val_loss: 0.5352\n",
      "Epoch 498/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5396 - val_loss: 0.5350\n",
      "Epoch 499/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5396 - val_loss: 0.5353\n",
      "Epoch 500/500\n",
      "4909/4909 [==============================] - 53s 11ms/step - loss: 0.5396 - val_loss: 0.5351\n"
     ]
    }
   ],
   "source": [
    "%%wandb\n",
    "\n",
    "model_version = 'patch_desc_ae_' + datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + '16_alex_3conv3mp_2020_augm_relu_dwnsmpl'\n",
    "\n",
    "os.system('mkdir ' + base_dir + '/weights_' + model_version)\n",
    "print(base_dir + '/weights_' + model_version)\n",
    "\n",
    "# checkpointer = ModelCheckpoint(base_dir + '/weights' + model_version + '/weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "history_callback = autoencoder.fit(image_datagen.flow(x_train, y_train, batch_size),\n",
    "#                 steps_per_epoch=x_train.shape[0],\n",
    "                epochs=wandb.config.epochs,\n",
    "                validation_data=image_datagen.flow(x_validation, y_validation, batch_size),\n",
    "#                 validation_steps=x_validation.shape[0],\n",
    "                callbacks=[WandbCallback(data_type=\"image\", predictions=1)]  # checkpointer,\n",
    "                )\n",
    "autoencoder.save(base_dir + '/' + model_version + '.h5')\n",
    "\n",
    "# autoencoder = load_model(base_dir + '/' + model_version + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.save(\"patch_desc_ae.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 37326<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.97MB of 0.97MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>wandb/run-20201023_153238-183kde2v/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>wandb/run-20201023_153238-183kde2v/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>499</td></tr><tr><td>loss</td><td>0.53957</td></tr><tr><td>val_loss</td><td>0.53508</td></tr><tr><td>_step</td><td>499</td></tr><tr><td>_runtime</td><td>26602</td></tr><tr><td>_timestamp</td><td>1603486560</td></tr><tr><td>best_val_loss</td><td>0.53461</td></tr><tr><td>best_epoch</td><td>476</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▄▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1501 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">curious-brook-3</strong>: <a href=\"https://wandb.ai/nimpy/patch-desc-ae/runs/183kde2v\" target=\"_blank\">https://wandb.ai/nimpy/patch-desc-ae/runs/183kde2v</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6427811340838695,\n",
       "  0.6112030945784596,\n",
       "  0.599876537229413,\n",
       "  0.5921597616309742,\n",
       "  0.5867754996999928,\n",
       "  0.5822773794734587,\n",
       "  0.5786683579565965,\n",
       "  0.5752818117997072,\n",
       "  0.5717876743536033,\n",
       "  0.5685864390904422,\n",
       "  0.5657664656414471,\n",
       "  0.5638158766789553,\n",
       "  0.562458957176395,\n",
       "  0.561474795583908,\n",
       "  0.5604123130912925,\n",
       "  0.5596772892587473,\n",
       "  0.5589220918140244,\n",
       "  0.558221827017111,\n",
       "  0.5576246947643159,\n",
       "  0.5570898665068732,\n",
       "  0.556586069962865,\n",
       "  0.5561190933888772,\n",
       "  0.5556799980036046,\n",
       "  0.5553170322329187,\n",
       "  0.5550017254431463,\n",
       "  0.5546291223019215,\n",
       "  0.5543626178196251,\n",
       "  0.5540239880783251,\n",
       "  0.5537526381420563,\n",
       "  0.553482891468511,\n",
       "  0.5532866133717479,\n",
       "  0.5529637102472553,\n",
       "  0.552664884039694,\n",
       "  0.5525467360191039,\n",
       "  0.5522096875140601,\n",
       "  0.5520531316136099,\n",
       "  0.5518388297683107,\n",
       "  0.5516530161467444,\n",
       "  0.5514115488624975,\n",
       "  0.5512772907073104,\n",
       "  0.5510106698956708,\n",
       "  0.5508325021651507,\n",
       "  0.5506907551059697,\n",
       "  0.55047832347507,\n",
       "  0.5503720552180356,\n",
       "  0.5501668573051158,\n",
       "  0.5500860068171929,\n",
       "  0.5499049122256455,\n",
       "  0.5497650285236321,\n",
       "  0.5495755639982395,\n",
       "  0.5494262371243785,\n",
       "  0.5493009540712114,\n",
       "  0.5491010560313735,\n",
       "  0.5489831108235117,\n",
       "  0.5488337440918002,\n",
       "  0.5487153793649222,\n",
       "  0.548573903214972,\n",
       "  0.5484125816255776,\n",
       "  0.5482446931460679,\n",
       "  0.5481225759629151,\n",
       "  0.5480319721393722,\n",
       "  0.5479073932721723,\n",
       "  0.5478017899678121,\n",
       "  0.5477074268330392,\n",
       "  0.547558302217166,\n",
       "  0.5474784065100051,\n",
       "  0.5473151748013102,\n",
       "  0.5472412447569491,\n",
       "  0.5471144816951741,\n",
       "  0.5470327776078454,\n",
       "  0.5469567879245023,\n",
       "  0.5468878054504093,\n",
       "  0.5467754958323804,\n",
       "  0.5466329773383978,\n",
       "  0.5465913510323481,\n",
       "  0.5464857253122158,\n",
       "  0.546380623760534,\n",
       "  0.5462992040897262,\n",
       "  0.546329550470028,\n",
       "  0.5462207237703375,\n",
       "  0.5460944381262631,\n",
       "  0.5460077346615049,\n",
       "  0.5459746047481624,\n",
       "  0.5458848909509829,\n",
       "  0.5457997846005094,\n",
       "  0.545771662243037,\n",
       "  0.5456498824021545,\n",
       "  0.5456620842378143,\n",
       "  0.545540753071326,\n",
       "  0.5454673691338527,\n",
       "  0.5454461304886739,\n",
       "  0.5453650565328498,\n",
       "  0.5452973038671871,\n",
       "  0.545224445613646,\n",
       "  0.5451297760518214,\n",
       "  0.5451160637264139,\n",
       "  0.5450817030499712,\n",
       "  0.5449906161998517,\n",
       "  0.5449784141403224,\n",
       "  0.5448832585247525,\n",
       "  0.5448295326374547,\n",
       "  0.5447791683381387,\n",
       "  0.5447013584543261,\n",
       "  0.5447220513409426,\n",
       "  0.5446428974138632,\n",
       "  0.5445840183531703,\n",
       "  0.544578549645415,\n",
       "  0.5445279390822271,\n",
       "  0.5444385492862225,\n",
       "  0.54439090451608,\n",
       "  0.5443065307222704,\n",
       "  0.5443836172250267,\n",
       "  0.5443184097155639,\n",
       "  0.5442594179947084,\n",
       "  0.5441756215030317,\n",
       "  0.5442020162015521,\n",
       "  0.5440689099733049,\n",
       "  0.544095256806282,\n",
       "  0.5440286741508905,\n",
       "  0.5439475659362263,\n",
       "  0.5439849345424788,\n",
       "  0.5439339120035335,\n",
       "  0.5438785702439763,\n",
       "  0.5438357897776054,\n",
       "  0.5438415494525263,\n",
       "  0.5437699948114478,\n",
       "  0.5437042817306268,\n",
       "  0.5436620748577463,\n",
       "  0.5436633084636078,\n",
       "  0.5436353218961755,\n",
       "  0.5435758638638155,\n",
       "  0.5434925882812035,\n",
       "  0.5435758526733837,\n",
       "  0.5433958709462311,\n",
       "  0.5434621459816131,\n",
       "  0.543431215992134,\n",
       "  0.5433770918040808,\n",
       "  0.5433443025546225,\n",
       "  0.5433245439749677,\n",
       "  0.5433111489134057,\n",
       "  0.5432633202304199,\n",
       "  0.5432411329271157,\n",
       "  0.5431960496457702,\n",
       "  0.5431702887623538,\n",
       "  0.5431357913685207,\n",
       "  0.5431025838613034,\n",
       "  0.543131261151428,\n",
       "  0.5430332177813908,\n",
       "  0.5430710976763969,\n",
       "  0.5429598377043358,\n",
       "  0.5429787495881085,\n",
       "  0.5429627752314095,\n",
       "  0.5429542794063439,\n",
       "  0.542900841709473,\n",
       "  0.5428461585477361,\n",
       "  0.5428603191369844,\n",
       "  0.54277120894393,\n",
       "  0.5428167638170612,\n",
       "  0.5426975075840053,\n",
       "  0.5427860038514192,\n",
       "  0.5427444717518679,\n",
       "  0.5426935102351536,\n",
       "  0.5426520224829817,\n",
       "  0.5426658518267948,\n",
       "  0.5426338056778675,\n",
       "  0.5426232395523267,\n",
       "  0.542607449855208,\n",
       "  0.5425856021359031,\n",
       "  0.5425405464527154,\n",
       "  0.5425429275688403,\n",
       "  0.5424874185439718,\n",
       "  0.5425178518060704,\n",
       "  0.5424731656256923,\n",
       "  0.5424355395628595,\n",
       "  0.5424228586650077,\n",
       "  0.5424550789827702,\n",
       "  0.5424149128793418,\n",
       "  0.542383887171677,\n",
       "  0.5423315414206973,\n",
       "  0.5422893638792546,\n",
       "  0.5423102565415653,\n",
       "  0.5423095537185451,\n",
       "  0.5423452966887992,\n",
       "  0.54229751568619,\n",
       "  0.5422293082568868,\n",
       "  0.5422237971217162,\n",
       "  0.5421964710189467,\n",
       "  0.5422426526101441,\n",
       "  0.5422292056025458,\n",
       "  0.5421431730514575,\n",
       "  0.5421625451248567,\n",
       "  0.5421415237687849,\n",
       "  0.5421052987903701,\n",
       "  0.5421276497998425,\n",
       "  0.5420813114826473,\n",
       "  0.5421320258126928,\n",
       "  0.5420852206080039,\n",
       "  0.542040622644291,\n",
       "  0.5420197345132477,\n",
       "  0.5419951009114122,\n",
       "  0.5420224173369547,\n",
       "  0.541941910614455,\n",
       "  0.5419246936181971,\n",
       "  0.5419683319746764,\n",
       "  0.5419086711584256,\n",
       "  0.5419014031482147,\n",
       "  0.5418690144093679,\n",
       "  0.5418220179899005,\n",
       "  0.5418727954503433,\n",
       "  0.5418161336478312,\n",
       "  0.5418429139920383,\n",
       "  0.5418020946864204,\n",
       "  0.5417661564337956,\n",
       "  0.5418277765697588,\n",
       "  0.5417763043767062,\n",
       "  0.5417670064740581,\n",
       "  0.5417549072950159,\n",
       "  0.541693656129888,\n",
       "  0.5417070955251695,\n",
       "  0.5417066699768585,\n",
       "  0.541709128016009,\n",
       "  0.541719301745633,\n",
       "  0.5416429399011267,\n",
       "  0.5416492543022847,\n",
       "  0.5416474767265391,\n",
       "  0.5415916023142627,\n",
       "  0.5415458860108419,\n",
       "  0.5416104160446068,\n",
       "  0.5416011493318915,\n",
       "  0.5416057794394875,\n",
       "  0.5415498995185073,\n",
       "  0.5415696629565064,\n",
       "  0.5415246555706643,\n",
       "  0.541544301777013,\n",
       "  0.5415438272938979,\n",
       "  0.5414681902503108,\n",
       "  0.5414761208591528,\n",
       "  0.541515861458285,\n",
       "  0.541457146809518,\n",
       "  0.5414471673908994,\n",
       "  0.5414302118224362,\n",
       "  0.5414687916597575,\n",
       "  0.5413750602546885,\n",
       "  0.5414141888542157,\n",
       "  0.5413860185735252,\n",
       "  0.5413779284050306,\n",
       "  0.5413695850903895,\n",
       "  0.541364805274151,\n",
       "  0.5413707019214457,\n",
       "  0.5413167225047671,\n",
       "  0.5413152586693916,\n",
       "  0.541288225937158,\n",
       "  0.5413355802265765,\n",
       "  0.541309587354564,\n",
       "  0.541283621794612,\n",
       "  0.5412342054567701,\n",
       "  0.5412135340851362,\n",
       "  0.5412267819195904,\n",
       "  0.5411798648014761,\n",
       "  0.5411612926436128,\n",
       "  0.5411751978829293,\n",
       "  0.5411570066163749,\n",
       "  0.5411852488744757,\n",
       "  0.5411228842386084,\n",
       "  0.5411293387121615,\n",
       "  0.5411065300803509,\n",
       "  0.5410908126619176,\n",
       "  0.5411194543515037,\n",
       "  0.5411351178189419,\n",
       "  0.5410873288830101,\n",
       "  0.5410400015079995,\n",
       "  0.5410819988323403,\n",
       "  0.5410707419271913,\n",
       "  0.5411049655788976,\n",
       "  0.5410233521783858,\n",
       "  0.5410433572488174,\n",
       "  0.5410929843790019,\n",
       "  0.5410161308255828,\n",
       "  0.5410090727167904,\n",
       "  0.5409747136066744,\n",
       "  0.5409573822367048,\n",
       "  0.5409875762545637,\n",
       "  0.5409729102950603,\n",
       "  0.5409193229623993,\n",
       "  0.5409321952465361,\n",
       "  0.540920615679634,\n",
       "  0.5409349090021571,\n",
       "  0.5409232370902872,\n",
       "  0.5409349838898689,\n",
       "  0.5408605810994672,\n",
       "  0.540899882501847,\n",
       "  0.5408735775187781,\n",
       "  0.540897494529249,\n",
       "  0.540859227413123,\n",
       "  0.5408788186902813,\n",
       "  0.540826738713956,\n",
       "  0.5408037736392095,\n",
       "  0.5408360722179016,\n",
       "  0.5408659605281265,\n",
       "  0.5408518814508463,\n",
       "  0.5408453142913288,\n",
       "  0.5407842272512704,\n",
       "  0.5407972935443787,\n",
       "  0.5408205127411906,\n",
       "  0.5407758138617288,\n",
       "  0.5407131330843981,\n",
       "  0.540745779789792,\n",
       "  0.5407263294167602,\n",
       "  0.5407765621233969,\n",
       "  0.5407377367924662,\n",
       "  0.5407692485576708,\n",
       "  0.540711341734996,\n",
       "  0.5407145316212587,\n",
       "  0.5407056827375359,\n",
       "  0.5406839109205643,\n",
       "  0.5406841576329336,\n",
       "  0.5406634229017209,\n",
       "  0.5406632920671617,\n",
       "  0.5406730772453507,\n",
       "  0.540681653183011,\n",
       "  0.5406755868806945,\n",
       "  0.5406362176049229,\n",
       "  0.540585772143482,\n",
       "  0.5405666333131062,\n",
       "  0.5406583878250985,\n",
       "  0.5405651331479091,\n",
       "  0.5406547427092435,\n",
       "  0.540629026666478,\n",
       "  0.5405331751230638,\n",
       "  0.5404994554058133,\n",
       "  0.5405309655242502,\n",
       "  0.5405642221339839,\n",
       "  0.5404994155267142,\n",
       "  0.5405679354662443,\n",
       "  0.5405556699446876,\n",
       "  0.540552768648781,\n",
       "  0.5405394554437182,\n",
       "  0.5405523460153246,\n",
       "  0.5405007035366216,\n",
       "  0.5405093477134536,\n",
       "  0.5405458726016659,\n",
       "  0.5404995719438483,\n",
       "  0.5405063626676445,\n",
       "  0.540498898947814,\n",
       "  0.5404633793521189,\n",
       "  0.5404542945935799,\n",
       "  0.54050789869747,\n",
       "  0.5404310730260294,\n",
       "  0.5404603427419894,\n",
       "  0.5404400730003136,\n",
       "  0.5403963507315316,\n",
       "  0.5403925192569659,\n",
       "  0.5403747277816054,\n",
       "  0.5403878417733036,\n",
       "  0.5403927252296671,\n",
       "  0.5404414528793716,\n",
       "  0.5403949669799133,\n",
       "  0.5403621094161544,\n",
       "  0.5403418656137267,\n",
       "  0.5403379492775003,\n",
       "  0.5403421881457114,\n",
       "  0.5403352509256083,\n",
       "  0.5404069661439962,\n",
       "  0.5403565618684445,\n",
       "  0.5403049150770313,\n",
       "  0.5403025956297025,\n",
       "  0.5403504654484913,\n",
       "  0.5403242075037875,\n",
       "  0.5403132026793189,\n",
       "  0.540257385041068,\n",
       "  0.5402898597070417,\n",
       "  0.5402813097837584,\n",
       "  0.5402402144646885,\n",
       "  0.540261300060639,\n",
       "  0.5402003247731236,\n",
       "  0.5402661394291595,\n",
       "  0.5402738863846948,\n",
       "  0.540305533038391,\n",
       "  0.5402298457365147,\n",
       "  0.5401716267754638,\n",
       "  0.5402882282997673,\n",
       "  0.5402630539396243,\n",
       "  0.5402585609857741,\n",
       "  0.5402358760755485,\n",
       "  0.5402128505500069,\n",
       "  0.5401606719140805,\n",
       "  0.5402071902874952,\n",
       "  0.5401707544787938,\n",
       "  0.5401841369907713,\n",
       "  0.5401811169310371,\n",
       "  0.540157869780912,\n",
       "  0.5401711720626683,\n",
       "  0.5401680116064977,\n",
       "  0.5401202978420987,\n",
       "  0.5401329252040622,\n",
       "  0.5401708741153323,\n",
       "  0.5401352174007997,\n",
       "  0.5401155521321658,\n",
       "  0.540121259479334,\n",
       "  0.5401338342562848,\n",
       "  0.5401342724338626,\n",
       "  0.5401765810033786,\n",
       "  0.5400843336805811,\n",
       "  0.5400634775583012,\n",
       "  0.540112253984204,\n",
       "  0.5400666952225762,\n",
       "  0.54006396802417,\n",
       "  0.5400831720809673,\n",
       "  0.5400441382206718,\n",
       "  0.5400884844687251,\n",
       "  0.5400547841302126,\n",
       "  0.5400582824720108,\n",
       "  0.5400442072877806,\n",
       "  0.5400176167923695,\n",
       "  0.5400682501439391,\n",
       "  0.5400113387506291,\n",
       "  0.5400136487233518,\n",
       "  0.5400059171510556,\n",
       "  0.5400463632649525,\n",
       "  0.5400190269537409,\n",
       "  0.5399836412228094,\n",
       "  0.5399968341607051,\n",
       "  0.5399241032470847,\n",
       "  0.5399807614509919,\n",
       "  0.5399143978498603,\n",
       "  0.5399305623399351,\n",
       "  0.5400149638480111,\n",
       "  0.5399812596634991,\n",
       "  0.5399276590428642,\n",
       "  0.5399744493105348,\n",
       "  0.5399272489316727,\n",
       "  0.539892741200388,\n",
       "  0.5399293375734979,\n",
       "  0.5398956525537199,\n",
       "  0.5399814324466208,\n",
       "  0.5398761205040434,\n",
       "  0.5399458624780457,\n",
       "  0.5398695339323973,\n",
       "  0.539854125292782,\n",
       "  0.5398485129299633,\n",
       "  0.5398879556447466,\n",
       "  0.5398424191357318,\n",
       "  0.5398402858437342,\n",
       "  0.5398540661282871,\n",
       "  0.53987738209585,\n",
       "  0.5398517586659367,\n",
       "  0.5398927434656422,\n",
       "  0.5398243833324005,\n",
       "  0.5398368402743918,\n",
       "  0.5397935615317678,\n",
       "  0.5398528592061342,\n",
       "  0.539821131198317,\n",
       "  0.5398191000180617,\n",
       "  0.5398487336408563,\n",
       "  0.539859447305404,\n",
       "  0.5398812775978082,\n",
       "  0.5398129202109502,\n",
       "  0.5397886725484876,\n",
       "  0.5397761101966652,\n",
       "  0.539863572825908,\n",
       "  0.5397371409116727,\n",
       "  0.5397429476537959,\n",
       "  0.5397469127965757,\n",
       "  0.5397182858626357,\n",
       "  0.5397333844644525,\n",
       "  0.5397409466860373,\n",
       "  0.5397565575585974,\n",
       "  0.5397460514209355,\n",
       "  0.5397151191358468,\n",
       "  0.5397461760880838,\n",
       "  0.5397028756278565,\n",
       "  0.5397060407033244,\n",
       "  0.5397121202685717,\n",
       "  0.5396996722479637,\n",
       "  0.5396712894469627,\n",
       "  0.5397153471388096,\n",
       "  0.5396825460561488,\n",
       "  0.539713194915054,\n",
       "  0.5396817569561584,\n",
       "  0.5396386546248574,\n",
       "  0.5397217200616918,\n",
       "  0.5396873549518773,\n",
       "  0.5396707953619994,\n",
       "  0.5396617785390804,\n",
       "  0.5396906471487087,\n",
       "  0.5396023901422298,\n",
       "  0.5396268430094078,\n",
       "  0.5396536382056387,\n",
       "  0.5396255799218505,\n",
       "  0.5396946096399646,\n",
       "  0.5396065493675922,\n",
       "  0.5396005397740377,\n",
       "  0.5396523203285247,\n",
       "  0.5395862204424496,\n",
       "  0.5396315407020217,\n",
       "  0.5395816567071826,\n",
       "  0.5395937403360322,\n",
       "  0.5395593564477531,\n",
       "  0.5396494176749833,\n",
       "  0.5395727116317337],\n",
       " 'val_loss': [0.6175597406984344,\n",
       "  0.6012856388479714,\n",
       "  0.5918562916236195,\n",
       "  0.5854173777549248,\n",
       "  0.580008025091838,\n",
       "  0.5764983228551663,\n",
       "  0.5726673324418262,\n",
       "  0.5692922589255542,\n",
       "  0.566357017774892,\n",
       "  0.5629002095722571,\n",
       "  0.5604839719892517,\n",
       "  0.559040711904929,\n",
       "  0.5577392963374533,\n",
       "  0.5565691578194378,\n",
       "  0.5560170177037154,\n",
       "  0.5553163651043806,\n",
       "  0.554469889014717,\n",
       "  0.5541186429620758,\n",
       "  0.5530959539781741,\n",
       "  0.5526882870410516,\n",
       "  0.5523168410712141,\n",
       "  0.5517128437030606,\n",
       "  0.551234844738875,\n",
       "  0.5508813329828464,\n",
       "  0.550412313724921,\n",
       "  0.5502952625596427,\n",
       "  0.5499022457657791,\n",
       "  0.5495620764852539,\n",
       "  0.5494691911267071,\n",
       "  0.5492013797042815,\n",
       "  0.5488649323219206,\n",
       "  0.5488235010364191,\n",
       "  0.5480502039436402,\n",
       "  0.5479906172287173,\n",
       "  0.5475505079195752,\n",
       "  0.5475355735639247,\n",
       "  0.5474430237843738,\n",
       "  0.5470708754004502,\n",
       "  0.5470395197228688,\n",
       "  0.546814581000708,\n",
       "  0.5468623722956433,\n",
       "  0.5461859664296717,\n",
       "  0.5460569051707663,\n",
       "  0.5462113163335537,\n",
       "  0.5463523057902732,\n",
       "  0.5456998653528167,\n",
       "  0.5458175842839528,\n",
       "  0.5456772705888361,\n",
       "  0.5453077886647325,\n",
       "  0.5452243411928658,\n",
       "  0.5451013048489889,\n",
       "  0.5446894331191613,\n",
       "  0.544556964219101,\n",
       "  0.5444704710952635,\n",
       "  0.5444932223820105,\n",
       "  0.544472543204703,\n",
       "  0.5446423883360576,\n",
       "  0.5442345120557924,\n",
       "  0.5438986309175569,\n",
       "  0.5436734125866154,\n",
       "  0.5435289171168475,\n",
       "  0.5434752298079855,\n",
       "  0.543411580527701,\n",
       "  0.5436458546456283,\n",
       "  0.5432893934288645,\n",
       "  0.5431696661119538,\n",
       "  0.5430717269579569,\n",
       "  0.5424237561419727,\n",
       "  0.5427537197019996,\n",
       "  0.542678314495862,\n",
       "  0.5423315981539284,\n",
       "  0.5427993300969038,\n",
       "  0.542225597350578,\n",
       "  0.5425052519251661,\n",
       "  0.5421705655450744,\n",
       "  0.5423386099377299,\n",
       "  0.5419742736389966,\n",
       "  0.5422284251790706,\n",
       "  0.5418117484910702,\n",
       "  0.5419863077198587,\n",
       "  0.5415267774729224,\n",
       "  0.5420215839777536,\n",
       "  0.5414874267771961,\n",
       "  0.541775357674777,\n",
       "  0.541208985375195,\n",
       "  0.5411930893494831,\n",
       "  0.5413135297414733,\n",
       "  0.5408653561177292,\n",
       "  0.5413202238761312,\n",
       "  0.5410090362637993,\n",
       "  0.5407456191090064,\n",
       "  0.5409589242644426,\n",
       "  0.5408635066776741,\n",
       "  0.5406918864909226,\n",
       "  0.5409766275708269,\n",
       "  0.5408040854504438,\n",
       "  0.5407841833141761,\n",
       "  0.540552232081328,\n",
       "  0.5405649164827858,\n",
       "  0.540776519029121,\n",
       "  0.5401136303335671,\n",
       "  0.5404136081536611,\n",
       "  0.5402895493236014,\n",
       "  0.5404308726632499,\n",
       "  0.5401557419842821,\n",
       "  0.5401555503286967,\n",
       "  0.5400045664329839,\n",
       "  0.5401707395790069,\n",
       "  0.5399694580857347,\n",
       "  0.5403943020638412,\n",
       "  0.540389796582664,\n",
       "  0.5396627371873313,\n",
       "  0.5396082532115098,\n",
       "  0.5396923570613551,\n",
       "  0.5397574896734905,\n",
       "  0.5396417207349606,\n",
       "  0.5397710540914923,\n",
       "  0.539959035268644,\n",
       "  0.5393468497729883,\n",
       "  0.5396758674121485,\n",
       "  0.5394918039077665,\n",
       "  0.539750277026882,\n",
       "  0.5394391873018528,\n",
       "  0.5395332911634833,\n",
       "  0.5392885188746258,\n",
       "  0.5391145426083387,\n",
       "  0.5394417745311085,\n",
       "  0.5390208315073959,\n",
       "  0.5395886253535263,\n",
       "  0.5388932550341133,\n",
       "  0.5388801061525578,\n",
       "  0.538874438865398,\n",
       "  0.5393840646356102,\n",
       "  0.539498540686398,\n",
       "  0.5392933907063027,\n",
       "  0.5388633906841278,\n",
       "  0.5391678989418154,\n",
       "  0.538777372459086,\n",
       "  0.5389300984580342,\n",
       "  0.5390770222113385,\n",
       "  0.5386862682133187,\n",
       "  0.5388770256100631,\n",
       "  0.538914015622643,\n",
       "  0.5390076244749674,\n",
       "  0.5387612879276276,\n",
       "  0.5389709751295849,\n",
       "  0.5388219295963039,\n",
       "  0.5385816739342077,\n",
       "  0.5386841367415296,\n",
       "  0.5387320603297009,\n",
       "  0.5384872080833931,\n",
       "  0.5385293490518399,\n",
       "  0.538705526813259,\n",
       "  0.5383653633478211,\n",
       "  0.5387394963725796,\n",
       "  0.5388945602789158,\n",
       "  0.5385198576178977,\n",
       "  0.5383687843152178,\n",
       "  0.5383727250060415,\n",
       "  0.5381488792779969,\n",
       "  0.5380911504834648,\n",
       "  0.5383053012495118,\n",
       "  0.5377292165426704,\n",
       "  0.5382003415890826,\n",
       "  0.5377845861078278,\n",
       "  0.538180213149001,\n",
       "  0.5379385633197257,\n",
       "  0.5380703736611498,\n",
       "  0.5378002563143164,\n",
       "  0.5378673939200921,\n",
       "  0.5382729618529963,\n",
       "  0.5380616997315631,\n",
       "  0.5380869510212565,\n",
       "  0.5379686406472834,\n",
       "  0.5379927621139744,\n",
       "  0.5379964791662325,\n",
       "  0.5378296888940702,\n",
       "  0.5378938171921707,\n",
       "  0.5378793935950209,\n",
       "  0.5380026814414234,\n",
       "  0.5379329546680295,\n",
       "  0.5378802731269743,\n",
       "  0.5375812703031835,\n",
       "  0.5376824547604817,\n",
       "  0.5378191039814213,\n",
       "  0.5374628077677595,\n",
       "  0.537705934871503,\n",
       "  0.5375984347448116,\n",
       "  0.5374677927513433,\n",
       "  0.5374608047124816,\n",
       "  0.5375170547787737,\n",
       "  0.5378585438418194,\n",
       "  0.5377270717446397,\n",
       "  0.5377310424800811,\n",
       "  0.5376228728914648,\n",
       "  0.5375695383645654,\n",
       "  0.5372737813286665,\n",
       "  0.5377342046760931,\n",
       "  0.5377017916218052,\n",
       "  0.5374747175511306,\n",
       "  0.5375525907772344,\n",
       "  0.5375113802227548,\n",
       "  0.5372549731556963,\n",
       "  0.5375292451401067,\n",
       "  0.5375680133579223,\n",
       "  0.5373495136334644,\n",
       "  0.537461513668541,\n",
       "  0.5375327947663098,\n",
       "  0.5374369570394841,\n",
       "  0.5374207188928031,\n",
       "  0.5374939461064533,\n",
       "  0.5371189141661171,\n",
       "  0.537261456735735,\n",
       "  0.5372082121003934,\n",
       "  0.5373282602162865,\n",
       "  0.5368726442499858,\n",
       "  0.537077927977089,\n",
       "  0.5373017417221535,\n",
       "  0.5373614018525534,\n",
       "  0.5373676634900938,\n",
       "  0.5368119977354034,\n",
       "  0.5371832433270245,\n",
       "  0.5371186583022761,\n",
       "  0.5375294014205777,\n",
       "  0.5371729700061364,\n",
       "  0.5370679660056664,\n",
       "  0.537312551000254,\n",
       "  0.5368712643782297,\n",
       "  0.5371312784954785,\n",
       "  0.5368850495272536,\n",
       "  0.5372389319950972,\n",
       "  0.5371832862132933,\n",
       "  0.5369916080943937,\n",
       "  0.5372255744972849,\n",
       "  0.5372704737554721,\n",
       "  0.5371473756262927,\n",
       "  0.5370221184036597,\n",
       "  0.5366374339030041,\n",
       "  0.5371262981155054,\n",
       "  0.5369753251230813,\n",
       "  0.5367496716297739,\n",
       "  0.5368882206881919,\n",
       "  0.5368040361540104,\n",
       "  0.5370480301903515,\n",
       "  0.5368317007049312,\n",
       "  0.5368030197252103,\n",
       "  0.5371005360673113,\n",
       "  0.5369158442912063,\n",
       "  0.5368547429883384,\n",
       "  0.5367401719577913,\n",
       "  0.5368262873432501,\n",
       "  0.5368860586871945,\n",
       "  0.5366046918116933,\n",
       "  0.5364980702477742,\n",
       "  0.5369675556818644,\n",
       "  0.536935792705877,\n",
       "  0.5365708809557969,\n",
       "  0.5367096730364047,\n",
       "  0.536625889985542,\n",
       "  0.5366917322806226,\n",
       "  0.5368052667718592,\n",
       "  0.536817044746585,\n",
       "  0.5366148655492116,\n",
       "  0.5366456208190298,\n",
       "  0.5363787301187593,\n",
       "  0.536401074591691,\n",
       "  0.5362202527561808,\n",
       "  0.5368989262639022,\n",
       "  0.5365380378273444,\n",
       "  0.5366227428118387,\n",
       "  0.5365939278428148,\n",
       "  0.5366117670768644,\n",
       "  0.5368606409406275,\n",
       "  0.5366486347303158,\n",
       "  0.5364304337559677,\n",
       "  0.5366576011103343,\n",
       "  0.5367894242934095,\n",
       "  0.5363499129690775,\n",
       "  0.5365695669883634,\n",
       "  0.5363067330383673,\n",
       "  0.5365744068370601,\n",
       "  0.5363554058036184,\n",
       "  0.5363872739357677,\n",
       "  0.5365380099633845,\n",
       "  0.5364105432498746,\n",
       "  0.5365335851665435,\n",
       "  0.5362181241919355,\n",
       "  0.5364244677186981,\n",
       "  0.5359796242016118,\n",
       "  0.5364104708035787,\n",
       "  0.5366240158313658,\n",
       "  0.5368627651435572,\n",
       "  0.5366716951858707,\n",
       "  0.5365456294238082,\n",
       "  0.536274358751328,\n",
       "  0.536168842053995,\n",
       "  0.5360606635004525,\n",
       "  0.5362074796746417,\n",
       "  0.536388371048904,\n",
       "  0.5361082493289699,\n",
       "  0.5365580567499486,\n",
       "  0.5364734838163949,\n",
       "  0.5361209119238505,\n",
       "  0.5363273826556477,\n",
       "  0.5361801322882738,\n",
       "  0.53639609978451,\n",
       "  0.5363073644599294,\n",
       "  0.536286860704422,\n",
       "  0.5362377542305768,\n",
       "  0.5363272467279822,\n",
       "  0.5363780594453579,\n",
       "  0.5361709495385488,\n",
       "  0.5362446388093437,\n",
       "  0.53635977123811,\n",
       "  0.5362566949390783,\n",
       "  0.5361944354646574,\n",
       "  0.5362088038184778,\n",
       "  0.536194159248011,\n",
       "  0.5362672909973113,\n",
       "  0.5358703490195236,\n",
       "  0.5358779556382962,\n",
       "  0.5360710746873685,\n",
       "  0.5363860355644692,\n",
       "  0.536007027558195,\n",
       "  0.5362931199190093,\n",
       "  0.536167158586223,\n",
       "  0.536307389658641,\n",
       "  0.5359668695345158,\n",
       "  0.5362464288870493,\n",
       "  0.5361182587902721,\n",
       "  0.5363987987119008,\n",
       "  0.5359263994344851,\n",
       "  0.5357986531121944,\n",
       "  0.5360931397938147,\n",
       "  0.5358354395967189,\n",
       "  0.5362343061261061,\n",
       "  0.5357971380396587,\n",
       "  0.5358578160526307,\n",
       "  0.535800432771202,\n",
       "  0.5359870328651211,\n",
       "  0.5360847837556668,\n",
       "  0.5359260248459452,\n",
       "  0.5360701074445151,\n",
       "  0.5357413112632627,\n",
       "  0.5357154220100341,\n",
       "  0.5359898371909692,\n",
       "  0.535800485349283,\n",
       "  0.5358433146786884,\n",
       "  0.5360762079556783,\n",
       "  0.5359721498760751,\n",
       "  0.535926975612718,\n",
       "  0.5360466452633462,\n",
       "  0.5359077695908585,\n",
       "  0.5361787734962091,\n",
       "  0.5361672872450294,\n",
       "  0.5358506310276869,\n",
       "  0.5360339947832309,\n",
       "  0.5358098575739356,\n",
       "  0.5360010738779859,\n",
       "  0.5358035867291737,\n",
       "  0.5359294092267509,\n",
       "  0.535748635365711,\n",
       "  0.5359904780620481,\n",
       "  0.5359825857771121,\n",
       "  0.535820088008555,\n",
       "  0.5356704728390144,\n",
       "  0.5355631541915056,\n",
       "  0.5354172393558471,\n",
       "  0.5357590729628152,\n",
       "  0.5355021912392562,\n",
       "  0.5359039745195125,\n",
       "  0.5356426088790583,\n",
       "  0.5357199071384058,\n",
       "  0.5359014696706601,\n",
       "  0.5358811469097448,\n",
       "  0.5358407242995936,\n",
       "  0.5358939151453778,\n",
       "  0.5358096319970077,\n",
       "  0.5360062449443631,\n",
       "  0.5359694160581604,\n",
       "  0.5356941208606814,\n",
       "  0.5356540490941304,\n",
       "  0.5356689299025187,\n",
       "  0.535491547206553,\n",
       "  0.5355846518423499,\n",
       "  0.5358727317515427,\n",
       "  0.5358546666982698,\n",
       "  0.5357450309807692,\n",
       "  0.535479607136269,\n",
       "  0.5360704527153233,\n",
       "  0.5356882149126472,\n",
       "  0.535626875918086,\n",
       "  0.5356654927013366,\n",
       "  0.5356366837896952,\n",
       "  0.5358385567258044,\n",
       "  0.5356801920305423,\n",
       "  0.5355392486099305,\n",
       "  0.5357888714084781,\n",
       "  0.5357283150277486,\n",
       "  0.5356213959251962,\n",
       "  0.535658790086343,\n",
       "  0.5361292059344005,\n",
       "  0.5356718112782735,\n",
       "  0.5357642520249375,\n",
       "  0.5354660366608844,\n",
       "  0.5356803078476976,\n",
       "  0.535931083245006,\n",
       "  0.5357020448863021,\n",
       "  0.5354184825730518,\n",
       "  0.5355077994063617,\n",
       "  0.5359310939059994,\n",
       "  0.5356672444963843,\n",
       "  0.5355991025765737,\n",
       "  0.5357689317164382,\n",
       "  0.5355607944775403,\n",
       "  0.5356426827791261,\n",
       "  0.5354251221912664,\n",
       "  0.5353846976427528,\n",
       "  0.535443107287089,\n",
       "  0.5357508220808292,\n",
       "  0.5353227296495825,\n",
       "  0.5355073797508954,\n",
       "  0.535394103788748,\n",
       "  0.5358857907415405,\n",
       "  0.5358148348040697,\n",
       "  0.5355250791805547,\n",
       "  0.5356989851812037,\n",
       "  0.5355834309163132,\n",
       "  0.5357178730693289,\n",
       "  0.5354137881015374,\n",
       "  0.5356488535559274,\n",
       "  0.5356483675115477,\n",
       "  0.535665151064958,\n",
       "  0.5353227383722134,\n",
       "  0.5358282456068488,\n",
       "  0.5357419361428517,\n",
       "  0.5352598060437335,\n",
       "  0.5352612178984696,\n",
       "  0.5353503854778724,\n",
       "  0.5356503703245302,\n",
       "  0.5357969679483553,\n",
       "  0.53563384990382,\n",
       "  0.5354980790033573,\n",
       "  0.5357348834111438,\n",
       "  0.5355075125287219,\n",
       "  0.5354570227909864,\n",
       "  0.5354541072515937,\n",
       "  0.5356129453918799,\n",
       "  0.5352371984381017,\n",
       "  0.5351501577268771,\n",
       "  0.5353528285414223,\n",
       "  0.5356570375644094,\n",
       "  0.5355518317319513,\n",
       "  0.5352343417764679,\n",
       "  0.5357095121852751,\n",
       "  0.5354840520436202,\n",
       "  0.5355829005318928,\n",
       "  0.5353674735964798,\n",
       "  0.535352947023826,\n",
       "  0.5349860033853268,\n",
       "  0.5352376873900251,\n",
       "  0.5356208725673396,\n",
       "  0.535528874494196,\n",
       "  0.5351683344782853,\n",
       "  0.5351202606670256,\n",
       "  0.5355329891530479,\n",
       "  0.5352090946057948,\n",
       "  0.5352525415459299,\n",
       "  0.5353318823546898,\n",
       "  0.5351964300725518,\n",
       "  0.5354780264017058,\n",
       "  0.5353900322584602,\n",
       "  0.5353056989549622,\n",
       "  0.5354609019388028,\n",
       "  0.5349298519332234,\n",
       "  0.5349471571484232,\n",
       "  0.5346099598620965,\n",
       "  0.5354769692672947,\n",
       "  0.5352515224518815,\n",
       "  0.535059903453036,\n",
       "  0.5353651652491189,\n",
       "  0.5351490867816335,\n",
       "  0.5354633202882317,\n",
       "  0.535063816522195,\n",
       "  0.5355750811778432,\n",
       "  0.5352763218608328,\n",
       "  0.5351867624899236,\n",
       "  0.5354182170173987,\n",
       "  0.5349765000789146,\n",
       "  0.5350298585930491,\n",
       "  0.5351667018925271,\n",
       "  0.5353681527502169,\n",
       "  0.5353003493169459,\n",
       "  0.5350631349455051,\n",
       "  0.535356499799868,\n",
       "  0.5350494106126026,\n",
       "  0.5352499802422718,\n",
       "  0.5350338845718198,\n",
       "  0.5353013751952629,\n",
       "  0.5350829891073026]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_callback.history  # why is there still no val_loss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# didn't execute from here onward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_directory = base_dir + '/tiny_test16/class0'\n",
    "files = os.listdir(images_directory)\n",
    "files.sort()\n",
    "\n",
    "images = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for file in files:\n",
    "    counter += 1\n",
    "    if counter > 100:\n",
    "        break\n",
    "    if not file.startswith('.'):\n",
    "        #print(file)\n",
    "        \n",
    "#         img = load_img(images_directory + '/' + file, False, target_size=(patch_size, patch_size))\n",
    "#         x = img_to_array(img)\n",
    "#         x = np.expand_dims(x, axis=0)\n",
    "#         images.append(x)\n",
    "        \n",
    "#         img = load_img(images_directory + '/' + file, False, target_size=(input_patch_size, input_patch_size))\n",
    "        img = imageio.imread(images_directory + '/' + file)\n",
    "        img = np.expand_dims(img, axis=-1)        \n",
    "        images.append(img)\n",
    "        \n",
    "\n",
    "\n",
    "images = np.array(images).reshape(np.array(images).shape[0], input_shape[0], input_shape[1], input_shape[2])\n",
    "images = images / 255\n",
    "predictions = autoencoder.predict_on_batch(np.array(images))\n",
    "print(\"predictions: \")\n",
    "for i, im1 in enumerate(images):\n",
    "    im_1 = im1.reshape(input_shape)\n",
    "    plt.imshow(im_1, interpolation='nearest')\n",
    "    plt.show()\n",
    "    \n",
    "    pred_1 = predictions[i].numpy()#.reshape(input_shape)\n",
    "    plt.imshow(pred_1, interpolation='nearest')\n",
    "    plt.show()\n",
    "    \n",
    "    if i > 2:\n",
    "        break\n",
    "    print(\"next\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f7e6b5ccdd8>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f7e6b5cc588>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f7e6fcc5f98>\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f7e6b5cc128>\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f7e6e4a6da0>\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f7e6b14b978>\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 16, 16, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 16, 16, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 32)          0         \n",
      "=================================================================\n",
      "Total params: 19,392\n",
      "Trainable params: 19,392\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = Model(input_img, encoded)\n",
    "for i in range(1, len(encoder.layers)):\n",
    "    print(encoder.get_layer(index=i))\n",
    "    encoder.get_layer(index=i).set_weights(autoencoder.get_layer(index=i).get_weights())\n",
    "encoder.summary()\n",
    "\n",
    "# encoder.save(base_dir + '/encoder' + model_version + '.h5')\n",
    "encoder.save(base_dir + '/' + model_version + '__encoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = encoder.predict_on_batch(np.array(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 8, 3), dtype=float32, numpy=\n",
       "array([[[0.4687319 , 0.49327746, 0.36475247],\n",
       "        [0.45917287, 0.5299182 , 0.34918627],\n",
       "        [0.45706642, 0.5147845 , 0.34410366],\n",
       "        [0.43663764, 0.49823803, 0.3672783 ],\n",
       "        [0.41848794, 0.4933808 , 0.3847771 ],\n",
       "        [0.39643723, 0.47318175, 0.37775475],\n",
       "        [0.39109114, 0.45867485, 0.36692142],\n",
       "        [0.40281394, 0.44525164, 0.37302437]],\n",
       "\n",
       "       [[0.46041107, 0.51659435, 0.33979943],\n",
       "        [0.46980157, 0.5751926 , 0.34173083],\n",
       "        [0.47157863, 0.5601211 , 0.3408242 ],\n",
       "        [0.43710932, 0.5458603 , 0.3502554 ],\n",
       "        [0.40591332, 0.53194016, 0.37000254],\n",
       "        [0.37138948, 0.48986995, 0.36715367],\n",
       "        [0.35074612, 0.47033924, 0.34184617],\n",
       "        [0.36991128, 0.45179874, 0.32374305]],\n",
       "\n",
       "       [[0.48024878, 0.5416377 , 0.34048468],\n",
       "        [0.4785609 , 0.58541095, 0.3535821 ],\n",
       "        [0.46945688, 0.586514  , 0.372834  ],\n",
       "        [0.4556866 , 0.57783   , 0.37135366],\n",
       "        [0.41862264, 0.55973953, 0.36492613],\n",
       "        [0.3839564 , 0.5154443 , 0.35826367],\n",
       "        [0.3626115 , 0.47676158, 0.32153112],\n",
       "        [0.35437635, 0.46150088, 0.31808606]],\n",
       "\n",
       "       [[0.4988543 , 0.5430629 , 0.32755074],\n",
       "        [0.49789616, 0.58876234, 0.34445143],\n",
       "        [0.4958063 , 0.58804065, 0.3543804 ],\n",
       "        [0.46639264, 0.5950909 , 0.36181477],\n",
       "        [0.43556365, 0.56647134, 0.36483997],\n",
       "        [0.404573  , 0.51970804, 0.34744307],\n",
       "        [0.37934053, 0.48057014, 0.32230407],\n",
       "        [0.3872116 , 0.46268395, 0.31583363]],\n",
       "\n",
       "       [[0.5044174 , 0.55593854, 0.34891617],\n",
       "        [0.506134  , 0.59272736, 0.35223237],\n",
       "        [0.5207095 , 0.5912356 , 0.36200845],\n",
       "        [0.50202495, 0.59224427, 0.36336422],\n",
       "        [0.48363674, 0.5739438 , 0.38153675],\n",
       "        [0.4531376 , 0.5434005 , 0.37604773],\n",
       "        [0.42111465, 0.5259646 , 0.3583475 ],\n",
       "        [0.44448778, 0.5158225 , 0.35366133]],\n",
       "\n",
       "       [[0.5268514 , 0.5540347 , 0.35595393],\n",
       "        [0.51989174, 0.5958156 , 0.3670512 ],\n",
       "        [0.54700357, 0.60815895, 0.39089453],\n",
       "        [0.5355379 , 0.6153048 , 0.3743138 ],\n",
       "        [0.526646  , 0.6123319 , 0.40450057],\n",
       "        [0.51293147, 0.60091096, 0.4198707 ],\n",
       "        [0.4947664 , 0.60001147, 0.39901853],\n",
       "        [0.51796246, 0.57224154, 0.4330128 ]],\n",
       "\n",
       "       [[0.5619532 , 0.5600096 , 0.36726478],\n",
       "        [0.5693816 , 0.6091318 , 0.36051258],\n",
       "        [0.57952535, 0.631266  , 0.3929014 ],\n",
       "        [0.55792594, 0.6604324 , 0.4105712 ],\n",
       "        [0.5777429 , 0.6747705 , 0.47402063],\n",
       "        [0.5877776 , 0.6748953 , 0.50264376],\n",
       "        [0.57731897, 0.68344516, 0.4890481 ],\n",
       "        [0.590487  , 0.6371467 , 0.502354  ]],\n",
       "\n",
       "       [[0.56318164, 0.54423684, 0.38965526],\n",
       "        [0.5813107 , 0.5763751 , 0.38604948],\n",
       "        [0.5855452 , 0.60798216, 0.42417213],\n",
       "        [0.5920745 , 0.6522277 , 0.46124688],\n",
       "        [0.63526535, 0.679049  , 0.5278307 ],\n",
       "        [0.65175104, 0.7172686 , 0.5582107 ],\n",
       "        [0.6441335 , 0.69861174, 0.5462327 ],\n",
       "        [0.6156322 , 0.64086974, 0.5175602 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_shape = (8, 2, 2)\n",
    "\n",
    "images_directory = base_dir + '/tiny_test16/class0'\n",
    "files = os.listdir(images_directory)\n",
    "files.sort()\n",
    "\n",
    "images = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for file in files:\n",
    "    counter += 1\n",
    "#     if counter > 100:\n",
    "#         break\n",
    "    if not file.startswith('.'):\n",
    "        #print(file)\n",
    "        \n",
    "        img = load_img(images_directory + '/' + file, False, target_size=(patch_size, patch_size))\n",
    "        x = img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        images.append(x)\n",
    "        \n",
    "\n",
    "\n",
    "images = np.array(images).reshape(np.array(images).shape[0], input_shape[0], input_shape[1], input_shape[2]) #patch_size, patch_size, 3\n",
    "images /= 255\n",
    "predictions = encoder.predict_on_batch(np.array(images))\n",
    "# print(\"predictions: \")\n",
    "\n",
    "# for i, im1 in enumerate(images):\n",
    "#     im_1 = im1.reshape(input_shape)\n",
    "#     plt.imshow(im_1, interpolation='nearest')\n",
    "#     plt.show()\n",
    "    \n",
    "#     pred_1 = predictions[i].reshape(code_shape)\n",
    "#     plt.imshow(pred_1, interpolation='nearest')\n",
    "#     plt.show()\n",
    "    \n",
    "#     print(\"next\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_2",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
