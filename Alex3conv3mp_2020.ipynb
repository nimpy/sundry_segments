{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import listdir\n",
    "from os import system\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import imageio\n",
    "from skimage.measure import block_reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 16\n",
    "nb_channels = 3\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/niaki/Code/ImageNet/tiny-imagenet-200'\n",
    "\n",
    "train_data_dir      = base_dir + '/tiny_train16'\n",
    "validation_data_dir = base_dir + '/tiny_validation16'\n",
    "test_data_dir       = base_dir + '/tiny_test16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_data(dir_patches):\n",
    "    \"\"\"Load all the patches from dir_patches into tensors for training the autoencoder.\n",
    "    Return:\n",
    "        patches_in  -- tensor of stacked patches in their original shape, 16x16\n",
    "        patches_out -- tensor of the original patches downsampled to 8x8\n",
    "    \n",
    "    \"\"\"\n",
    "    files_patches = listdir(dir_patches + '/class0')\n",
    "    files_patches.sort()\n",
    "    \n",
    "    patches_in = []\n",
    "    patches_out = []\n",
    "\n",
    "    \n",
    "    for file_patch in files_patches:\n",
    "        patch_in = imageio.imread(dir_patches + '/class0/' + file_patch)\n",
    "        \n",
    "        patch_out = block_reduce(patch_in, (2, 2, 1), func=np.mean)  # downsample (mean-pool)\n",
    "        \n",
    "        patches_in.append(patch_in)\n",
    "        patches_out.append(patch_out)\n",
    "        \n",
    "\n",
    "    patches_in = np.array(patches_in)\n",
    "    patches_in = patches_in.astype(np.float64) / 255\n",
    "#     patches_in = np.expand_dims(patches_in, -1)  # need this if grayscale\n",
    "    \n",
    "    patches_out = np.array(patches_out)\n",
    "    patches_out = patches_out.astype(np.float64) / 255\n",
    "#     patches_out = np.expand_dims(patches_out, -1)  # need this if grayscale\n",
    "        \n",
    "    print(\"in\", patches_in.shape, \"; out\", patches_out.shape)\n",
    "    \n",
    "    return patches_in, patches_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in (157086, 16, 16, 3) ; out (157086, 8, 8, 3)\n",
      "in (3932, 16, 16, 3) ; out (3932, 8, 8, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train, _ = loading_data(train_data_dir)  # y_train\n",
    "x_validation, _ = loading_data(validation_data_dir)  # y_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do I copy or do I just point to the same thing?\n",
    "#   I think I can just point to the same thing\n",
    "y_train = x_train\n",
    "y_validation = x_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEBBJREFUeJzt3X2MXNV9xvHv49ld72K7wUBNCEYFKoREo7YgCxFS0agu1FCKkyp/GDWtGyJFUUsLVaPEEVIT9a+madPXKBEFGtpagEogQRE0WCRpVam4AdfmzQQMpWDjgEta24296931r3/MdTK7zNhzz33xrs/zkVY7M/eevb89d5+9M3fumaOIwMzys+RkF2BmJ4fDb5Yph98sUw6/WaYcfrNMOfxmmXL4zTLl8JtlyuE3y9RImxsbHx+LFcsnWtnWkiVp/9ck1VzJYL668uQRifs5sVnEbCsbO3DwEIcPHxmqYavhX7F8gl/9lStLt0sJ5NKlS0u3ARgdHU1ql+Lo0aOtbSvVYvgHlfL3kfpPPrXdkekflG4zMlI+npvv++eh1/XTfrNMVQq/pHWSvitpl6RNdRVlZs1LDr+kDvAF4FrgEuBGSZfUVZiZNavKkf9yYFdEvBwRR4B7gfX1lGVmTasS/nOB13ru7y4eM7NFoEr4+532fNupYUkflfSEpCcmJ49U2JyZ1alK+HcD5/XcXw28Pn+liLg9ItZExJrx8bEKmzOzOlUJ/3eAiyRdIGkM2AA8VE9ZZta05It8ImJG0s3AN4AOcFdEPFtbZWbWqEpX+EXEw8DDNdViZi3yFX5mmXL4zTLV6sCekc4IK1euLN0uZQDM7GzKKKq0dothgI6dXGNj5d/pavrvykd+s0w5/GaZcvjNMuXwm2XK4TfLlMNvlimH3yxTDr9Zphx+s0w5/GaZcvjNMuXwm2Wq1YE90zPT7Nu3r3S7lNl3Uqfr6nQ6pduMj48nbSt1VqGDBw+WbpPaH222O5WnSpucKr/PUmbsKdOFPvKbZcrhN8uUw2+WqSrTdZ0n6VuSdkp6VtItdRZmZs2qcsJvBvj9iNgmaQXwpKQtEfFcTbWZWYOSj/wRsTcithW3DwI78XRdZotGLa/5JZ0PXAps7bPsR9N1TU3XsTkzq0Hl8EtaDnwFuDUiDsxfPme6rqWjVTdnZjWpFH5Jo3SDvzkiHqinJDNrQ5Wz/QLuBHZGxOfrK8nM2lDlyP9e4NeBX5C0vfi6rqa6zKxhVSbq/FegvYuxzaxWvsLPLFPtjuqbnmbPnj2l242Oln+XIHWqo5TRXin1QdoUTgCTk5Ol26SOzksZWZbaLrXGxTAacHrmUOk2KaNFp6dnhl7XR36zTDn8Zply+M0y5fCbZcrhN8uUw2+WKYffLFMOv1mmHH6zTDn8Zply+M0y5fCbZarVgT2zs7McOPC/pdulDKaYmRl+gEOv2dnZpHYpUgekpPRHm9OXpbZrc4BOmwO/ADoJSUvZ1tTU1NDr+shvlimH3yxTDr9Zpur46O6OpP+Q9PU6CjKzdtRx5L+F7mw9ZraIVP3c/tXALwN31FOOmbWl6pH/z4FPAGnvm5jZSVNl0o7rgTcj4skTrPfDufqmZ/w/wmyhqDppxw2SXgHupTt5xz/MX6l3rr7REb+5YLZQVJmi+1MRsToizgc2AN+MiA/VVpmZNcqHYrNM1XJtf0R8G/h2HT/LzNrhI79Zplod1Se1N43TxMRE6Taw8Eejtb29Nkcepo6YSxmhlzqqL7WdlpRvlzIytcz+8pHfLFMOv1mmHH6zTDn8Zply+M0y5fCbZcrhN8uUw2+WKYffLFMOv1mmHH6zTDn8Zply+M0y1eqovrHRMVavXl26XZsjxBb6tgBGR0eT2qU4Vfux7X22pFO+XcoI2Ode2D/0uj7ym2XK4TfLVNVJO06XdL+k5yXtlPSeugozs2ZVfc3/F8A/RcQHJY0Bp9VQk5m1IDn8kn4MuAr4TYCIOAIcqacsM2talaf9FwL7gL8tZum9Q9Kymuoys4ZVCf8IcBnwxYi4FPgBsGn+Sr3TdU1OTVfYnJnVqUr4dwO7I2Jrcf9+uv8M5uidrmt8aXvvT5vZ8VWZrut7wGuSLi4eWgs8V0tVZta4qmf7fwfYXJzpfxn4cPWSzKwNlcIfEduBNTXVYmYt8hV+ZplqdWDPks4Sli9fXrpd29NhlZUynRik/14p0zilSh3IstCnFEvdZ6kOHT5Yus34+HjpNkuWDD/dnI/8Zply+M0y5fCbZcrhN8uUw2+WKYffLFMOv1mmHH6zTDn8Zply+M0y5fCbZcrhN8uUw2+WqVZH9QGgo6WbLOkMP1LpmE5CG0gb7XX0aPnfCWB2djap3dLx8h+Hljo6L/V3S91eipRRfamDDlNHK5555pml27z11lul20QMv7985DfLlMNvlqmq03X9nqRnJT0j6R5J5T99wMxOiuTwSzoX+F1gTUS8G+gAG+oqzMyaVfVp/wgwIWmE7jx9r1cvyczaUOVz+/cAfwK8CuwF9kfEo3UVZmbNqvK0fyWwHrgAeBewTNKH+qz3o+m6Jj1dl9lCUeVp/y8C/xkR+yJiGngAuHL+SnOm60p4f9rMmlEl/K8CV0g6Td0rH9YCO+spy8yaVuU1/1a6k3NuA54uftbtNdVlZg2rOl3Xp4FP11SLmbXIV/iZZcrhN8tUq6P6JDE2Nla6XcpIu9RRfSmjtlJHsKXOF5eyvdTRaIuhH9uUWuPU1FTpNhMTE6XbSMP/TfnIb5Yph98sUw6/WaYcfrNMOfxmmXL4zTLl8JtlyuE3y5TDb5Yph98sUw6/WaYcfrNMtT9dV4KUwRSpAzDa3FabUgf2pA4+Sm2XIqX/U6chS203Olp+QFuKMv3uI79Zphx+s0ydMPyS7pL0pqRneh47Q9IWSS8W31c2W6aZ1W2YI/+XgXXzHtsEPBYRFwGPFffNbBE5Yfgj4l+A7897eD1wd3H7buD9NddlZg1Lfc1/dkTsBSi+r6qvJDNrQ+Mn/Hqn6zo8eaTpzZnZkFLD/4akcwCK728OWrF3uq6J8Xbe6zSzE0sN/0PAxuL2RuBr9ZRjZm0Z5q2+e4B/Ay6WtFvSR4A/Aq6W9CJwdXHfzBaRE17eGxE3Dli0tuZazKxFvsLPLFMOv1mmTsKovnZGwB09OtvKdqD9UX0pI/QSB/Ult2trP6duK/X36nTSjpeHDh0q3SZlBGGZNj7ym2XK4TfLlMNvlimH3yxTDr9Zphx+s0w5/GaZcvjNMuXwm2XK4TfLlMNvlimH3yxTrQ7skcTIyKKYIeyUkzr4KHV6qpTtpU4pltIudTqx1BpXrSr/GbeHDx8u3abT6Qy9ro/8Zply+M0y5fCbZSp1rr7PSXpe0lOSHpR0erNlmlndUufq2wK8OyJ+GngB+FTNdZlZw5Lm6ouIRyNiprj7OLC6gdrMrEF1vOa/CXhk0MI503Ud9nRdZgtFpfBLug2YATYPWmfOdF0Tnq7LbKFIvuJG0kbgemBttP3xtWZWWVL4Ja0DPgn8fESU/0xiMzvpUufq+2tgBbBF0nZJX2q4TjOrWepcfXc2UIuZtchX+Jll6pQdYneqjkar0i5Faj+mSD1vnDpCL0Vq309OTpZu0/Tv5SO/WaYcfrNMOfxmmXL4zTLl8JtlyuE3y5TDb5Yph98sUw6/WaYcfrNMOfxmmXL4zTLl8JtlalGM6ksZ7ZU6QmwxfCJZmzUuhhFzbY5yTO372dnZVrZVpo2P/GaZcvjNMpU0XVfPso9LCklnNVOemTUldbouJJ0HXA28WnNNZtaCpOm6Cn8GfAJY+GfIzOxtkl7zS7oB2BMRO4ZY19N1mS1Apd/qk3QacBtwzTDrR8TtwO0AZ6863c8SzBaIlCP/TwIXADskvUJ3ht5tkt5ZZ2Fm1qzSR/6IeBpYdex+8Q9gTUT8d411mVnDUqfrMrNFLnW6rt7l59dWjZm1xlf4mWWq1YE9khgdHW1lWykDKSBteqrUgSWpg2ampqZa21bq79bpdFrbVpsDv1KnL1u2bFnpNvv37y/dxgN7zOyEHH6zTDn8Zply+M0y5fCbZcrhN8uUw2+WKYffLFMOv1mmHH6zTDn8Zply+M0y5fCbZUptTv0kaR/wXwMWnwUshE8Dch1zuY65FnodPxERPz7MD2g1/Mcj6YmIWOM6XIfraKcOP+03y5TDb5aphRT+2092AQXXMZfrmOuUqWPBvOY3s3YtpCO/mbWo1fBLWifpu5J2SdrUZ/lSSfcVy7dKOr+BGs6T9C1JOyU9K+mWPuu8T9J+SduLrz+ou46ebb0i6eliO0/0WS5Jf1n0yVOSLqt5+xf3/J7bJR2QdOu8dRrrj35TwEs6Q9IWSS8W31cOaLuxWOdFSRsbqONzkp4v+v1BSacPaHvcfVhDHZ+RtKen/68b0Pa4+XqbiGjlC+gALwEXAmPADuCSeev8FvCl4vYG4L4G6jgHuKy4vQJ4oU8d7wO+3lK/vAKcdZzl1wGPAAKuALY2vI++R/e94lb6A7gKuAx4puexPwY2Fbc3AZ/t0+4M4OXi+8ri9sqa67gGGCluf7ZfHcPswxrq+Azw8SH23XHzNf+rzSP/5cCuiHg5Io4A9wLr562zHri7uH0/sFapn+c8QETsjYhtxe2DwE7g3Dq3UbP1wN9F1+PA6ZLOaWhba4GXImLQhVi1i/5TwPf+HdwNvL9P018CtkTE9yPif4AtwLo664iIRyNiprj7ON15KRs1oD+GMUy+5mgz/OcCr/Xc383bQ/fDdYpO3w+c2VRBxcuKS4GtfRa/R9IOSY9I+qmmagACeFTSk5I+2mf5MP1Wlw3APQOWtdUfAGdHxF7o/rOmZ27IHm32C8BNdJ+B9XOifViHm4uXH3cNeBlUuj/aDH+/I/j8txqGWacWkpYDXwFujYgD8xZvo/vU92eAvwK+2kQNhfdGxGXAtcBvS7pqfql92tTeJ5LGgBuAf+yzuM3+GFabfyu3ATPA5gGrnGgfVvVFurNj/yywF/jTfmX2eey4/dFm+HcD5/XcXw28PmgdSSPAO0h7CnRckkbpBn9zRDwwf3lEHIiI/ytuPwyMSjqr7jqKn/968f1N4EG6T996DdNvdbgW2BYRb/SpsbX+KLxx7KVN8f3NPuu00i/FicTrgV+L4sX1fEPsw0oi4o2ImI2Io8DfDPj5pfujzfB/B7hI0gXFUWYD8NC8dR4Cjp21/SDwzUEdnqo4h3AnsDMiPj9gnXceO9cg6XK6/fRWnXUUP3uZpBXHbtM9wfTMvNUeAn6jOOt/BbD/2FPimt3IgKf8bfVHj96/g43A1/qs8w3gGkkri6fB1xSP1UbSOuCTwA0RcWjAOsPsw6p19J7j+cCAnz9Mvuaq4wxliTOZ19E9u/4ScFvx2B/S7VyAcbpPO3cB/w5c2EANP0f36dBTwPbi6zrgY8DHinVuBp6le8b0ceDKhvrjwmIbO4rtHeuT3loEfKHos6eBNQ3UcRrdML+j57FW+oPuP5y9wDTdo9dH6J7neQx4sfh+RrHuGuCOnrY3FX8ru4APN1DHLrqvo4/9nRx7J+pdwMPH24c11/H3xb5/im6gz5lfx6B8He/LV/iZZcpX+JllyuE3y5TDb5Yph98sUw6/WaYcfrNMOfxmmXL4zTL1/8NU7rKV/2q0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_index = np.random.randint(x_train.shape[0]) #  5429\n",
    "# print(np.array(np.round(x_train[temp_index] * 255), dtype=np.uint8))\n",
    "plt.imshow(np.array(np.round(x_train[temp_index] * 255), dtype=np.uint8))\n",
    "plt.show()\n",
    "plt.imshow(np.array(np.round(y_train[temp_index] * 255), dtype=np.uint8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 16, 16, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 16, 16, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 2, 32)          9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 16, 3)         867       \n",
      "=================================================================\n",
      "Total params: 48,003\n",
      "Trainable params: 48,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (patch_size, patch_size, nb_channels)\n",
    "input_img = Input(shape=input_shape)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation=\"elu\", padding=\"same\")(input_img)\n",
    "x = Conv2D(32, (3, 3), activation=\"elu\", padding=\"same\")(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"elu\", padding=\"same\")(x)\n",
    "x = MaxPool2D((2, 2), padding=\"same\")(x)\n",
    "x = MaxPool2D((2, 2), padding=\"same\")(x)\n",
    "encoded = MaxPool2D((2, 2), padding=\"same\")(x)\n",
    "\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation=\"elu\", padding=\"same\")(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"elu\", padding=\"same\")(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"elu\", padding=\"same\")(x)  # decoded = Conv2D(3, (3, 3), activation=\"elu\", padding=\"same\")(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(3, (3, 3), activation=\"elu\", padding=\"same\")(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7fdb18c75208>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdb18b1db70>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdb118ee1d0>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdb118ee860>\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fdb118eea90>\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fdb118eebe0>\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fdb118eed30>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdb118eee80>\n",
      "<tensorflow.python.keras.layers.convolutional.UpSampling2D object at 0x7fdb118f10b8>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdb118f11d0>\n",
      "<tensorflow.python.keras.layers.convolutional.UpSampling2D object at 0x7fdb1922fe80>\n"
     ]
    }
   ],
   "source": [
    "model_version_dwnsmpld_output = 'patch_desc_ae_20201026_14251116_alex_3conv3mp_2020_augm_elu_lastelu_dwnsmpl'\n",
    "autoencoder_dwnsmpld_output = load_model(base_dir + '/' + model_version_dwnsmpld_output + '.h5')\n",
    "\n",
    "for i in range(11):\n",
    "    print(autoencoder_dwnsmpld_output.get_layer(index=i))\n",
    "    autoencoder.get_layer(index=i).set_weights(autoencoder_dwnsmpld_output.get_layer(index=i).get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datagen = ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n",
    "    width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
    "    horizontal_flip=False, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "# os.environ['WANDB_MODE'] = 'dryrun'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: nimpy (use `wandb login --relogin` to force relogin)\n",
      "wandb: wandb version 0.10.8 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.7<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">light-river-5</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nimpy/patch-desc-ae\" target=\"_blank\">https://wandb.ai/nimpy/patch-desc-ae</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/nimpy/patch-desc-ae/runs/333fadgt\" target=\"_blank\">https://wandb.ai/nimpy/patch-desc-ae/runs/333fadgt</a><br/>\n",
       "                Run data is saved locally in <code>wandb/run-20201027_095631-333fadgt</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "  project=\"patch-desc-ae\",\n",
    "  config={\n",
    "    \"augmentation\": True,\n",
    "    \"elus\": False,\n",
    "    \"last_layer_activation\": \"elu\",\n",
    "    \"downsampling_output\": False,\n",
    "    \"optimizer\": \"adadelta\", \n",
    "    \"loss\": \"binary_crossentropy\",\n",
    "    \"epochs\": 500 }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://wandb.ai/nimpy/patch-desc-ae/runs/333fadgt?jupyter=true\" style=\"border:none;width:100%;height:420px\">\n",
       "                </iframe>"
      ],
      "text/plain": [
       "<wandb.jupyter.Run at 0x7fdb63ff6ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/niaki/Code/ImageNet/tiny-imagenet-200/weights_patch_desc_ae_20201027_09572116_alex_3conv3mp_2020_augm_elu_lastelu_NOTdwnsmpl\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 4909 steps, validate for 123 steps\n",
      "Epoch 1/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 1.5291 - val_loss: 0.6965\n",
      "Epoch 2/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.6308 - val_loss: 0.5929\n",
      "Epoch 3/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5840 - val_loss: 0.5731\n",
      "Epoch 4/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5707 - val_loss: 0.5626\n",
      "Epoch 5/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5637 - val_loss: 0.5575\n",
      "Epoch 6/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5595 - val_loss: 0.5539\n",
      "Epoch 7/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5567 - val_loss: 0.5518\n",
      "Epoch 8/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5549 - val_loss: 0.5499\n",
      "Epoch 9/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5534 - val_loss: 0.5487\n",
      "Epoch 10/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5522 - val_loss: 0.5474\n",
      "Epoch 11/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5512 - val_loss: 0.5465\n",
      "Epoch 12/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5503 - val_loss: 0.5460\n",
      "Epoch 13/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5495 - val_loss: 0.5454\n",
      "Epoch 14/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5489 - val_loss: 0.5446\n",
      "Epoch 15/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5483 - val_loss: 0.5443\n",
      "Epoch 16/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5478 - val_loss: 0.5434\n",
      "Epoch 17/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5473 - val_loss: 0.5432\n",
      "Epoch 18/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5469 - val_loss: 0.5424\n",
      "Epoch 19/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5465 - val_loss: 0.5422\n",
      "Epoch 20/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5462 - val_loss: 0.5425\n",
      "Epoch 21/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5460 - val_loss: 0.5416\n",
      "Epoch 22/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5457 - val_loss: 0.5416\n",
      "Epoch 23/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5454 - val_loss: 0.5413\n",
      "Epoch 24/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5451 - val_loss: 0.5408\n",
      "Epoch 25/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5450 - val_loss: 0.5408\n",
      "Epoch 26/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5448 - val_loss: 0.5409\n",
      "Epoch 27/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5446 - val_loss: 0.5400\n",
      "Epoch 28/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5444 - val_loss: 0.5402\n",
      "Epoch 29/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5442 - val_loss: 0.5402\n",
      "Epoch 30/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5440 - val_loss: 0.5396\n",
      "Epoch 31/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5439 - val_loss: 0.5398\n",
      "Epoch 32/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5438 - val_loss: 0.5396\n",
      "Epoch 33/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5436 - val_loss: 0.5394\n",
      "Epoch 34/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5434 - val_loss: 0.5391\n",
      "Epoch 35/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5433 - val_loss: 0.5391\n",
      "Epoch 36/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5432 - val_loss: 0.5390\n",
      "Epoch 37/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5432 - val_loss: 0.5388\n",
      "Epoch 38/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5430 - val_loss: 0.5390\n",
      "Epoch 39/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5429 - val_loss: 0.5388\n",
      "Epoch 40/500\n",
      "4909/4909 [==============================] - 64s 13ms/step - loss: 0.5429 - val_loss: 0.5385\n",
      "Epoch 41/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5427 - val_loss: 0.5390\n",
      "Epoch 42/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5426 - val_loss: 0.5385\n",
      "Epoch 43/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5426 - val_loss: 0.5383\n",
      "Epoch 44/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5425 - val_loss: 0.5380\n",
      "Epoch 45/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5423 - val_loss: 0.5382\n",
      "Epoch 46/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5423 - val_loss: 0.5381\n",
      "Epoch 47/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5422 - val_loss: 0.5380\n",
      "Epoch 48/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5422 - val_loss: 0.5380\n",
      "Epoch 49/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5421 - val_loss: 0.5377\n",
      "Epoch 50/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5420 - val_loss: 0.5377\n",
      "Epoch 51/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5419 - val_loss: 0.5373\n",
      "Epoch 52/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5419 - val_loss: 0.5378\n",
      "Epoch 53/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5418 - val_loss: 0.5376\n",
      "Epoch 54/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5418 - val_loss: 0.5375\n",
      "Epoch 55/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5417 - val_loss: 0.5378\n",
      "Epoch 56/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5416 - val_loss: 0.5370\n",
      "Epoch 57/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5415 - val_loss: 0.5372\n",
      "Epoch 58/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5416 - val_loss: 0.5373\n",
      "Epoch 59/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5415 - val_loss: 0.5374\n",
      "Epoch 60/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5415 - val_loss: 0.5372\n",
      "Epoch 61/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5414 - val_loss: 0.5373\n",
      "Epoch 62/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5413 - val_loss: 0.5369\n",
      "Epoch 63/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5413 - val_loss: 0.5369\n",
      "Epoch 64/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5412 - val_loss: 0.5368\n",
      "Epoch 65/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5412 - val_loss: 0.5371\n",
      "Epoch 66/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5411 - val_loss: 0.5369\n",
      "Epoch 67/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5411 - val_loss: 0.5372\n",
      "Epoch 68/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5411 - val_loss: 0.5366\n",
      "Epoch 69/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5410 - val_loss: 0.5368\n",
      "Epoch 70/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5410 - val_loss: 0.5368\n",
      "Epoch 71/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5409 - val_loss: 0.5366\n",
      "Epoch 72/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5409 - val_loss: 0.5364\n",
      "Epoch 73/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5408 - val_loss: 0.5367\n",
      "Epoch 74/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5408 - val_loss: 0.5364\n",
      "Epoch 75/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5409 - val_loss: 0.5365\n",
      "Epoch 76/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5408 - val_loss: 0.5363\n",
      "Epoch 77/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5408 - val_loss: 0.5364\n",
      "Epoch 78/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5407 - val_loss: 0.5363\n",
      "Epoch 79/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5407 - val_loss: 0.5364\n",
      "Epoch 80/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5406 - val_loss: 0.5360\n",
      "Epoch 81/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5406 - val_loss: 0.5361\n",
      "Epoch 82/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5406 - val_loss: 0.5362\n",
      "Epoch 83/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5405 - val_loss: 0.5363\n",
      "Epoch 84/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5405 - val_loss: 0.5363\n",
      "Epoch 85/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5404 - val_loss: 0.5362\n",
      "Epoch 86/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5405 - val_loss: 0.5360\n",
      "Epoch 87/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5404 - val_loss: 0.5359\n",
      "Epoch 88/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5404 - val_loss: 0.5362\n",
      "Epoch 89/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5404 - val_loss: 0.5363\n",
      "Epoch 90/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5403 - val_loss: 0.5361\n",
      "Epoch 91/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5403 - val_loss: 0.5363\n",
      "Epoch 92/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5403 - val_loss: 0.5359\n",
      "Epoch 93/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5403 - val_loss: 0.5358\n",
      "Epoch 94/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5402 - val_loss: 0.5361\n",
      "Epoch 95/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5402 - val_loss: 0.5360\n",
      "Epoch 96/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5402 - val_loss: 0.5359\n",
      "Epoch 97/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5402 - val_loss: 0.5360\n",
      "Epoch 98/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5401 - val_loss: 0.5360\n",
      "Epoch 99/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5400 - val_loss: 0.5359\n",
      "Epoch 100/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5401 - val_loss: 0.5358\n",
      "Epoch 101/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5401 - val_loss: 0.5359\n",
      "Epoch 102/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5400 - val_loss: 0.5358\n",
      "Epoch 103/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5400 - val_loss: 0.5359\n",
      "Epoch 104/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5400 - val_loss: 0.5355\n",
      "Epoch 105/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5400 - val_loss: 0.5357\n",
      "Epoch 106/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5399 - val_loss: 0.5358\n",
      "Epoch 107/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5399 - val_loss: 0.5353\n",
      "Epoch 108/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5398 - val_loss: 0.5356\n",
      "Epoch 109/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5399 - val_loss: 0.5357\n",
      "Epoch 110/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5398 - val_loss: 0.5355\n",
      "Epoch 111/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5399 - val_loss: 0.5354\n",
      "Epoch 112/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5398 - val_loss: 0.5353\n",
      "Epoch 113/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5397 - val_loss: 0.5358\n",
      "Epoch 114/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5398 - val_loss: 0.5357\n",
      "Epoch 115/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5397 - val_loss: 0.5358\n",
      "Epoch 116/500\n",
      "4909/4909 [==============================] - 64s 13ms/step - loss: 0.5398 - val_loss: 0.5353\n",
      "Epoch 117/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5398 - val_loss: 0.5354\n",
      "Epoch 118/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5397 - val_loss: 0.5354\n",
      "Epoch 119/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5397 - val_loss: 0.5354\n",
      "Epoch 120/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5397 - val_loss: 0.5356\n",
      "Epoch 121/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5397 - val_loss: 0.5356\n",
      "Epoch 122/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5396 - val_loss: 0.5356\n",
      "Epoch 123/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5396 - val_loss: 0.5353\n",
      "Epoch 124/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5396 - val_loss: 0.5354\n",
      "Epoch 125/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5396 - val_loss: 0.5351\n",
      "Epoch 126/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5396 - val_loss: 0.5355\n",
      "Epoch 127/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5396 - val_loss: 0.5353\n",
      "Epoch 128/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5396 - val_loss: 0.5350\n",
      "Epoch 129/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5395 - val_loss: 0.5351\n",
      "Epoch 130/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5395 - val_loss: 0.5353\n",
      "Epoch 131/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5395 - val_loss: 0.5350\n",
      "Epoch 132/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5395 - val_loss: 0.5351\n",
      "Epoch 133/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5394 - val_loss: 0.5351\n",
      "Epoch 134/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5395 - val_loss: 0.5351\n",
      "Epoch 135/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5394 - val_loss: 0.5354\n",
      "Epoch 136/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5394 - val_loss: 0.5355\n",
      "Epoch 137/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5394 - val_loss: 0.5349\n",
      "Epoch 138/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5394 - val_loss: 0.5348\n",
      "Epoch 139/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5394 - val_loss: 0.5351\n",
      "Epoch 140/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5394 - val_loss: 0.5350\n",
      "Epoch 141/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5394 - val_loss: 0.5348\n",
      "Epoch 142/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5393 - val_loss: 0.5351\n",
      "Epoch 143/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5393 - val_loss: 0.5351\n",
      "Epoch 144/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5393 - val_loss: 0.5346\n",
      "Epoch 145/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5393 - val_loss: 0.5345\n",
      "Epoch 146/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5393 - val_loss: 0.5350\n",
      "Epoch 147/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5393 - val_loss: 0.5347\n",
      "Epoch 148/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5393 - val_loss: 0.5351\n",
      "Epoch 149/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5393 - val_loss: 0.5349\n",
      "Epoch 150/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5392 - val_loss: 0.5352\n",
      "Epoch 151/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5393 - val_loss: 0.5349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5392 - val_loss: 0.5349\n",
      "Epoch 153/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5392 - val_loss: 0.5350\n",
      "Epoch 154/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5393 - val_loss: 0.5348\n",
      "Epoch 155/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5392 - val_loss: 0.5347\n",
      "Epoch 156/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5392 - val_loss: 0.5350\n",
      "Epoch 157/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5392 - val_loss: 0.5348\n",
      "Epoch 158/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5392 - val_loss: 0.5349\n",
      "Epoch 159/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5391 - val_loss: 0.5347\n",
      "Epoch 160/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5391 - val_loss: 0.5347\n",
      "Epoch 161/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5391 - val_loss: 0.5348\n",
      "Epoch 162/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5391 - val_loss: 0.5349\n",
      "Epoch 163/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5391 - val_loss: 0.5351\n",
      "Epoch 164/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5391 - val_loss: 0.5348\n",
      "Epoch 165/500\n",
      "4909/4909 [==============================] - 60s 12ms/step - loss: 0.5390 - val_loss: 0.5348\n",
      "Epoch 166/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5390 - val_loss: 0.5348\n",
      "Epoch 167/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5390 - val_loss: 0.5351\n",
      "Epoch 168/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5390 - val_loss: 0.5346\n",
      "Epoch 169/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5390 - val_loss: 0.5349\n",
      "Epoch 170/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5390 - val_loss: 0.5349\n",
      "Epoch 171/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5389 - val_loss: 0.5346\n",
      "Epoch 172/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5390 - val_loss: 0.5344\n",
      "Epoch 173/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5390 - val_loss: 0.5352\n",
      "Epoch 174/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5390 - val_loss: 0.5347\n",
      "Epoch 175/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5390 - val_loss: 0.5346\n",
      "Epoch 176/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5390 - val_loss: 0.5347\n",
      "Epoch 177/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5389 - val_loss: 0.5348\n",
      "Epoch 178/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5390 - val_loss: 0.5348\n",
      "Epoch 179/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5390 - val_loss: 0.5345\n",
      "Epoch 180/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5389 - val_loss: 0.5346\n",
      "Epoch 181/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5389 - val_loss: 0.5349\n",
      "Epoch 182/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5389 - val_loss: 0.5350\n",
      "Epoch 183/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5390 - val_loss: 0.5345\n",
      "Epoch 184/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5389 - val_loss: 0.5342\n",
      "Epoch 185/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5389 - val_loss: 0.5344\n",
      "Epoch 186/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5388 - val_loss: 0.5345\n",
      "Epoch 187/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5388 - val_loss: 0.5348\n",
      "Epoch 188/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5388 - val_loss: 0.5348\n",
      "Epoch 189/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5389 - val_loss: 0.5346\n",
      "Epoch 190/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5388 - val_loss: 0.5343\n",
      "Epoch 191/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5388 - val_loss: 0.5341\n",
      "Epoch 192/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5388 - val_loss: 0.5347\n",
      "Epoch 193/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5388 - val_loss: 0.5344\n",
      "Epoch 194/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5388 - val_loss: 0.5347\n",
      "Epoch 195/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5388 - val_loss: 0.5345\n",
      "Epoch 196/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5388 - val_loss: 0.5344\n",
      "Epoch 197/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5388 - val_loss: 0.5341\n",
      "Epoch 198/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5388 - val_loss: 0.5346\n",
      "Epoch 199/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5387 - val_loss: 0.5347\n",
      "Epoch 200/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5387 - val_loss: 0.5346\n",
      "Epoch 201/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5387 - val_loss: 0.5344\n",
      "Epoch 202/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5387 - val_loss: 0.5343\n",
      "Epoch 203/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5387 - val_loss: 0.5344\n",
      "Epoch 204/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5387 - val_loss: 0.5346\n",
      "Epoch 205/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5387 - val_loss: 0.5343\n",
      "Epoch 206/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5386 - val_loss: 0.5346\n",
      "Epoch 207/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5387 - val_loss: 0.5345\n",
      "Epoch 208/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5387 - val_loss: 0.5345\n",
      "Epoch 209/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5386 - val_loss: 0.5344\n",
      "Epoch 210/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5387 - val_loss: 0.5344\n",
      "Epoch 211/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5387 - val_loss: 0.5345\n",
      "Epoch 212/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5386 - val_loss: 0.5344\n",
      "Epoch 213/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5386 - val_loss: 0.5348\n",
      "Epoch 214/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5386 - val_loss: 0.5343\n",
      "Epoch 215/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5386 - val_loss: 0.5344\n",
      "Epoch 216/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5386 - val_loss: 0.5342\n",
      "Epoch 217/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5386 - val_loss: 0.5343\n",
      "Epoch 218/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5385 - val_loss: 0.5342\n",
      "Epoch 219/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5386 - val_loss: 0.5340\n",
      "Epoch 220/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5386 - val_loss: 0.5340\n",
      "Epoch 221/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5386 - val_loss: 0.5342\n",
      "Epoch 222/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5386 - val_loss: 0.5342\n",
      "Epoch 223/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5386 - val_loss: 0.5341\n",
      "Epoch 224/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5385 - val_loss: 0.5340\n",
      "Epoch 225/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5386 - val_loss: 0.5344\n",
      "Epoch 226/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5385 - val_loss: 0.5343\n",
      "Epoch 227/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5385 - val_loss: 0.5342\n",
      "Epoch 228/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5385 - val_loss: 0.5342\n",
      "Epoch 229/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5385 - val_loss: 0.5346\n",
      "Epoch 230/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5386 - val_loss: 0.5345\n",
      "Epoch 231/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5386 - val_loss: 0.5344\n",
      "Epoch 232/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5385 - val_loss: 0.5338\n",
      "Epoch 233/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5385 - val_loss: 0.5339\n",
      "Epoch 234/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5385 - val_loss: 0.5340\n",
      "Epoch 235/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5385 - val_loss: 0.5343\n",
      "Epoch 236/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5385 - val_loss: 0.5344\n",
      "Epoch 237/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5385 - val_loss: 0.5339\n",
      "Epoch 238/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5385 - val_loss: 0.5340\n",
      "Epoch 239/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5384 - val_loss: 0.5339\n",
      "Epoch 240/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5385 - val_loss: 0.5342\n",
      "Epoch 241/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5385 - val_loss: 0.5342\n",
      "Epoch 242/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5384 - val_loss: 0.5338\n",
      "Epoch 243/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5384 - val_loss: 0.5339\n",
      "Epoch 244/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5384 - val_loss: 0.5340\n",
      "Epoch 245/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5385 - val_loss: 0.5341\n",
      "Epoch 246/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5384 - val_loss: 0.5341\n",
      "Epoch 247/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5384 - val_loss: 0.5343\n",
      "Epoch 248/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5384 - val_loss: 0.5337\n",
      "Epoch 249/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5384 - val_loss: 0.5339\n",
      "Epoch 250/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5384 - val_loss: 0.5339\n",
      "Epoch 251/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5384 - val_loss: 0.5342\n",
      "Epoch 252/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5383 - val_loss: 0.5341\n",
      "Epoch 253/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5383 - val_loss: 0.5343\n",
      "Epoch 254/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5383 - val_loss: 0.5339\n",
      "Epoch 255/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5384 - val_loss: 0.5337\n",
      "Epoch 256/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5383 - val_loss: 0.5340\n",
      "Epoch 257/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5383 - val_loss: 0.5340\n",
      "Epoch 258/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5383 - val_loss: 0.5339\n",
      "Epoch 259/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5383 - val_loss: 0.5338\n",
      "Epoch 260/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5383 - val_loss: 0.5337\n",
      "Epoch 261/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5383 - val_loss: 0.5339\n",
      "Epoch 262/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5383 - val_loss: 0.5342\n",
      "Epoch 263/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5383 - val_loss: 0.5336\n",
      "Epoch 264/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5384 - val_loss: 0.5341\n",
      "Epoch 265/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5383 - val_loss: 0.5340\n",
      "Epoch 266/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5383 - val_loss: 0.5339\n",
      "Epoch 267/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5382 - val_loss: 0.5339\n",
      "Epoch 268/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5383 - val_loss: 0.5340\n",
      "Epoch 269/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5383 - val_loss: 0.5341\n",
      "Epoch 270/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5383 - val_loss: 0.5341\n",
      "Epoch 271/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5382 - val_loss: 0.5337\n",
      "Epoch 272/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5382 - val_loss: 0.5340\n",
      "Epoch 273/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5382 - val_loss: 0.5338\n",
      "Epoch 274/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5383 - val_loss: 0.5341\n",
      "Epoch 275/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5382 - val_loss: 0.5341\n",
      "Epoch 276/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5383 - val_loss: 0.5338\n",
      "Epoch 277/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5382 - val_loss: 0.5339\n",
      "Epoch 278/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5381 - val_loss: 0.5342\n",
      "Epoch 279/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5382 - val_loss: 0.5340\n",
      "Epoch 280/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5382 - val_loss: 0.5336\n",
      "Epoch 281/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5381 - val_loss: 0.5341\n",
      "Epoch 282/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5382 - val_loss: 0.5340\n",
      "Epoch 283/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5382 - val_loss: 0.5338\n",
      "Epoch 284/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5381 - val_loss: 0.5340\n",
      "Epoch 285/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5381 - val_loss: 0.5338\n",
      "Epoch 286/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5381 - val_loss: 0.5338\n",
      "Epoch 287/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5381 - val_loss: 0.5339\n",
      "Epoch 288/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5382 - val_loss: 0.5343\n",
      "Epoch 289/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5381 - val_loss: 0.5339\n",
      "Epoch 290/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5381 - val_loss: 0.5334\n",
      "Epoch 291/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5382 - val_loss: 0.5338\n",
      "Epoch 292/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5381 - val_loss: 0.5337\n",
      "Epoch 293/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5381 - val_loss: 0.5335\n",
      "Epoch 294/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5381 - val_loss: 0.5341\n",
      "Epoch 295/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5381 - val_loss: 0.5341\n",
      "Epoch 296/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5381 - val_loss: 0.5340\n",
      "Epoch 297/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5381 - val_loss: 0.5339\n",
      "Epoch 298/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5381 - val_loss: 0.5339\n",
      "Epoch 299/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5381 - val_loss: 0.5336\n",
      "Epoch 300/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5381 - val_loss: 0.5338\n",
      "Epoch 301/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5380 - val_loss: 0.5338\n",
      "Epoch 302/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5381 - val_loss: 0.5335\n",
      "Epoch 303/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5381 - val_loss: 0.5339\n",
      "Epoch 304/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5380 - val_loss: 0.5338\n",
      "Epoch 305/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5381 - val_loss: 0.5339\n",
      "Epoch 306/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5380 - val_loss: 0.5338\n",
      "Epoch 307/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5381 - val_loss: 0.5335\n",
      "Epoch 308/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5381 - val_loss: 0.5337\n",
      "Epoch 309/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5380 - val_loss: 0.5340\n",
      "Epoch 310/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5381 - val_loss: 0.5335\n",
      "Epoch 311/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5380 - val_loss: 0.5334\n",
      "Epoch 312/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5380 - val_loss: 0.5337\n",
      "Epoch 313/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5381 - val_loss: 0.5336\n",
      "Epoch 314/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5381 - val_loss: 0.5339\n",
      "Epoch 315/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5380 - val_loss: 0.5338\n",
      "Epoch 316/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5380 - val_loss: 0.5337\n",
      "Epoch 317/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5380 - val_loss: 0.5336\n",
      "Epoch 318/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5380 - val_loss: 0.5337\n",
      "Epoch 319/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5380 - val_loss: 0.5337\n",
      "Epoch 320/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5381 - val_loss: 0.5339\n",
      "Epoch 321/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5380 - val_loss: 0.5338\n",
      "Epoch 322/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5379 - val_loss: 0.5336\n",
      "Epoch 323/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5379 - val_loss: 0.5336\n",
      "Epoch 324/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5380 - val_loss: 0.5337\n",
      "Epoch 325/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5380 - val_loss: 0.5334\n",
      "Epoch 326/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5380 - val_loss: 0.5336\n",
      "Epoch 327/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5380 - val_loss: 0.5335\n",
      "Epoch 328/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5380 - val_loss: 0.5332\n",
      "Epoch 329/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5379 - val_loss: 0.5335\n",
      "Epoch 330/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5380 - val_loss: 0.5335\n",
      "Epoch 331/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5379 - val_loss: 0.5335\n",
      "Epoch 332/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5379 - val_loss: 0.5336\n",
      "Epoch 333/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5379 - val_loss: 0.5338\n",
      "Epoch 334/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5379 - val_loss: 0.5340\n",
      "Epoch 335/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5379 - val_loss: 0.5337\n",
      "Epoch 336/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5379 - val_loss: 0.5340\n",
      "Epoch 337/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5379 - val_loss: 0.5335\n",
      "Epoch 338/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5379 - val_loss: 0.5335\n",
      "Epoch 339/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5379 - val_loss: 0.5338\n",
      "Epoch 340/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5378 - val_loss: 0.5335\n",
      "Epoch 341/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5379 - val_loss: 0.5335\n",
      "Epoch 342/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5379 - val_loss: 0.5333\n",
      "Epoch 343/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5379 - val_loss: 0.5338\n",
      "Epoch 344/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5379 - val_loss: 0.5334\n",
      "Epoch 345/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5379 - val_loss: 0.5334\n",
      "Epoch 346/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5379 - val_loss: 0.5334\n",
      "Epoch 347/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5379 - val_loss: 0.5334\n",
      "Epoch 348/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5378 - val_loss: 0.5337\n",
      "Epoch 349/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5379 - val_loss: 0.5334\n",
      "Epoch 350/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5379 - val_loss: 0.5336\n",
      "Epoch 351/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5378 - val_loss: 0.5332\n",
      "Epoch 352/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5379 - val_loss: 0.5337\n",
      "Epoch 353/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5378 - val_loss: 0.5336\n",
      "Epoch 354/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5378 - val_loss: 0.5334\n",
      "Epoch 355/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5379 - val_loss: 0.5334\n",
      "Epoch 356/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5379 - val_loss: 0.5334\n",
      "Epoch 357/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5378 - val_loss: 0.5333\n",
      "Epoch 358/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5378 - val_loss: 0.5337\n",
      "Epoch 359/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5378 - val_loss: 0.5338\n",
      "Epoch 360/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5378 - val_loss: 0.5337\n",
      "Epoch 361/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5377 - val_loss: 0.5335\n",
      "Epoch 362/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5378 - val_loss: 0.5335\n",
      "Epoch 363/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5378 - val_loss: 0.5336\n",
      "Epoch 364/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5378 - val_loss: 0.5336\n",
      "Epoch 365/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5378 - val_loss: 0.5338\n",
      "Epoch 366/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5378 - val_loss: 0.5335\n",
      "Epoch 367/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5378 - val_loss: 0.5333\n",
      "Epoch 368/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5378 - val_loss: 0.5335\n",
      "Epoch 369/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5377 - val_loss: 0.5334\n",
      "Epoch 370/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5378 - val_loss: 0.5333\n",
      "Epoch 371/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5377 - val_loss: 0.5331\n",
      "Epoch 372/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5377 - val_loss: 0.5334\n",
      "Epoch 373/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5378 - val_loss: 0.5332\n",
      "Epoch 374/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5377 - val_loss: 0.5333\n",
      "Epoch 375/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5378 - val_loss: 0.5336\n",
      "Epoch 376/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5378 - val_loss: 0.5334\n",
      "Epoch 377/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5377 - val_loss: 0.5334\n",
      "Epoch 378/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5378 - val_loss: 0.5334\n",
      "Epoch 379/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5378 - val_loss: 0.5337\n",
      "Epoch 380/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5378 - val_loss: 0.5337\n",
      "Epoch 381/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5377 - val_loss: 0.5334\n",
      "Epoch 382/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5378 - val_loss: 0.5333\n",
      "Epoch 383/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5378 - val_loss: 0.5338\n",
      "Epoch 384/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5377 - val_loss: 0.5334\n",
      "Epoch 385/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5377 - val_loss: 0.5331\n",
      "Epoch 386/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5377 - val_loss: 0.5332\n",
      "Epoch 387/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5377 - val_loss: 0.5329\n",
      "Epoch 388/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5377 - val_loss: 0.5330\n",
      "Epoch 389/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5377 - val_loss: 0.5336\n",
      "Epoch 390/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5377 - val_loss: 0.5329\n",
      "Epoch 391/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5377 - val_loss: 0.5332\n",
      "Epoch 392/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5377 - val_loss: 0.5332\n",
      "Epoch 393/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5376 - val_loss: 0.5336\n",
      "Epoch 394/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5376 - val_loss: 0.5334\n",
      "Epoch 395/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5377 - val_loss: 0.5333\n",
      "Epoch 396/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5376 - val_loss: 0.5333\n",
      "Epoch 397/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5376 - val_loss: 0.5335\n",
      "Epoch 398/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5377 - val_loss: 0.5333\n",
      "Epoch 399/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5376 - val_loss: 0.5333\n",
      "Epoch 400/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5377 - val_loss: 0.5334\n",
      "Epoch 401/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5376 - val_loss: 0.5337\n",
      "Epoch 402/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5377 - val_loss: 0.5330\n",
      "Epoch 403/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5377 - val_loss: 0.5335\n",
      "Epoch 404/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5376 - val_loss: 0.5335\n",
      "Epoch 405/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5377 - val_loss: 0.5335\n",
      "Epoch 406/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5376 - val_loss: 0.5333\n",
      "Epoch 407/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5376 - val_loss: 0.5331\n",
      "Epoch 408/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5376 - val_loss: 0.5331\n",
      "Epoch 409/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5377 - val_loss: 0.5335\n",
      "Epoch 410/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5376 - val_loss: 0.5332\n",
      "Epoch 411/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5377 - val_loss: 0.5336\n",
      "Epoch 412/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5376 - val_loss: 0.5334\n",
      "Epoch 413/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5376 - val_loss: 0.5336\n",
      "Epoch 414/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5377 - val_loss: 0.5333\n",
      "Epoch 415/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5376 - val_loss: 0.5333\n",
      "Epoch 416/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5331\n",
      "Epoch 417/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5375 - val_loss: 0.5330\n",
      "Epoch 418/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5376 - val_loss: 0.5331\n",
      "Epoch 419/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5376 - val_loss: 0.5334\n",
      "Epoch 420/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5376 - val_loss: 0.5333\n",
      "Epoch 421/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5376 - val_loss: 0.5333\n",
      "Epoch 422/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5376 - val_loss: 0.5334\n",
      "Epoch 423/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5376 - val_loss: 0.5335\n",
      "Epoch 424/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5332\n",
      "Epoch 425/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5376 - val_loss: 0.5335\n",
      "Epoch 426/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5376 - val_loss: 0.5335\n",
      "Epoch 427/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5375 - val_loss: 0.5335\n",
      "Epoch 428/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5329\n",
      "Epoch 429/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5335\n",
      "Epoch 430/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5333\n",
      "Epoch 431/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5376 - val_loss: 0.5327\n",
      "Epoch 432/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5375 - val_loss: 0.5332\n",
      "Epoch 433/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5376 - val_loss: 0.5332\n",
      "Epoch 434/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5333\n",
      "Epoch 435/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5334\n",
      "Epoch 436/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5375 - val_loss: 0.5332\n",
      "Epoch 437/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5376 - val_loss: 0.5333\n",
      "Epoch 438/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5330\n",
      "Epoch 439/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5333\n",
      "Epoch 440/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5334\n",
      "Epoch 441/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5334\n",
      "Epoch 442/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5331\n",
      "Epoch 443/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5335\n",
      "Epoch 444/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5332\n",
      "Epoch 445/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5333\n",
      "Epoch 446/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5331\n",
      "Epoch 447/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5332\n",
      "Epoch 448/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5376 - val_loss: 0.5334\n",
      "Epoch 449/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5330\n",
      "Epoch 450/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5331\n",
      "Epoch 451/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5330\n",
      "Epoch 452/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5375 - val_loss: 0.5333\n",
      "Epoch 453/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5333\n",
      "Epoch 454/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5335\n",
      "Epoch 455/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5332\n",
      "Epoch 456/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5333\n",
      "Epoch 457/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5374 - val_loss: 0.5329\n",
      "Epoch 458/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5334\n",
      "Epoch 459/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5374 - val_loss: 0.5331\n",
      "Epoch 460/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5330\n",
      "Epoch 461/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5331\n",
      "Epoch 462/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5374 - val_loss: 0.5330\n",
      "Epoch 463/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5374 - val_loss: 0.5335\n",
      "Epoch 464/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5375 - val_loss: 0.5329\n",
      "Epoch 465/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5334\n",
      "Epoch 466/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5374 - val_loss: 0.5329\n",
      "Epoch 467/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5374 - val_loss: 0.5328\n",
      "Epoch 468/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5374 - val_loss: 0.5328\n",
      "Epoch 469/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5374 - val_loss: 0.5330\n",
      "Epoch 470/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5335\n",
      "Epoch 471/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5374 - val_loss: 0.5333\n",
      "Epoch 472/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5331\n",
      "Epoch 473/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5373 - val_loss: 0.5330\n",
      "Epoch 474/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5374 - val_loss: 0.5335\n",
      "Epoch 475/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5374 - val_loss: 0.5329\n",
      "Epoch 476/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5374 - val_loss: 0.5333\n",
      "Epoch 477/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5374 - val_loss: 0.5328\n",
      "Epoch 478/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5374 - val_loss: 0.5328\n",
      "Epoch 479/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5329\n",
      "Epoch 480/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5335\n",
      "Epoch 481/500\n",
      "4909/4909 [==============================] - 61s 12ms/step - loss: 0.5375 - val_loss: 0.5331\n",
      "Epoch 482/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5374 - val_loss: 0.5332\n",
      "Epoch 483/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5374 - val_loss: 0.5330\n",
      "Epoch 484/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5374 - val_loss: 0.5335\n",
      "Epoch 485/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5375 - val_loss: 0.5332\n",
      "Epoch 486/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5374 - val_loss: 0.5330\n",
      "Epoch 487/500\n",
      "4909/4909 [==============================] - 61s 13ms/step - loss: 0.5374 - val_loss: 0.5331\n",
      "Epoch 488/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5374 - val_loss: 0.5333\n",
      "Epoch 489/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5374 - val_loss: 0.5329\n",
      "Epoch 490/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5374 - val_loss: 0.5332\n",
      "Epoch 491/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5374 - val_loss: 0.5331\n",
      "Epoch 492/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5374 - val_loss: 0.5329\n",
      "Epoch 493/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5373 - val_loss: 0.5331\n",
      "Epoch 494/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5374 - val_loss: 0.5332\n",
      "Epoch 495/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5373 - val_loss: 0.5333\n",
      "Epoch 496/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5373 - val_loss: 0.5333\n",
      "Epoch 497/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5374 - val_loss: 0.5328\n",
      "Epoch 498/500\n",
      "4909/4909 [==============================] - 63s 13ms/step - loss: 0.5373 - val_loss: 0.5333\n",
      "Epoch 499/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5374 - val_loss: 0.5332\n",
      "Epoch 500/500\n",
      "4909/4909 [==============================] - 62s 13ms/step - loss: 0.5374 - val_loss: 0.5330\n"
     ]
    }
   ],
   "source": [
    "%%wandb\n",
    "\n",
    "model_version = 'patch_desc_ae_' + datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + '16_alex_3conv3mp_2020_augm_elu_lastelu_NOTdwnsmpl'\n",
    "\n",
    "os.system('mkdir ' + base_dir + '/weights_' + model_version)\n",
    "print(base_dir + '/weights_' + model_version)\n",
    "\n",
    "# checkpointer = ModelCheckpoint(base_dir + '/weights' + model_version + '/weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "history_callback = autoencoder.fit(image_datagen.flow(x_train, y_train, batch_size),\n",
    "                epochs=wandb.config.epochs,\n",
    "                validation_data=image_datagen.flow(x_validation, y_validation, batch_size),\n",
    "                callbacks=[WandbCallback(data_type=\"image\", predictions=1)]\n",
    "                )\n",
    "autoencoder.save(base_dir + '/' + model_version + '.h5')\n",
    "\n",
    "# autoencoder = load_model(base_dir + '/' + model_version + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.5291429358871114,\n",
       "  0.6308274780148398,\n",
       "  0.5840441379424121,\n",
       "  0.5706511503395567,\n",
       "  0.5636718482659019,\n",
       "  0.559548435167713,\n",
       "  0.5567262296563229,\n",
       "  0.5548753325641363,\n",
       "  0.5533573101219591,\n",
       "  0.5522047847593999,\n",
       "  0.5512200325343091,\n",
       "  0.5502675929620829,\n",
       "  0.5495285349742886,\n",
       "  0.5489167038349827,\n",
       "  0.548334599493653,\n",
       "  0.5477810769352309,\n",
       "  0.5473285980977296,\n",
       "  0.5468734297492783,\n",
       "  0.5465041179101665,\n",
       "  0.5461977574995974,\n",
       "  0.5460171572077762,\n",
       "  0.5457139786052013,\n",
       "  0.5454406912064574,\n",
       "  0.5451295342592657,\n",
       "  0.5449587966416131,\n",
       "  0.5447574737818941,\n",
       "  0.5445564555871093,\n",
       "  0.5444325020143183,\n",
       "  0.5441963948065537,\n",
       "  0.5440349807477354,\n",
       "  0.5438828718532798,\n",
       "  0.5437657664377765,\n",
       "  0.5435908468670898,\n",
       "  0.5434498372950106,\n",
       "  0.5433477397269671,\n",
       "  0.5431608531140341,\n",
       "  0.5431519673798988,\n",
       "  0.5430352534959489,\n",
       "  0.5429075125000089,\n",
       "  0.5428954223152023,\n",
       "  0.5426708376741682,\n",
       "  0.5426371612107525,\n",
       "  0.5425533007903376,\n",
       "  0.5424921928477121,\n",
       "  0.5423337172554599,\n",
       "  0.5423324030862293,\n",
       "  0.5422422601869077,\n",
       "  0.5422277573446823,\n",
       "  0.5421069368924762,\n",
       "  0.5420435097506754,\n",
       "  0.5419486801108837,\n",
       "  0.5418748861525255,\n",
       "  0.5418095608088622,\n",
       "  0.5417647414307752,\n",
       "  0.5417076693774378,\n",
       "  0.5416180623393766,\n",
       "  0.541546016563098,\n",
       "  0.5415761729276504,\n",
       "  0.5414728544619356,\n",
       "  0.5414686133785562,\n",
       "  0.5414303238808076,\n",
       "  0.5413200811027651,\n",
       "  0.5412555851813766,\n",
       "  0.5412402025842169,\n",
       "  0.5412076144096538,\n",
       "  0.5411208563518887,\n",
       "  0.5411429652106143,\n",
       "  0.5410748949737598,\n",
       "  0.5410345644197027,\n",
       "  0.5410077834274127,\n",
       "  0.5409144083881965,\n",
       "  0.540930292634827,\n",
       "  0.5408311195828741,\n",
       "  0.5408319599679172,\n",
       "  0.5408699445829334,\n",
       "  0.5408117862297656,\n",
       "  0.5407573628209773,\n",
       "  0.5406836842494344,\n",
       "  0.540666488819763,\n",
       "  0.5405912400627619,\n",
       "  0.5405924643761483,\n",
       "  0.5405611062505801,\n",
       "  0.540538511155978,\n",
       "  0.5405464382724581,\n",
       "  0.5404294064765797,\n",
       "  0.5404607613845003,\n",
       "  0.5404395773459881,\n",
       "  0.5403676101379853,\n",
       "  0.5403840784400141,\n",
       "  0.5403194988233624,\n",
       "  0.5403327324645,\n",
       "  0.5403102310641529,\n",
       "  0.5402597330397069,\n",
       "  0.5402077144491159,\n",
       "  0.5402153873547418,\n",
       "  0.5401606566317723,\n",
       "  0.5401507505110137,\n",
       "  0.5400811385208671,\n",
       "  0.5400061126322526,\n",
       "  0.540105490436629,\n",
       "  0.5400791101120386,\n",
       "  0.5400246562957217,\n",
       "  0.5399798572639435,\n",
       "  0.5400007369031292,\n",
       "  0.5399605997691533,\n",
       "  0.5398925650136932,\n",
       "  0.5399092922589465,\n",
       "  0.5398386495690091,\n",
       "  0.5398641544066015,\n",
       "  0.5398160055358086,\n",
       "  0.5398661223266912,\n",
       "  0.5398120493569094,\n",
       "  0.5397350313536203,\n",
       "  0.5397758576743171,\n",
       "  0.5397464287257815,\n",
       "  0.5398144049306799,\n",
       "  0.5397581198524712,\n",
       "  0.5397280485324693,\n",
       "  0.5396781052251539,\n",
       "  0.5396714943375023,\n",
       "  0.5397002104587139,\n",
       "  0.5395905927360334,\n",
       "  0.5396028650305863,\n",
       "  0.5396365514504965,\n",
       "  0.5395862626095694,\n",
       "  0.539575229671664,\n",
       "  0.5396027699976687,\n",
       "  0.5396080759842808,\n",
       "  0.5395056748676144,\n",
       "  0.5395229411857047,\n",
       "  0.5394987545993535,\n",
       "  0.5395030716131447,\n",
       "  0.5394419319675839,\n",
       "  0.5395122883362139,\n",
       "  0.5394402398355592,\n",
       "  0.5393993140106288,\n",
       "  0.5394255074149379,\n",
       "  0.5393880366787299,\n",
       "  0.539411155744474,\n",
       "  0.539410163236035,\n",
       "  0.5393569015725651,\n",
       "  0.5393338116986253,\n",
       "  0.5393427179574058,\n",
       "  0.5393152164192322,\n",
       "  0.5393053509933678,\n",
       "  0.5392952520095453,\n",
       "  0.5393283407043671,\n",
       "  0.5392921669859619,\n",
       "  0.539261856668356,\n",
       "  0.5392487982569666,\n",
       "  0.5392685611493316,\n",
       "  0.5392211094850944,\n",
       "  0.5392266936456875,\n",
       "  0.5392583332167646,\n",
       "  0.5392433746562288,\n",
       "  0.53918668879573,\n",
       "  0.5391524699044725,\n",
       "  0.5391581387294176,\n",
       "  0.5391172568580085,\n",
       "  0.5391396257633689,\n",
       "  0.5391392844794805,\n",
       "  0.5390920169033876,\n",
       "  0.539085859701768,\n",
       "  0.5390920545035726,\n",
       "  0.5390240946692151,\n",
       "  0.5390374174323607,\n",
       "  0.5390427510353439,\n",
       "  0.5390371297010558,\n",
       "  0.5389855295791923,\n",
       "  0.539009073373658,\n",
       "  0.5389346121267956,\n",
       "  0.5389752975335004,\n",
       "  0.5390069742403285,\n",
       "  0.538974173092404,\n",
       "  0.5389574458676405,\n",
       "  0.5389792631741048,\n",
       "  0.5388885955796705,\n",
       "  0.5389643051918349,\n",
       "  0.5389735785151464,\n",
       "  0.5388902169712578,\n",
       "  0.5389140849938032,\n",
       "  0.5388900157385158,\n",
       "  0.5389852130765024,\n",
       "  0.5389254726803898,\n",
       "  0.5388775770870297,\n",
       "  0.538841173222587,\n",
       "  0.5388421893291319,\n",
       "  0.5388124841971553,\n",
       "  0.5388598635128903,\n",
       "  0.5388214154382375,\n",
       "  0.5387713737164389,\n",
       "  0.5388500101881128,\n",
       "  0.5387601974634478,\n",
       "  0.5388176945498174,\n",
       "  0.5387979477707333,\n",
       "  0.5387967852627413,\n",
       "  0.5387760233803505,\n",
       "  0.5387887025638942,\n",
       "  0.5387359557392146,\n",
       "  0.5387148846257138,\n",
       "  0.5387311875459693,\n",
       "  0.5387376048238198,\n",
       "  0.5387181515700828,\n",
       "  0.538705960572735,\n",
       "  0.5386582623395566,\n",
       "  0.5386354410314287,\n",
       "  0.5387283950953397,\n",
       "  0.5387119268608511,\n",
       "  0.538602004218253,\n",
       "  0.5386667573336494,\n",
       "  0.5386702540992556,\n",
       "  0.5386365539345265,\n",
       "  0.5386110974124926,\n",
       "  0.5386222254743812,\n",
       "  0.5385751460502306,\n",
       "  0.5385836846153695,\n",
       "  0.5386135987760536,\n",
       "  0.5385375995710538,\n",
       "  0.5385952304500936,\n",
       "  0.5385623605644139,\n",
       "  0.5385832451932299,\n",
       "  0.5385876024443111,\n",
       "  0.5385613606386901,\n",
       "  0.5385010450417811,\n",
       "  0.5385607669424911,\n",
       "  0.5385397280783185,\n",
       "  0.538524758960256,\n",
       "  0.5385014959366556,\n",
       "  0.5385199051662017,\n",
       "  0.5385674124638692,\n",
       "  0.5385584440172191,\n",
       "  0.5384915140463676,\n",
       "  0.5384930336494952,\n",
       "  0.5384808431347944,\n",
       "  0.5384542036256559,\n",
       "  0.5384698423255554,\n",
       "  0.5384987116447357,\n",
       "  0.5385070687041962,\n",
       "  0.5384260433720357,\n",
       "  0.538482912403194,\n",
       "  0.5384646714421977,\n",
       "  0.5383847701352676,\n",
       "  0.5384138193998712,\n",
       "  0.538427744517268,\n",
       "  0.5384511769545667,\n",
       "  0.5383685597542531,\n",
       "  0.5383574809679053,\n",
       "  0.538378277041596,\n",
       "  0.5383791410604123,\n",
       "  0.5383565511831043,\n",
       "  0.5383987711383025,\n",
       "  0.5383161638451562,\n",
       "  0.538317960892223,\n",
       "  0.5382982635563918,\n",
       "  0.5383659493018148,\n",
       "  0.538303793758401,\n",
       "  0.538301346106788,\n",
       "  0.5383250202615134,\n",
       "  0.538317844096169,\n",
       "  0.5383099660010051,\n",
       "  0.5383330696948933,\n",
       "  0.5383094473207686,\n",
       "  0.5382946829634773,\n",
       "  0.5383583929858275,\n",
       "  0.5382773536546235,\n",
       "  0.5382840117961618,\n",
       "  0.5382011646319418,\n",
       "  0.5383041099453971,\n",
       "  0.5382708566003616,\n",
       "  0.5382726747199843,\n",
       "  0.538198378304708,\n",
       "  0.5382439477498365,\n",
       "  0.5381818115358333,\n",
       "  0.5382792204965641,\n",
       "  0.5382237950645101,\n",
       "  0.5382511397082148,\n",
       "  0.5382291768935041,\n",
       "  0.5381069068030334,\n",
       "  0.5382100557192105,\n",
       "  0.5381939281728902,\n",
       "  0.5381286602612008,\n",
       "  0.5382112517233691,\n",
       "  0.5382031296386943,\n",
       "  0.538132392362819,\n",
       "  0.5381480556534384,\n",
       "  0.5381122966844941,\n",
       "  0.5381088328003624,\n",
       "  0.5381928493730626,\n",
       "  0.5381403736154607,\n",
       "  0.5381145297820004,\n",
       "  0.5381558028662337,\n",
       "  0.5381356761884546,\n",
       "  0.5381199450115423,\n",
       "  0.5381082350138048,\n",
       "  0.5380914561898126,\n",
       "  0.5381404640768904,\n",
       "  0.5381284468150577,\n",
       "  0.5381249872375652,\n",
       "  0.5381115231885767,\n",
       "  0.5380719461013397,\n",
       "  0.5380470529931913,\n",
       "  0.5380843654446636,\n",
       "  0.5380997097821724,\n",
       "  0.5380329603122436,\n",
       "  0.5380629354314128,\n",
       "  0.5379986127590979,\n",
       "  0.5380913817316262,\n",
       "  0.5380575794194873,\n",
       "  0.5380056698790707,\n",
       "  0.5380523125113568,\n",
       "  0.538009638817005,\n",
       "  0.5379918799825545,\n",
       "  0.5381172391839317,\n",
       "  0.5380633678217783,\n",
       "  0.5380387703008518,\n",
       "  0.5379943820412488,\n",
       "  0.538013393594691,\n",
       "  0.5380110897871025,\n",
       "  0.5380186466107799,\n",
       "  0.5380564457845702,\n",
       "  0.5379983536337425,\n",
       "  0.5379194909197054,\n",
       "  0.5379436965486109,\n",
       "  0.5379669561997522,\n",
       "  0.5379710234482032,\n",
       "  0.5379640280129631,\n",
       "  0.5379734837131465,\n",
       "  0.5379759611735322,\n",
       "  0.5379413853298086,\n",
       "  0.5379690244360762,\n",
       "  0.5379492634272491,\n",
       "  0.5379468412231306,\n",
       "  0.5379453152909511,\n",
       "  0.5379429249385081,\n",
       "  0.5379377403452397,\n",
       "  0.5379285474395924,\n",
       "  0.5379427636015606,\n",
       "  0.5378842695346772,\n",
       "  0.5378935528729167,\n",
       "  0.5378456713810489,\n",
       "  0.5379262554598944,\n",
       "  0.5378945729301865,\n",
       "  0.5378931544294921,\n",
       "  0.5379406392468826,\n",
       "  0.5379271023993766,\n",
       "  0.537851571051718,\n",
       "  0.5379002336396779,\n",
       "  0.5378480839967293,\n",
       "  0.5378876501454825,\n",
       "  0.5378783247896223,\n",
       "  0.5378280123877743,\n",
       "  0.537850677348585,\n",
       "  0.5378339430616922,\n",
       "  0.5378269375455014,\n",
       "  0.5378766038050125,\n",
       "  0.5378543612970448,\n",
       "  0.5377860643245556,\n",
       "  0.5378109673937516,\n",
       "  0.5378058301993157,\n",
       "  0.537783556666092,\n",
       "  0.5377230419711679,\n",
       "  0.5377939887439792,\n",
       "  0.5378274853500018,\n",
       "  0.5377896799799632,\n",
       "  0.537796353891769,\n",
       "  0.5377772915404747,\n",
       "  0.5377755101938586,\n",
       "  0.5378020092390204,\n",
       "  0.5376977966482359,\n",
       "  0.5377712386551414,\n",
       "  0.537741390159511,\n",
       "  0.5377188487282888,\n",
       "  0.537752954863765,\n",
       "  0.5377149871527817,\n",
       "  0.537757903922195,\n",
       "  0.5377568434955903,\n",
       "  0.5377469912294492,\n",
       "  0.5377551358596646,\n",
       "  0.5377525626006521,\n",
       "  0.5377957632933147,\n",
       "  0.5377405430993669,\n",
       "  0.5377718732860405,\n",
       "  0.5377914655634015,\n",
       "  0.5376554677217867,\n",
       "  0.5377088096526628,\n",
       "  0.5377443641583164,\n",
       "  0.5377060418299381,\n",
       "  0.5376892499456358,\n",
       "  0.5376711688455671,\n",
       "  0.5377304523729084,\n",
       "  0.5376798435361707,\n",
       "  0.5376685145686169,\n",
       "  0.5376405752846676,\n",
       "  0.5376362598523805,\n",
       "  0.5376967917192219,\n",
       "  0.5376330475245438,\n",
       "  0.5376375523055253,\n",
       "  0.5376679016811231,\n",
       "  0.5375949405243288,\n",
       "  0.5376562382929839,\n",
       "  0.5376460291707543,\n",
       "  0.5376819365445866,\n",
       "  0.5376642025937833,\n",
       "  0.53761462555797,\n",
       "  0.5376513266488134,\n",
       "  0.5376089241300591,\n",
       "  0.5376452437778886,\n",
       "  0.5375988981321974,\n",
       "  0.5376620609897824,\n",
       "  0.5376105186542892,\n",
       "  0.5376535523093041,\n",
       "  0.5376478535458179,\n",
       "  0.5376131818822188,\n",
       "  0.5376738033180481,\n",
       "  0.5375720051346577,\n",
       "  0.5375359330438301,\n",
       "  0.5375495436080975,\n",
       "  0.5376351340331598,\n",
       "  0.5376119825435453,\n",
       "  0.5375611225648607,\n",
       "  0.5376370401000456,\n",
       "  0.5376405943340519,\n",
       "  0.5375612773617878,\n",
       "  0.5375369255181195,\n",
       "  0.5375638196881275,\n",
       "  0.5375753170152965,\n",
       "  0.5375437874741067,\n",
       "  0.5374988206738801,\n",
       "  0.5375445270268776,\n",
       "  0.5375275501164563,\n",
       "  0.5375856804389051,\n",
       "  0.5375233795951777,\n",
       "  0.5375809249690274,\n",
       "  0.5375341879261045,\n",
       "  0.5375290486644818,\n",
       "  0.537529250430716,\n",
       "  0.5375529760237876,\n",
       "  0.537530040266819,\n",
       "  0.5375267071595717,\n",
       "  0.5375103691464681,\n",
       "  0.5375151783540958,\n",
       "  0.5375092162504393,\n",
       "  0.5374962898802269,\n",
       "  0.537531440566556,\n",
       "  0.5374956864620271,\n",
       "  0.5374776875295979,\n",
       "  0.5375048040390537,\n",
       "  0.5375604661822087,\n",
       "  0.5374667556235498,\n",
       "  0.5374560625906496,\n",
       "  0.5374987258967047,\n",
       "  0.537452835787193,\n",
       "  0.5374599801031386,\n",
       "  0.5375156829927915,\n",
       "  0.5374706415309991,\n",
       "  0.5374898663712196,\n",
       "  0.5374267960634999,\n",
       "  0.5374535210414022,\n",
       "  0.5374488996859593,\n",
       "  0.537467543148866,\n",
       "  0.5375061220785677,\n",
       "  0.5374067713236798,\n",
       "  0.5374462287007671,\n",
       "  0.5374935169229259,\n",
       "  0.5374595580122808,\n",
       "  0.5374493548905086,\n",
       "  0.5374370383859332,\n",
       "  0.5374437246818878,\n",
       "  0.5374376936477208,\n",
       "  0.5374639183170917,\n",
       "  0.5374479827125562,\n",
       "  0.5374547164543939,\n",
       "  0.5373387097699204,\n",
       "  0.5373992589574194,\n",
       "  0.5374422695660335,\n",
       "  0.5373822906557231,\n",
       "  0.5373866239300177,\n",
       "  0.5374062654100671,\n",
       "  0.5374556314835487,\n",
       "  0.5374733200548968,\n",
       "  0.5374518734267459,\n",
       "  0.5373846301845119,\n",
       "  0.5374198622029546,\n",
       "  0.5373759842182428,\n",
       "  0.5374682779222161,\n",
       "  0.537426163207619,\n",
       "  0.5374156176522564,\n",
       "  0.5373722010850375,\n",
       "  0.5373862642675941,\n",
       "  0.5373645809822225,\n",
       "  0.5373827525513097,\n",
       "  0.5373530798462391,\n",
       "  0.537334246593729,\n",
       "  0.5373660229914751,\n",
       "  0.5373402057544522,\n",
       "  0.5373327380656838,\n",
       "  0.5373821972346646,\n",
       "  0.5373428076603936,\n",
       "  0.5374226854094383,\n",
       "  0.5373862953209287],\n",
       " 'val_loss': [0.6965247542877507,\n",
       "  0.5928637424135595,\n",
       "  0.5730649698071364,\n",
       "  0.5626084247255713,\n",
       "  0.5575370463898511,\n",
       "  0.5538861739441632,\n",
       "  0.5518344415397178,\n",
       "  0.5499113727875842,\n",
       "  0.5486536311909436,\n",
       "  0.5474035105084986,\n",
       "  0.5464833054116102,\n",
       "  0.5459841768431469,\n",
       "  0.5454107658649848,\n",
       "  0.5446193523523284,\n",
       "  0.5443252504356508,\n",
       "  0.5433557748309965,\n",
       "  0.543246680401205,\n",
       "  0.5424180748016854,\n",
       "  0.5422102772608036,\n",
       "  0.5424893762522597,\n",
       "  0.5415958355112773,\n",
       "  0.5415994541916421,\n",
       "  0.5413397802570001,\n",
       "  0.5408132025381414,\n",
       "  0.5407945794787833,\n",
       "  0.5409377149450101,\n",
       "  0.5400013785536696,\n",
       "  0.5401735254904119,\n",
       "  0.5402396221955618,\n",
       "  0.5395690011299723,\n",
       "  0.5398496030791988,\n",
       "  0.5395551493497399,\n",
       "  0.539366485626717,\n",
       "  0.5391103191588952,\n",
       "  0.5390827345654248,\n",
       "  0.5390299316344223,\n",
       "  0.5387936794176335,\n",
       "  0.5389675728189267,\n",
       "  0.5388421472010574,\n",
       "  0.5384909796520947,\n",
       "  0.5389509072633294,\n",
       "  0.5384826090762286,\n",
       "  0.5383423096765347,\n",
       "  0.5379808150171265,\n",
       "  0.5381992059509929,\n",
       "  0.5381460170435711,\n",
       "  0.5380324345778643,\n",
       "  0.5379853529658744,\n",
       "  0.5376665638229712,\n",
       "  0.5377069648688402,\n",
       "  0.5372664007714124,\n",
       "  0.5378451320698591,\n",
       "  0.5376289651645878,\n",
       "  0.5375139880471114,\n",
       "  0.5377690859926425,\n",
       "  0.537042402881917,\n",
       "  0.5372288815858888,\n",
       "  0.5372793257721071,\n",
       "  0.5373714600152116,\n",
       "  0.5371846341020693,\n",
       "  0.537260917870979,\n",
       "  0.5369209206201196,\n",
       "  0.5369302589234298,\n",
       "  0.5368400775804753,\n",
       "  0.5371228252969137,\n",
       "  0.5369474478368836,\n",
       "  0.5371811418998532,\n",
       "  0.5365620873323301,\n",
       "  0.5368118889448119,\n",
       "  0.536838022431707,\n",
       "  0.5366269999403295,\n",
       "  0.5363555143519145,\n",
       "  0.5366607046708828,\n",
       "  0.5364479742399076,\n",
       "  0.5365159116624817,\n",
       "  0.5363174931305211,\n",
       "  0.5364033390836018,\n",
       "  0.5363401249656833,\n",
       "  0.5364294846852621,\n",
       "  0.535961606395923,\n",
       "  0.5360815161611976,\n",
       "  0.5361656229185864,\n",
       "  0.5362835066105293,\n",
       "  0.536255477405176,\n",
       "  0.5362344161281741,\n",
       "  0.5360093254868578,\n",
       "  0.5358521373775916,\n",
       "  0.5362445135426716,\n",
       "  0.5362733498336824,\n",
       "  0.536072706788536,\n",
       "  0.5363012091900276,\n",
       "  0.535927749746214,\n",
       "  0.535761921628704,\n",
       "  0.5361321612102229,\n",
       "  0.5359691698861316,\n",
       "  0.5359105986308276,\n",
       "  0.5359554159932021,\n",
       "  0.5360186737242753,\n",
       "  0.5359310444777574,\n",
       "  0.5357692026025881,\n",
       "  0.5359026826009518,\n",
       "  0.5357834192795482,\n",
       "  0.5358951673275087,\n",
       "  0.5354702465417909,\n",
       "  0.5356944971452884,\n",
       "  0.5358145840284301,\n",
       "  0.5353366621141511,\n",
       "  0.5356221935613369,\n",
       "  0.5356902601273079,\n",
       "  0.5354826775023608,\n",
       "  0.5353742338777557,\n",
       "  0.5352549620760165,\n",
       "  0.5358373408879691,\n",
       "  0.5356650294327154,\n",
       "  0.5357619189634556,\n",
       "  0.5352528291504558,\n",
       "  0.5353932952493187,\n",
       "  0.5353594608907777,\n",
       "  0.5353517195558161,\n",
       "  0.535566484055868,\n",
       "  0.5356198966018553,\n",
       "  0.5356178690747517,\n",
       "  0.5353353893369194,\n",
       "  0.535416164776174,\n",
       "  0.5350708702230841,\n",
       "  0.5354585228412132,\n",
       "  0.5353090399649085,\n",
       "  0.5350289887529078,\n",
       "  0.5350755416765446,\n",
       "  0.5352656128929882,\n",
       "  0.5349734929518971,\n",
       "  0.5351329021822147,\n",
       "  0.5350531126425518,\n",
       "  0.5351407065139553,\n",
       "  0.5354019594870931,\n",
       "  0.5354817240703397,\n",
       "  0.5349466124685799,\n",
       "  0.5348490244004784,\n",
       "  0.5351409757040381,\n",
       "  0.5349618298251454,\n",
       "  0.5348457306381164,\n",
       "  0.5350802024690117,\n",
       "  0.5350571974990813,\n",
       "  0.5346281630236928,\n",
       "  0.5345232784748077,\n",
       "  0.5349922764107464,\n",
       "  0.5347475857754064,\n",
       "  0.5350690028531765,\n",
       "  0.5348607827492846,\n",
       "  0.5352010547630186,\n",
       "  0.5349331805861093,\n",
       "  0.5349024454268013,\n",
       "  0.5349825087601576,\n",
       "  0.5348103981677109,\n",
       "  0.5346944598647637,\n",
       "  0.5349664438546189,\n",
       "  0.5347901190199503,\n",
       "  0.534910743071781,\n",
       "  0.5346604227050533,\n",
       "  0.5347173276955519,\n",
       "  0.5347746528261076,\n",
       "  0.5349047734000818,\n",
       "  0.5350544813687239,\n",
       "  0.5348318764349309,\n",
       "  0.5348088099219934,\n",
       "  0.5348448864812774,\n",
       "  0.5350547968372097,\n",
       "  0.5346395295809924,\n",
       "  0.534861150553556,\n",
       "  0.5348809153083863,\n",
       "  0.5345692540087351,\n",
       "  0.5343665979742035,\n",
       "  0.5351587228658723,\n",
       "  0.534663649109321,\n",
       "  0.5345689186720344,\n",
       "  0.5346980867831688,\n",
       "  0.5347875322752852,\n",
       "  0.534819778630404,\n",
       "  0.5345369194581256,\n",
       "  0.5346105806226653,\n",
       "  0.5348911086718241,\n",
       "  0.5350025351939163,\n",
       "  0.5344579178627914,\n",
       "  0.534231319902389,\n",
       "  0.5344473600872164,\n",
       "  0.5345276911568836,\n",
       "  0.5347567583487286,\n",
       "  0.5347818943058572,\n",
       "  0.5346262942000133,\n",
       "  0.5342803810670124,\n",
       "  0.5340737937911739,\n",
       "  0.5347474440326535,\n",
       "  0.5343959154636879,\n",
       "  0.5346595683718115,\n",
       "  0.5345055158060741,\n",
       "  0.5343544354768304,\n",
       "  0.5340975612644258,\n",
       "  0.5345955992617258,\n",
       "  0.5347182447832775,\n",
       "  0.5346365859353446,\n",
       "  0.5344399955214524,\n",
       "  0.5342777836613539,\n",
       "  0.5343824205844383,\n",
       "  0.534630507473054,\n",
       "  0.5343295750094623,\n",
       "  0.5346242315400906,\n",
       "  0.5345262700949258,\n",
       "  0.5345051654470645,\n",
       "  0.5343739547865177,\n",
       "  0.5343526085702385,\n",
       "  0.5345076967061051,\n",
       "  0.5344361960887909,\n",
       "  0.5347589012083969,\n",
       "  0.5342828100774346,\n",
       "  0.5343855052459531,\n",
       "  0.5342256128787994,\n",
       "  0.5342585970231188,\n",
       "  0.5342470264531732,\n",
       "  0.5340430305256108,\n",
       "  0.5340116850244321,\n",
       "  0.5341814649783498,\n",
       "  0.5342195322358512,\n",
       "  0.5341183281526333,\n",
       "  0.5339942271631908,\n",
       "  0.5343734418473592,\n",
       "  0.5343452558769444,\n",
       "  0.5342235228395075,\n",
       "  0.5341595755359991,\n",
       "  0.5345643424406284,\n",
       "  0.5345185966026492,\n",
       "  0.5343922994485716,\n",
       "  0.5338485631031719,\n",
       "  0.5338638197115766,\n",
       "  0.5340153875389719,\n",
       "  0.5343095970347644,\n",
       "  0.5343829085671805,\n",
       "  0.5338854070116834,\n",
       "  0.5339786172882328,\n",
       "  0.5338687213455758,\n",
       "  0.5341841682670562,\n",
       "  0.534153003275879,\n",
       "  0.5337501144021507,\n",
       "  0.5338603800874415,\n",
       "  0.534004229597929,\n",
       "  0.5341412364467373,\n",
       "  0.534112791947233,\n",
       "  0.5342509366147886,\n",
       "  0.5336513429637847,\n",
       "  0.5338559114351505,\n",
       "  0.5339029906241874,\n",
       "  0.5342478131860252,\n",
       "  0.5340975140168415,\n",
       "  0.534317738399273,\n",
       "  0.5338713393463352,\n",
       "  0.533655253852286,\n",
       "  0.5340063596159462,\n",
       "  0.5340094760181459,\n",
       "  0.533870526930181,\n",
       "  0.5338324473156193,\n",
       "  0.53372692577238,\n",
       "  0.533912864157824,\n",
       "  0.5341651916988497,\n",
       "  0.5336411423314877,\n",
       "  0.5341451672034535,\n",
       "  0.5340281594090346,\n",
       "  0.5338542943562918,\n",
       "  0.5339308727562913,\n",
       "  0.5339996572432479,\n",
       "  0.5341002592226354,\n",
       "  0.5341193356165072,\n",
       "  0.533707307848504,\n",
       "  0.5340409026882513,\n",
       "  0.5337869256007962,\n",
       "  0.5341093479617824,\n",
       "  0.5340681752053703,\n",
       "  0.5337998314601619,\n",
       "  0.5338750476759624,\n",
       "  0.5341582022062162,\n",
       "  0.5340220731932942,\n",
       "  0.5336471093379385,\n",
       "  0.5341474101310824,\n",
       "  0.533965025006271,\n",
       "  0.5338012779631266,\n",
       "  0.533998620219347,\n",
       "  0.5338346759478251,\n",
       "  0.5337597708391949,\n",
       "  0.5339131881066455,\n",
       "  0.5342624563027204,\n",
       "  0.5338885745381922,\n",
       "  0.5334442221536869,\n",
       "  0.5337503116305281,\n",
       "  0.5336854150140189,\n",
       "  0.5335415521772896,\n",
       "  0.5340973330222494,\n",
       "  0.5340513398007649,\n",
       "  0.5340076580764802,\n",
       "  0.5338715760688472,\n",
       "  0.5338978835237704,\n",
       "  0.5336445955241599,\n",
       "  0.5337637767074553,\n",
       "  0.5337659467041977,\n",
       "  0.5335118252087415,\n",
       "  0.5338820427413878,\n",
       "  0.5338094244158365,\n",
       "  0.5338896801316642,\n",
       "  0.5337827690248567,\n",
       "  0.5334651114010229,\n",
       "  0.5336921452506771,\n",
       "  0.5339536928549046,\n",
       "  0.5335165179841886,\n",
       "  0.5334220133661255,\n",
       "  0.5337331588190746,\n",
       "  0.5335955573775903,\n",
       "  0.5338760258221045,\n",
       "  0.5338276830630574,\n",
       "  0.5337484248769961,\n",
       "  0.5335985332485137,\n",
       "  0.5336836893868641,\n",
       "  0.5336561416222797,\n",
       "  0.5338795832017573,\n",
       "  0.5337948823362831,\n",
       "  0.533624079411592,\n",
       "  0.5336443159153791,\n",
       "  0.5336701971728627,\n",
       "  0.5334322450122213,\n",
       "  0.5336316024384847,\n",
       "  0.5335358703524117,\n",
       "  0.5331572689176575,\n",
       "  0.5335030155937847,\n",
       "  0.5335081033105773,\n",
       "  0.5335015593990078,\n",
       "  0.5335976898185606,\n",
       "  0.5338223838224644,\n",
       "  0.5339912161594484,\n",
       "  0.5336704525521131,\n",
       "  0.5340156400106787,\n",
       "  0.5335176810016476,\n",
       "  0.533533315106136,\n",
       "  0.5337761029964541,\n",
       "  0.5335049651018003,\n",
       "  0.5334511375039573,\n",
       "  0.5332973124535103,\n",
       "  0.5338199191946325,\n",
       "  0.5333768233535735,\n",
       "  0.5333790670080882,\n",
       "  0.5334097750303222,\n",
       "  0.5333951292483787,\n",
       "  0.5336535752304201,\n",
       "  0.5334356800327457,\n",
       "  0.5336008587988411,\n",
       "  0.5332218217171305,\n",
       "  0.5336629334019451,\n",
       "  0.5335653421840048,\n",
       "  0.5334004866398447,\n",
       "  0.5333937047942867,\n",
       "  0.5333693713192048,\n",
       "  0.5332575144806528,\n",
       "  0.533651379065785,\n",
       "  0.5338081225631682,\n",
       "  0.5336697782442822,\n",
       "  0.5334821072051196,\n",
       "  0.5335416701751027,\n",
       "  0.533555607243282,\n",
       "  0.533610474287979,\n",
       "  0.5338022391485974,\n",
       "  0.5334671803606235,\n",
       "  0.5332953963822465,\n",
       "  0.5335295866659986,\n",
       "  0.5334094731303735,\n",
       "  0.5333274452666926,\n",
       "  0.5331076206715126,\n",
       "  0.5334375062124516,\n",
       "  0.5332063555232878,\n",
       "  0.5333407022119537,\n",
       "  0.5335781574249268,\n",
       "  0.5334319784873869,\n",
       "  0.5334247096282679,\n",
       "  0.5333708459284248,\n",
       "  0.5336965816776927,\n",
       "  0.5337020277492399,\n",
       "  0.5334272188384358,\n",
       "  0.5333030153580798,\n",
       "  0.5337597301335839,\n",
       "  0.5334146865984288,\n",
       "  0.5331461928724274,\n",
       "  0.5332142335128008,\n",
       "  0.5329269965489706,\n",
       "  0.5330069758058563,\n",
       "  0.5335729849047777,\n",
       "  0.5329302307066879,\n",
       "  0.5331869178671178,\n",
       "  0.5331804919533614,\n",
       "  0.5335973033575507,\n",
       "  0.5334448448526181,\n",
       "  0.5332763386451131,\n",
       "  0.5333363971089929,\n",
       "  0.5335312669839316,\n",
       "  0.5332792963438887,\n",
       "  0.5332837637847032,\n",
       "  0.5333796250141734,\n",
       "  0.5337232363417865,\n",
       "  0.5329947117867508,\n",
       "  0.5335415124408598,\n",
       "  0.5334886557202998,\n",
       "  0.533508326222257,\n",
       "  0.5332871866904623,\n",
       "  0.5331160976150171,\n",
       "  0.5331330272724958,\n",
       "  0.5335269146333865,\n",
       "  0.5331824472764644,\n",
       "  0.533554900225585,\n",
       "  0.5333989344961275,\n",
       "  0.5335709634350567,\n",
       "  0.5332871593110929,\n",
       "  0.5332679833338513,\n",
       "  0.5330866914454514,\n",
       "  0.5330082691781889,\n",
       "  0.5331334990214526,\n",
       "  0.5333804490605021,\n",
       "  0.5332601031636804,\n",
       "  0.5332896537412473,\n",
       "  0.5334215895916389,\n",
       "  0.533471623087317,\n",
       "  0.533156640403639,\n",
       "  0.5335312657724551,\n",
       "  0.5334795480821191,\n",
       "  0.5334768842875472,\n",
       "  0.5328673783356581,\n",
       "  0.5334771764956838,\n",
       "  0.533322244397993,\n",
       "  0.5326512996258774,\n",
       "  0.5332057807988267,\n",
       "  0.533186250828146,\n",
       "  0.5332634950556406,\n",
       "  0.5333689097466507,\n",
       "  0.533246383676684,\n",
       "  0.5333292527896601,\n",
       "  0.5329983835297871,\n",
       "  0.5333014164513689,\n",
       "  0.5333665573015446,\n",
       "  0.5334121587315226,\n",
       "  0.5331446673811936,\n",
       "  0.5334907346140079,\n",
       "  0.5331912103707228,\n",
       "  0.5332888044962069,\n",
       "  0.5331293482606004,\n",
       "  0.5332392599524521,\n",
       "  0.533366160664132,\n",
       "  0.5330182655555445,\n",
       "  0.5331448563715306,\n",
       "  0.5329846017728976,\n",
       "  0.5332800237143912,\n",
       "  0.53330965158416,\n",
       "  0.5335286625517093,\n",
       "  0.5332283137775049,\n",
       "  0.5333328002352056,\n",
       "  0.5328600522948475,\n",
       "  0.5333550977028483,\n",
       "  0.5331482315451149,\n",
       "  0.5330187045946354,\n",
       "  0.533124357219634,\n",
       "  0.5330061127499837,\n",
       "  0.533532946817274,\n",
       "  0.5329420641670383,\n",
       "  0.5333918909716412,\n",
       "  0.5328884706264589,\n",
       "  0.5328115413828594,\n",
       "  0.5327501638633448,\n",
       "  0.5330059346629352,\n",
       "  0.5335027476151785,\n",
       "  0.5332516555379077,\n",
       "  0.5330702662467957,\n",
       "  0.5329889117217645,\n",
       "  0.5335275988753249,\n",
       "  0.532936480229463,\n",
       "  0.5332607193206383,\n",
       "  0.5328353914788099,\n",
       "  0.5328113204095422,\n",
       "  0.5329194175518626,\n",
       "  0.5334810403788962,\n",
       "  0.5330872341869323,\n",
       "  0.5332236505620848,\n",
       "  0.5329853725142595,\n",
       "  0.5334582781888605,\n",
       "  0.5332357074187054,\n",
       "  0.5329784397187272,\n",
       "  0.5331223701558462,\n",
       "  0.5332509780802378,\n",
       "  0.5329333313596927,\n",
       "  0.5332262511175823,\n",
       "  0.533127044274555,\n",
       "  0.532907756121178,\n",
       "  0.5331315490288463,\n",
       "  0.5331823268556982,\n",
       "  0.533331121128749,\n",
       "  0.533264168878881,\n",
       "  0.5328153606837358,\n",
       "  0.5333465558242022,\n",
       "  0.5331760317814059,\n",
       "  0.5329982376680141]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_callback.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_directory = base_dir + '/tiny_test16/class0'\n",
    "files = os.listdir(images_directory)\n",
    "files.sort()\n",
    "\n",
    "images = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for file in files:\n",
    "    counter += 1\n",
    "    if counter > 100:\n",
    "        break\n",
    "    if not file.startswith('.'):\n",
    "        #print(file)\n",
    "        \n",
    "#         img = load_img(images_directory + '/' + file, False, target_size=(patch_size, patch_size))\n",
    "#         x = img_to_array(img)\n",
    "#         x = np.expand_dims(x, axis=0)\n",
    "#         images.append(x)\n",
    "        \n",
    "#         img = load_img(images_directory + '/' + file, False, target_size=(input_patch_size, input_patch_size))\n",
    "        img = imageio.imread(images_directory + '/' + file)\n",
    "        img = np.expand_dims(img, axis=-1)        \n",
    "        images.append(img)\n",
    "        \n",
    "\n",
    "\n",
    "images = np.array(images).reshape(np.array(images).shape[0], input_shape[0], input_shape[1], input_shape[2])\n",
    "images = images / 255\n",
    "predictions = autoencoder.predict_on_batch(np.array(images))\n",
    "print(\"predictions: \")\n",
    "for i, im1 in enumerate(images):\n",
    "    im_1 = im1.reshape(input_shape)\n",
    "    plt.imshow(im_1, interpolation='nearest')\n",
    "    plt.show()\n",
    "    \n",
    "    pred_1 = predictions[i].numpy()#.reshape(input_shape)\n",
    "    plt.imshow(pred_1, interpolation='nearest')\n",
    "    plt.show()\n",
    "    \n",
    "    if i == 2:\n",
    "        break\n",
    "    print(\"next\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdb1adccba8>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdb28ca04a8>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fdb1add5a90>\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fdb1add58d0>\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fdb1a927940>\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fdb1a93e668>\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 16, 16, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 16, 16, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 32)          0         \n",
      "=================================================================\n",
      "Total params: 19,392\n",
      "Trainable params: 19,392\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = Model(input_img, encoded)\n",
    "for i in range(1, len(encoder.layers)):\n",
    "    print(encoder.get_layer(index=i))\n",
    "    encoder.get_layer(index=i).set_weights(autoencoder.get_layer(index=i).get_weights())\n",
    "encoder.summary()\n",
    "\n",
    "# encoder.save(base_dir + '/encoder' + model_version + '.h5')\n",
    "encoder.save(base_dir + '/' + model_version + '__encoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = encoder.predict_on_batch(np.array(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 32), dtype=float32, numpy=\n",
       "array([[[ 0.05966851, -0.26818657, -0.11318576,  0.17221172,\n",
       "          0.04130863,  0.05998178,  0.01170761,  0.12407231,\n",
       "          0.08902258,  0.08709061,  0.20052694, -0.03684419,\n",
       "          0.15361314,  0.01420016, -0.01120436,  0.02685038,\n",
       "          0.12268754,  0.10113987,  0.05806715, -0.06729281,\n",
       "          0.03453163,  0.14863712, -0.00692987, -0.13400543,\n",
       "          0.21564935,  0.15792151, -0.09602183,  0.03884255,\n",
       "         -0.19177443, -0.05892086,  0.07646348,  0.02323889],\n",
       "        [ 0.12723237, -0.18052644,  0.02786624,  0.09348749,\n",
       "          0.00314188,  0.10303205,  0.0825392 ,  0.0552977 ,\n",
       "         -0.03070724,  0.10069417,  0.20991829, -0.02091908,\n",
       "          0.06154021, -0.07194704,  0.10726494,  0.10775547,\n",
       "          0.09555376,  0.10137293,  0.11164939,  0.06571281,\n",
       "          0.0666851 ,  0.16709495,  0.095796  ,  0.02433616,\n",
       "          0.1679791 ,  0.20184939, -0.10499144, -0.11508316,\n",
       "         -0.02523911, -0.10525906,  0.05522071, -0.08020419]],\n",
       "\n",
       "       [[-0.02786893, -0.14658022, -0.00697649,  0.13087265,\n",
       "          0.02505282,  0.13258153, -0.09728819,  0.11736601,\n",
       "          0.14210123,  0.09386212,  0.22447799,  0.0298565 ,\n",
       "          0.15457422,  0.01588979,  0.05021629,  0.02892663,\n",
       "         -0.04979199,  0.10780222,  0.04449468,  0.09166993,\n",
       "          0.05905635,  0.17498636,  0.16567247, -0.17520773,\n",
       "          0.17842343,  0.17122686, -0.17722887,  0.03506847,\n",
       "         -0.24285609, -0.15959734,  0.10885385, -0.06451911],\n",
       "        [ 0.21559793, -0.21637678,  0.06245741,  0.08787822,\n",
       "         -0.02987075,  0.12744436, -0.152417  ,  0.02493517,\n",
       "         -0.0489158 ,  0.07356837,  0.224976  ,  0.02389927,\n",
       "          0.06235826, -0.02924162,  0.1291567 ,  0.14630401,\n",
       "         -0.03587228,  0.09691723,  0.18973844,  0.17642066,\n",
       "          0.07709607,  0.21473272,  0.2487371 ,  0.00552327,\n",
       "          0.19566819,  0.19520703, -0.15224606, -0.03984702,\n",
       "         -0.12000954, -0.10332918,  0.03241099,  0.00672738]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.39828813"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(predictions.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4369346"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(predictions.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([100, 2, 2, 32])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 117831<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 1.39MB of 1.39MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>wandb/run-20201027_095631-333fadgt/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>wandb/run-20201027_095631-333fadgt/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>499</td></tr><tr><td>loss</td><td>0.53739</td></tr><tr><td>val_loss</td><td>0.533</td></tr><tr><td>_step</td><td>499</td></tr><tr><td>_runtime</td><td>30931</td></tr><tr><td>_timestamp</td><td>1603819922</td></tr><tr><td>best_val_loss</td><td>0.53265</td></tr><tr><td>best_epoch</td><td>430</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td></td></tr><tr><td>loss</td><td></td></tr><tr><td>val_loss</td><td></td></tr><tr><td>_step</td><td></td></tr><tr><td>_runtime</td><td></td></tr><tr><td>_timestamp</td><td></td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1501 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">light-river-5</strong>: <a href=\"https://wandb.ai/nimpy/patch-desc-ae/runs/333fadgt\" target=\"_blank\">https://wandb.ai/nimpy/patch-desc-ae/runs/333fadgt</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  59.,  160.,  689., 1378., 2944., 3645., 2379.,  988.,  453.,\n",
       "         105.]),\n",
       " array([-0.39828813, -0.31476587, -0.23124358, -0.14772132, -0.06419905,\n",
       "         0.01932323,  0.1028455 ,  0.18636778,  0.26989004,  0.35341233,\n",
       "         0.4369346 ], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(predictions.numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_2",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
