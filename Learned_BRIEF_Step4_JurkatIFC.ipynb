{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, Dense, Flatten, Reshape, UpSampling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras import backend as K\n",
    "from keras import initializers\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import listdir\n",
    "from os import system\n",
    "import os\n",
    "import random\n",
    "\n",
    "import imageio\n",
    "\n",
    "from skimage.measure import block_reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "brief_patch_size = 48  # default value of PATCH_SIZE in OpenCV implementation\n",
    "input_patch_size = 56  # larger than the default value, s.t. the blurring is done using valid padding\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/scratch/jurkat_ifc/ch3_dataset'\n",
    "\n",
    "train_data_dir      = base_dir + '/train'\n",
    "validation_data_dir = base_dir + '/validation'\n",
    "test_data_dir       = base_dir + '/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_data(dir_patches):\n",
    "    \"\"\"Load all the patches from dir_patches into tensors for training the autoencoder.\n",
    "    Return:\n",
    "        patches_in  -- tensor of stacked patches in their original shape, 56x56\n",
    "        patches_out -- tensor of the original patches center cropped to 48x48 \n",
    "                       and then downsampled to 24x24\n",
    "    \n",
    "    \"\"\"\n",
    "    files_patches = listdir(dir_patches)\n",
    "    files_patches.sort()\n",
    "    \n",
    "    patches_in = []\n",
    "    patches_out = []\n",
    "\n",
    "    \n",
    "    for file_patch in files_patches:\n",
    "        patch_orig = imageio.imread(dir_patches + '/' + file_patch)\n",
    "        patch_in = np.zeros((input_patch_size, input_patch_size))\n",
    "        patch_in[: 55, : 55] = patch_orig\n",
    "        patch_in[55, :] = patch_in[54, :]\n",
    "        patch_in[:, 55] = patch_in[:, 54]\n",
    "         \n",
    "        patch_out = patch_in[5: 53, 5: 53]  # center-crop to 48x48 (original BRIEF input patch size)\n",
    "        patch_out = block_reduce(patch_out, (2, 2), func=np.mean)  # downsample (mean-pool)\n",
    "        \n",
    "        patches_in.append(patch_in)\n",
    "        patches_out.append(patch_out)\n",
    "        \n",
    "\n",
    "    patches_in = np.array(patches_in)\n",
    "    patches_in = patches_in.astype(np.float64) / 255\n",
    "    patches_in = np.expand_dims(patches_in, -1)\n",
    "    \n",
    "    patches_out = np.array(patches_out)\n",
    "    patches_out = patches_out.astype(np.float64) / 255\n",
    "    patches_out = np.expand_dims(patches_out, -1)\n",
    "        \n",
    "    print(\"in\", patches_in.shape, \"; out\", patches_out.shape)\n",
    "    \n",
    "    return patches_in, patches_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in (25809, 56, 56, 1) ; out (25809, 24, 24, 1)\n",
      "in (3227, 56, 56, 1) ; out (3227, 24, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = loading_data(train_data_dir)\n",
    "x_validation, y_validation = loading_data(validation_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fcf64682978>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.array(y_validation[25, :, :, 0] * 255, dtype=np.uint8), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datagen = ImageDataGenerator(rotation_range=30, zoom_range=0.2,\n",
    "    width_shift_range=0.3, height_shift_range=0.3, shear_range=0.2,\n",
    "    horizontal_flip=False, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "brief_ae = load_model('/home/niaki/Projects/learned-brief/weights_pub/learned_brief_ae_20200605.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 2813/25809 [==>...........................] - ETA: 14:48 - loss: 0.6388"
     ]
    }
   ],
   "source": [
    "model_version = '0.0.0.0_pretrainedLearnedBRIEF_output24X24'\n",
    "\n",
    "os.system('mkdir ' + base_dir + '/weights' + model_version)\n",
    "\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "    base_dir + '/weights' + model_version + '/weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss',\n",
    "    verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "history_callback = brief_ae.fit_generator(image_datagen.flow(x_train, y_train, batch_size),\n",
    "                steps_per_epoch=x_train.shape[0],\n",
    "                epochs=50,\n",
    "                validation_data=image_datagen.flow(x_validation, y_validation, batch_size),\n",
    "                validation_steps=x_validation.shape[0],\n",
    "                callbacks=[checkpointer]\n",
    "                )\n",
    "\n",
    "brief_ae.save(base_dir + '/brief_ae_step4_' + model_version + '.h5')\n",
    "\n",
    "# brief_ae = load_model(base_dir + '/brief_ae_' + model_version + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf2)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
