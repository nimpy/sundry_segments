{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "\n",
    "import imageio\n",
    "import numpy as np\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/niaki/PycharmProjects/patch-desc-ae')\n",
    "from ae_descriptor import init_descr_32, init_descr_128\n",
    "import ae_descriptor\n",
    "from other_descriptors.other_descriptors import compute_chen_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/niaki/Code/sundry_segments/weights'\n",
    "model_version = '0.0.0.9_lr0.0001_50moreepochs'\n",
    "vae_patch_size = 56\n",
    "\n",
    "patch_size = 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/niaki/anaconda3/envs/nlm/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method Sampling.call of <__main__.Sampling object at 0x7fb74b856fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Sampling.call of <__main__.Sampling object at 0x7fb74b856fd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Sampling.call of <__main__.Sampling object at 0x7fb74b856fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Sampling.call of <__main__.Sampling object at 0x7fb74b856fd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 56, 56, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 28, 28, 32)   320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 14, 14, 64)   18496       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 7, 7, 64)     36928       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 3136)         0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          803072      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 128)          32896       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 128)          32896       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sampling (Sampling)             (None, 128)          0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 924,608\n",
      "Trainable params: 924,608\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 128\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(vae_patch_size, vae_patch_size, 1))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 128)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3136)              404544    \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 56, 56, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 56, 56, 1)         289       \n",
      "=================================================================\n",
      "Total params: 497,153\n",
      "Trainable params: 497,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((7, 7, 64))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = encoder(data)\n",
    "            reconstruction = decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(data, reconstruction)\n",
    "            )\n",
    "            reconstruction_loss *= 28 * 28\n",
    "            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "            kl_loss *= -0.5\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.load_weights(base_dir + '/vae_' + model_version + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ae32_encoder = init_descr_32(vae_patch_size, vae_patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psnr(img1, img2, max_value=255):\n",
    "    \"\"\"\"Calculating peak signal-to-noise ratio (PSNR) between two images.\"\"\"\n",
    "    mse = np.mean((np.array(img1, dtype=np.float32) - np.array(img2, dtype=np.float32)) ** 2)\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    return 20 * np.log10(max_value / (np.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ssd(img1, img2):\n",
    "    \"\"\"Computing the sum of squared differences (SSD) between two images.\"\"\"\n",
    "    if img1.shape != img2.shape:\n",
    "        raise Exception(\"Images don't have the same shape: \", img1.shape, \"and\", img2.shape)\n",
    "    return np.sum((np.array(img1, dtype=np.float32) - np.array(img2, dtype=np.float32))**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_descriptor(descr, patch):\n",
    "    assert patch.shape == (patch_size, patch_size), \"Patch shape should be (65, 65), and not \" + str(patch.shape)\n",
    "    assert descr == ae32_encoder or descr == vae.encoder, \"Type of descriptor not supported\"\n",
    "    \n",
    "    patch = patch / 255.0\n",
    "    patch_crop = patch[4: 60, 4: 60]\n",
    "    \n",
    "    if descr == ae32_encoder:\n",
    "        patch_crop = np.repeat(patch_crop, 3, axis=1).reshape((patch_crop.shape[0], patch_crop.shape[1], 3))\n",
    "    else:\n",
    "        patch_crop = np.expand_dims(patch_crop, axis=-1)\n",
    "    \n",
    "    patch_crop_encoded = descr.predict(np.expand_dims(patch_crop, axis=0))\n",
    "    \n",
    "    if descr == vae.encoder:\n",
    "        patch_crop_encoded = patch_crop_encoded[2]\n",
    "    \n",
    "    patch_crop_encoded_flat = patch_crop_encoded.flatten()\n",
    "    return patch_crop_encoded_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_lenna = imageio.imread('/home/niaki/Code/Lenna.png')\n",
    "image_lenna = np.dot(image_lenna[ : ,  : , : 3], [0.299, 0.587, 0.114])\n",
    "image_lenna = image_lenna.astype(np.uint8)\n",
    "image_briefs = imageio.imread(\"/home/niaki/PycharmProjects/learned-brief/images/briefs_gray.bmp\")\n",
    "image_hpatches = imageio.imread(\"/home/niaki/Downloads/hpatches_patch.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_patches_for_queries_and_descr(x_queries, y_queries, which_desc, image, random_seed=0, \n",
    "                                           noise_level=0, patch_size=65, compare_stride=8, eps=0.0001, nr_similar_patches=6):\n",
    "\n",
    "    np.random.seed(random_seed)\n",
    "#     image = imageio.imread(image_path)\n",
    "#     image = np.dot(image[ : ,  : , : 3], [0.299, 0.587, 0.114])\n",
    "#     image = image.astype(np.uint8)\n",
    "    image_height = image.shape[0]\n",
    "    image_width = image.shape[1]\n",
    "    \n",
    "    results_patches_diffs = {}\n",
    "    results_patches_x_coords = {}\n",
    "    results_patches_y_coords = {}\n",
    "    results_patches_positions = {}\n",
    "\n",
    "    counter_query_patches = 0\n",
    "\n",
    "    total_nr_query_patches = len(x_queries)\n",
    "\n",
    "    for query_it in range(total_nr_query_patches):\n",
    "\n",
    "        x_query = x_queries[query_it]\n",
    "        y_query = y_queries[query_it]\n",
    "\n",
    "        sys.stdout.write(\"\\r\" + str(counter_query_patches + 1) + \"/\" + str(total_nr_query_patches))\n",
    "\n",
    "        query_patch = image[x_query: x_query + patch_size, y_query: y_query + patch_size]\n",
    "\n",
    "        if which_desc == 0:\n",
    "            query_patch_descr = compute_descriptor(ae32_encoder, query_patch)\n",
    "        elif which_desc == 1:\n",
    "            query_patch_descr = compute_descriptor(vae.encoder, query_patch)\n",
    "        else:\n",
    "            raise Exception(\"Wrong input for which_desc\")\n",
    "\n",
    "        counter_compare_patches = 0\n",
    "\n",
    "        patches_diffs = [1000000000]\n",
    "        patches_x_coords = [-1]\n",
    "        patches_y_coords = [-1]\n",
    "        patches_positions = [-1]\n",
    "\n",
    "        for y_compare in range(0, image_width - patch_size + 1, compare_stride):\n",
    "            for x_compare in range(0, image_height - patch_size + 1, compare_stride):\n",
    "\n",
    "                compare_patch = image[x_compare: x_compare + patch_size, y_compare: y_compare + patch_size]\n",
    "\n",
    "                if which_desc == 0:\n",
    "                    compare_patch_descr = compute_descriptor(ae32_encoder, compare_patch)\n",
    "                elif which_desc == 1:\n",
    "                    compare_patch_descr = compute_descriptor(vae.encoder, compare_patch)\n",
    "                else:\n",
    "                    raise Exception(\"Wrong input for which_desc\")\n",
    "\n",
    "                diff = calculate_ssd(query_patch_descr, compare_patch_descr)\n",
    "\n",
    "                if diff < eps:\n",
    "                    counter_compare_patches += 1\n",
    "                    continue\n",
    "\n",
    "                # sorting\n",
    "                for i in range(len(patches_diffs)):\n",
    "                    if diff < patches_diffs[i]:\n",
    "                        patches_diffs.insert(i, diff)\n",
    "                        patches_x_coords.insert(i, x_compare)\n",
    "                        patches_y_coords.insert(i, y_compare)\n",
    "                        patches_positions.insert(i, counter_compare_patches)\n",
    "                        break\n",
    "\n",
    "                counter_compare_patches += 1\n",
    "\n",
    "        results_patches_diffs[counter_query_patches] = patches_diffs[:nr_similar_patches]\n",
    "        results_patches_x_coords[counter_query_patches] = patches_x_coords[:nr_similar_patches]\n",
    "        results_patches_y_coords[counter_query_patches] = patches_y_coords[:nr_similar_patches]\n",
    "        results_patches_positions[counter_query_patches] = patches_positions[:nr_similar_patches]\n",
    "\n",
    "        counter_query_patches += 1\n",
    "\n",
    "    return results_patches_x_coords, results_patches_y_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_visualisation_for_3_descrs(x_queries, y_queries, results_patches_x_coords_0, results_patches_y_coords_0,\n",
    "                                        results_patches_x_coords_1, results_patches_y_coords_1,\n",
    "                                        image, random_seed=0, noise_level=0,\n",
    "                                        patch_size=65, nr_similar_patches=6):\n",
    "\n",
    "    assert nr_similar_patches % 2 == 0, \"If nr_similar_patches is odd, it will give an odd graph (I'll show myself out)\"\n",
    "    np.random.seed(random_seed)\n",
    "#     image = imageio.imread(image_path)\n",
    "#     image = np.dot(image[ : ,  : , : 3], [0.299, 0.587, 0.114])\n",
    "#     image = image.astype(np.uint8)\n",
    "    \n",
    "\n",
    "    y_offset_under = -0.2\n",
    "    font_size = 18\n",
    "    x_offset_left = -2.5\n",
    "    y_offset_left = 15\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 4))\n",
    "\n",
    "    total_nr_query_patches = len(x_queries)\n",
    "\n",
    "    columns = nr_similar_patches + 2\n",
    "    rows = total_nr_query_patches * 2\n",
    "    \n",
    "\n",
    "    counter_query_patches = 0 # TODO test it with multiple query patches\n",
    "\n",
    "    for query_it in range(total_nr_query_patches):\n",
    "\n",
    "        x_query = x_queries[query_it]\n",
    "        y_query = y_queries[query_it]\n",
    "        patch_query = image[x_query: x_query + patch_size, y_query: y_query + patch_size]\n",
    "\n",
    "        ax = fig.add_subplot(rows // 2, columns // 2, (counter_query_patches * 2) * (nr_similar_patches + 2) + 1)\n",
    "        ax.axis('off')\n",
    "        # ax.set_title('query', y=y_offset_under, fontsize=font_size)  # + str(query_it + 1)\n",
    "        ax.imshow(patch_query, cmap='gray')\n",
    "\n",
    "        for i in range(nr_similar_patches):\n",
    "            x_compare = results_patches_x_coords_0[counter_query_patches][i]\n",
    "            y_compare = results_patches_y_coords_0[counter_query_patches][i]\n",
    "\n",
    "            # psnr = calculate_psnr(image[x_query: x_query + patch_size, y_query: y_query + patch_size, :],\n",
    "            #                       image[x_compare: x_compare + patch_size, y_compare: y_compare + patch_size, :],\n",
    "            #                       max_value=psnr_max_value)\n",
    "\n",
    "            patch_compare = image[x_compare: x_compare + patch_size, y_compare: y_compare + patch_size]\n",
    "\n",
    "            ax = fig.add_subplot(rows, columns, (counter_query_patches * 2) * (nr_similar_patches + 2) + 3 + i)\n",
    "            ax.axis('off')\n",
    "            # if i == 0:\n",
    "                # ax.text(x_offset_left, 1, 'proposed v128', rotation=90, fontsize=font_size)\n",
    "                # ax.text(x_offset_left, y_offset_left, 'proposed v128', rotation=90, fontsize=font_size)  # y_offset_left\n",
    "            # ax.set_title(\"{:.2f} [dB]\".format(psnr), y=y_offset_under, fontsize=font_size)\n",
    "            ax.imshow(patch_compare, cmap='gray')\n",
    "\n",
    "        for i in range(nr_similar_patches):\n",
    "            x_compare = results_patches_x_coords_1[counter_query_patches][i]\n",
    "            y_compare = results_patches_y_coords_1[counter_query_patches][i]\n",
    "\n",
    "            # psnr = calculate_psnr(image[x_query: x_query + patch_size, y_query: y_query + patch_size, :],\n",
    "            #                       image[x_compare: x_compare + patch_size, y_compare: y_compare + patch_size, :],\n",
    "            #                       max_value=psnr_max_value)\n",
    "\n",
    "            patch_compare = image[x_compare: x_compare + patch_size, y_compare: y_compare + patch_size]\n",
    "\n",
    "            ax = fig.add_subplot(rows, columns, ((counter_query_patches * 2) + 1) * (nr_similar_patches + 2) + 3 + i)\n",
    "            ax.axis('off')\n",
    "            # if i == 0:\n",
    "                # ax.text(x_offset_left, y_offset_left - 2, 'Chen et al.', rotation=90, fontsize=font_size)\n",
    "            # ax.set_title(\"{:.2f} [dB]\".format(psnr), y=y_offset_under, fontsize=font_size)\n",
    "            ax.imshow(patch_compare, cmap='gray')\n",
    "\n",
    "\n",
    "        counter_query_patches += 1\n",
    "\n",
    "    # fig.savefig(\"/home/niaki/PycharmProjects/patch-desc-ae/results/Visualisation_v128_chen_exhaustive_q_\" + str(x_query) + \"_\" + str(y_query) + \"_noise\" + str(noise_level) + \".pdf\", bbox_inches='tight')\n",
    "    fig.savefig(\"/home/niaki/Downloads/Visualisation_AE32_vs_VAE0.0.0.9_\" + str(x_query) + \"_\" + str(\n",
    "        y_query) + \"_noise\" + str(noise_level) + \"_\" + datetime.datetime.now().strftime(\n",
    "        \"%Y%m%d_%H%M%S\") + \".pdf\", bbox_inches='tight')\n",
    "    fig.savefig(\"/home/niaki/Downloads/Visualisation_AE32_vs_VAE0.0.0.9_\" + str(x_query) + \"_\" + str(\n",
    "        y_query) + \"_noise\" + str(noise_level) + \"_\" + datetime.datetime.now().strftime(\n",
    "        \"%Y%m%d_%H%M%S\") + \".png\", bbox_inches='tight')\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    plt.show(block=True)\n",
    "    plt.interactive(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1"
     ]
    }
   ],
   "source": [
    "x_queries = [patch_size * 7]   # 1, 4, 7,  7,  7,  51, 51, 51, 15, 31\n",
    "y_queries = [patch_size * 21]  # 1, 6, 19, 17, 21, 19, 21, 30, 29, 28\n",
    "\n",
    "image_path = '/home/niaki/Downloads/montage.png'\n",
    "image = imageio.imread(image_path)\n",
    "# image = np.dot(image[ : ,  : , : 3], [0.299, 0.587, 0.114])\n",
    "# image = image.astype(np.uint8)\n",
    "\n",
    "compare_stride = 65\n",
    "\n",
    "results_patches_x_coords_0, results_patches_y_coords_0 = retrieve_patches_for_queries_and_descr(x_queries, y_queries, 0, image, compare_stride=compare_stride)\n",
    "results_patches_x_coords_1, results_patches_y_coords_1 = retrieve_patches_for_queries_and_descr(x_queries, y_queries, 1, image, compare_stride=compare_stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_visualisation_for_3_descrs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-221-174a7a58355d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m generate_visualisation_for_3_descrs(x_queries, y_queries, results_patches_x_coords_0, results_patches_y_coords_0,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                         \u001b[0mresults_patches_x_coords_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_patches_y_coords_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                         image)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generate_visualisation_for_3_descrs' is not defined"
     ]
    }
   ],
   "source": [
    "generate_visualisation_for_3_descrs(x_queries, y_queries, results_patches_x_coords_0, results_patches_y_coords_0,\n",
    "                                        results_patches_x_coords_1, results_patches_y_coords_1,\n",
    "                                        image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_SSDs_for_descr(which_desc, image, patch_size=65, query_stride=65, compare_stride=65, nr_similar_patches=6, eps=0.0001):\n",
    "\n",
    "    image_height = image.shape[0]\n",
    "    image_width = image.shape[1]\n",
    "    \n",
    "    query_x_coords = []\n",
    "    query_y_coords = []\n",
    "\n",
    "    results_noisy_descr_patches_diffs = {}\n",
    "    results_noisy_descr_patches_x_coords = {}\n",
    "    results_noisy_descr_patches_y_coords = {}\n",
    "    results_noisy_descr_patches_positions = {}\n",
    "\n",
    "    counter_query_patches = 0\n",
    "\n",
    "    # just for the sake of output\n",
    "    total_nr_query_patches = len(range(0, image_width - patch_size + 1, query_stride)) * len(\n",
    "        range(0, image_height - patch_size + 1, query_stride))\n",
    "\n",
    "    for y_query in range(0, image_width - patch_size + 1, query_stride):\n",
    "        for x_query in range(0, image_height - patch_size + 1, query_stride):\n",
    "            sys.stdout.write(\"\\r\" + str(counter_query_patches + 1) + \"/\" + str(total_nr_query_patches))\n",
    "\n",
    "            query_x_coords.append(x_query)\n",
    "            query_y_coords.append(y_query)\n",
    "\n",
    "            query_patch = image[x_query: x_query + patch_size, y_query: y_query + patch_size]\n",
    "            \n",
    "            if which_desc == 0:\n",
    "                query_patch_descr = compute_descriptor(ae32_encoder, query_patch)\n",
    "            elif which_desc == 1:\n",
    "                query_patch_descr = compute_descriptor(vae.encoder, query_patch)\n",
    "            else:\n",
    "                raise Exception(\"Wrong input for which_desc\")\n",
    "            \n",
    "            counter_compare_patches = 0\n",
    "\n",
    "            patches_diffs = [1000000000]\n",
    "            patches_x_coords = [-1]\n",
    "            patches_y_coords = [-1]\n",
    "            patches_positions = [-1]\n",
    "\n",
    "            for y_compare in range(0, image_width - patch_size + 1, compare_stride):\n",
    "                for x_compare in range(0, image_height - patch_size + 1, compare_stride):\n",
    "\n",
    "                    compare_patch = image[x_compare: x_compare + patch_size, y_compare: y_compare + patch_size]\n",
    "\n",
    "                    if which_desc == 0:\n",
    "                        compare_patch_descr = compute_descriptor(ae32_encoder, compare_patch)\n",
    "                    elif which_desc == 1:\n",
    "                        compare_patch_descr = compute_descriptor(vae.encoder, compare_patch)\n",
    "                    else:\n",
    "                        raise Exception(\"Wrong input for which_desc\")\n",
    "\n",
    "                    diff = calculate_ssd(query_patch_descr, compare_patch_descr)\n",
    "\n",
    "                    if diff < eps:\n",
    "                        counter_compare_patches += 1\n",
    "                        continue\n",
    "\n",
    "                    # sorting\n",
    "                    for i in range(len(patches_diffs)):\n",
    "                        if diff < patches_diffs[i]:\n",
    "                            patches_diffs.insert(i, diff)\n",
    "                            patches_x_coords.insert(i, x_compare)\n",
    "                            patches_y_coords.insert(i, y_compare)\n",
    "                            patches_positions.insert(i, counter_compare_patches)\n",
    "                            break\n",
    "\n",
    "                    counter_compare_patches += 1\n",
    "            \n",
    "                       \n",
    "            results_noisy_descr_patches_diffs[counter_query_patches] = patches_diffs[:nr_similar_patches]\n",
    "            results_noisy_descr_patches_x_coords[counter_query_patches] = patches_x_coords[:nr_similar_patches]\n",
    "            results_noisy_descr_patches_y_coords[counter_query_patches] = patches_y_coords[:nr_similar_patches]\n",
    "            results_noisy_descr_patches_positions[counter_query_patches] = patches_positions[:nr_similar_patches]\n",
    "\n",
    "            counter_query_patches += 1\n",
    "\n",
    "    ssds = []\n",
    "    ssims = []\n",
    "    psnrs=[]\n",
    "\n",
    "    for q_it in range(total_nr_query_patches):\n",
    "        for c_it in range(nr_similar_patches):\n",
    "\n",
    "            # getting the query patch from the clean image\n",
    "            x_query = query_x_coords[q_it]\n",
    "            y_query = query_y_coords[q_it]\n",
    "            query_patch = image[x_query: x_query + patch_size, y_query: y_query + patch_size]\n",
    "\n",
    "            # getting the compare patch from the clean image\n",
    "            x_compare = results_noisy_descr_patches_x_coords[q_it][c_it]\n",
    "            y_compare = results_noisy_descr_patches_y_coords[q_it][c_it]\n",
    "            compare_patch = image[x_compare: x_compare + patch_size, y_compare: y_compare + patch_size]\n",
    "\n",
    "            # calculating the difference in the clean image\n",
    "            actual_diff = calculate_ssd(query_patch, compare_patch)\n",
    "            ssds.append(actual_diff)\n",
    "            \n",
    "            dr_max = max(query_patch.max(), compare_patch.max())\n",
    "            dr_min = min(query_patch.min(), compare_patch.min())\n",
    "            diff_ssim = ssim(query_patch, compare_patch, data_range=dr_max - dr_min)\n",
    "            ssims.append(diff_ssim)\n",
    "            \n",
    "            diff_psnr = calculate_psnr(query_patch, compare_patch, max_value=255)\n",
    "            psnrs.append(diff_psnr)\n",
    "            \n",
    "    ssds = np.array(ssds)\n",
    "    ssims = np.array(ssims)\n",
    "    psnrs = np.array(psnrs)\n",
    "    \n",
    "    return ssds, ssims, psnrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "580/580\n",
      "==============\n",
      "\n",
      "580/580\n",
      "==============\n",
      "\n"
     ]
    }
   ],
   "source": [
    "image_path = '/home/niaki/Downloads/montage.png'\n",
    "image = imageio.imread(image_path)\n",
    "\n",
    "ssds_by_model = {}\n",
    "ssims_by_model = {}\n",
    "psnrs_by_model = {}\n",
    "\n",
    "which_descs = [0, 1]\n",
    "\n",
    "query_stride = 65 * 2  # 5\n",
    "\n",
    "for which_desc in which_descs:\n",
    "    ssds_by_model[which_desc], ssims_by_model[which_desc], psnrs_by_model[which_desc] = calculate_SSDs_for_descr(which_desc, image, patch_size=65, query_stride=query_stride, compare_stride=65, nr_similar_patches=5)\n",
    "    print('\\n==============\\n')\n",
    "    \n",
    "which_descs_string = \"_\".join(str(which_desc) for which_desc in which_descs)\n",
    "ssds_by_model_file_path = '/home/niaki/Downloads/ssds__descrs_' + which_descs_string + '__querystride_' + str(query_stride) + '__' + datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + '.pkl'\n",
    "\n",
    "with open(ssds_by_model_file_path, 'wb') as f:\n",
    "    pickle.dump((ssds_by_model, ssims_by_model, psnrs_by_model), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nr_similar_patches=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3705725.0"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ssds_by_model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10119623.0"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ssds_by_model[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32032504156651004"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ssims_by_model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.423992354215702"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ssims_by_model[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.707794206803428"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(psnrs_by_model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.302910285213493"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(psnrs_by_model[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nr_similar_patches=5, 580 query patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3557544.8"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ssds_by_model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10301963.0"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ssds_by_model[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31872559185122595"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ssims_by_model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41613687748792816"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ssims_by_model[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.736298700335812"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(psnrs_by_model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.198053697735865"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(psnrs_by_model[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set is a matrix of patches of dimensions [58 40] so in total 2320 patches\n"
     ]
    }
   ],
   "source": [
    "print(\"test set is a matrix of patches of dimensions\", np.array(image.shape) // patch_size, \"so in total\", np.prod(np.array(image.shape) // patch_size), \"patches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlm]",
   "language": "python",
   "name": "conda-env-nlm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
